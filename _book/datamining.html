<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>資料科學與R語言</title>
  <meta name="description" content="介紹如何使用R語言完成資料讀取、處理、分析與呈現，以及大數據技術與R的整合">
  <meta name="generator" content="bookdown 0.3.9 and GitBook 2.6.7">

  <meta property="og:title" content="資料科學與R語言" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://yijutseng.github.io/DataScienceRBook" />
  
  <meta property="og:description" content="介紹如何使用R語言完成資料讀取、處理、分析與呈現，以及大數據技術與R的整合" />
  <meta name="github-repo" content="yijutseng/DataAnalyticsWithRBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="資料科學與R語言" />
  
  <meta name="twitter:description" content="介紹如何使用R語言完成資料讀取、處理、分析與呈現，以及大數據技術與R的整合" />
  

<meta name="author" content="曾意儒 Yi-Ju Tseng">


<meta name="date" content="2017-05-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="InteractiveGraphics.html">
<link rel="next" href="big.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/detect-resize/jquery.resize.js"></script>
<link href="libs/jquery-ui/jquery-ui.min.css" rel="stylesheet" />
<script src="libs/jquery-ui/jquery-ui.min.js"></script>
<script src="libs/d3/d3.min.js"></script>
<script src="libs/vega/vega.min.js"></script>
<script src="libs/lodash/lodash.min.js"></script>
<script>var lodash = _.noConflict();</script>
<link href="libs/ggvis/css/ggvis.css" rel="stylesheet" />
<script src="libs/ggvis/js/ggvis.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<link href="libs/plotlyjs/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs/plotly-latest.min.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-2407708-3', 'auto');
ga('send', 'pageview');

</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">資料科學與R語言</a></li>

<li class="divider"></li>
<li><a href="index.html#preface"></a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> R語言101</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>1.1</b> 什麼是R語言</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#section-1.2"><i class="fa fa-check"></i><b>1.2</b> 函數使用</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#section-1.3"><i class="fa fa-check"></i><b>1.3</b> 變數設定</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#section-1.4"><i class="fa fa-check"></i><b>1.4</b> 執行視窗</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#DataType"><i class="fa fa-check"></i><b>1.5</b> 資料型態</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#-numeric"><i class="fa fa-check"></i><b>1.5.1</b> 數值 numeric</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#-character"><i class="fa fa-check"></i><b>1.5.2</b> 字串 character</a></li>
<li class="chapter" data-level="1.5.3" data-path="intro.html"><a href="intro.html#-logic"><i class="fa fa-check"></i><b>1.5.3</b> 布林變數 logic</a></li>
<li class="chapter" data-level="1.5.4" data-path="intro.html"><a href="intro.html#-date"><i class="fa fa-check"></i><b>1.5.4</b> 日期 (Date)</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#section-1.6"><i class="fa fa-check"></i><b>1.6</b> 基本運算子</a><ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#section-1.6.1"><i class="fa fa-check"></i><b>1.6.1</b> 數學基本運算</a></li>
<li class="chapter" data-level="1.6.2" data-path="intro.html"><a href="intro.html#section-1.6.2"><i class="fa fa-check"></i><b>1.6.2</b> 進階數學函數</a></li>
<li class="chapter" data-level="1.6.3" data-path="intro.html"><a href="intro.html#section-1.6.3"><i class="fa fa-check"></i><b>1.6.3</b> 邏輯運算</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#section-1.7"><i class="fa fa-check"></i><b>1.7</b> 錯誤訊息</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#help"><i class="fa fa-check"></i><b>1.8</b> Help</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="RDataStructure.html"><a href="RDataStructure.html"><i class="fa fa-check"></i><b>2</b> R 資料結構</a><ul>
<li class="chapter" data-level="2.1" data-path="RDataStructure.html"><a href="RDataStructure.html#-vector"><i class="fa fa-check"></i><b>2.1</b> 向量 vector</a><ul>
<li class="chapter" data-level="2.1.1" data-path="RDataStructure.html"><a href="RDataStructure.html#section-2.1.1"><i class="fa fa-check"></i><b>2.1.1</b> 快速產生向量函數</a></li>
<li class="chapter" data-level="2.1.2" data-path="RDataStructure.html"><a href="RDataStructure.html#section-2.1.2"><i class="fa fa-check"></i><b>2.1.2</b> 向量運算</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="RDataStructure.html"><a href="RDataStructure.html#-factor"><i class="fa fa-check"></i><b>2.2</b> 因子 factor</a></li>
<li class="chapter" data-level="2.3" data-path="RDataStructure.html"><a href="RDataStructure.html#-list"><i class="fa fa-check"></i><b>2.3</b> 列表 list</a><ul>
<li class="chapter" data-level="2.3.1" data-path="RDataStructure.html"><a href="RDataStructure.html#section-2.3.1"><i class="fa fa-check"></i><b>2.3.1</b> 列表資料擷取</a></li>
<li class="chapter" data-level="2.3.2" data-path="RDataStructure.html"><a href="RDataStructure.html#section-2.3.2"><i class="fa fa-check"></i><b>2.3.2</b> 列表資料編輯設定</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="RDataStructure.html"><a href="RDataStructure.html#-matrix"><i class="fa fa-check"></i><b>2.4</b> 矩陣 matrix</a></li>
<li class="chapter" data-level="2.5" data-path="RDataStructure.html"><a href="RDataStructure.html#-data.frame"><i class="fa fa-check"></i><b>2.5</b> 資料框 data.frame</a></li>
<li class="chapter" data-level="2.6" data-path="RDataStructure.html"><a href="RDataStructure.html#-data.table"><i class="fa fa-check"></i><b>2.6</b> 資料表 data.table</a></li>
<li class="chapter" data-level="2.7" data-path="RDataStructure.html"><a href="RDataStructure.html#section-2.7"><i class="fa fa-check"></i><b>2.7</b> 資料屬性查詢函數</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="controlstructure.html"><a href="controlstructure.html"><i class="fa fa-check"></i><b>3</b> 控制流程</a><ul>
<li class="chapter" data-level="3.1" data-path="controlstructure.html"><a href="controlstructure.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 條件判斷</a><ul>
<li class="chapter" data-level="3.1.1" data-path="controlstructure.html"><a href="controlstructure.html#if-else"><i class="fa fa-check"></i><b>3.1.1</b> if-else敘述</a></li>
<li class="chapter" data-level="3.1.2" data-path="controlstructure.html"><a href="controlstructure.html#if-else-if-else"><i class="fa fa-check"></i><b>3.1.2</b> if-else if-else</a></li>
<li class="chapter" data-level="3.1.3" data-path="controlstructure.html"><a href="controlstructure.html#if"><i class="fa fa-check"></i><b>3.1.3</b> 巢狀if</a></li>
<li class="chapter" data-level="3.1.4" data-path="controlstructure.html"><a href="controlstructure.html#ifelse"><i class="fa fa-check"></i><b>3.1.4</b> ifelse()</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="controlstructure.html"><a href="controlstructure.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 迴圈</a><ul>
<li class="chapter" data-level="3.2.1" data-path="controlstructure.html"><a href="controlstructure.html#for"><i class="fa fa-check"></i><b>3.2.1</b> for</a></li>
<li class="chapter" data-level="3.2.2" data-path="controlstructure.html"><a href="controlstructure.html#while"><i class="fa fa-check"></i><b>3.2.2</b> while</a></li>
<li class="chapter" data-level="3.2.3" data-path="controlstructure.html"><a href="controlstructure.html#break"><i class="fa fa-check"></i><b>3.2.3</b> break</a></li>
<li class="chapter" data-level="3.2.4" data-path="controlstructure.html"><a href="controlstructure.html#next"><i class="fa fa-check"></i><b>3.2.4</b> next</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="controlstructure.html"><a href="controlstructure.html#purrr"><i class="fa fa-check"></i><b>3.3</b> purrr</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="function.html"><a href="function.html"><i class="fa fa-check"></i><b>4</b> 函數</a></li>
<li class="chapter" data-level="5" data-path="io.html"><a href="io.html"><i class="fa fa-check"></i><b>5</b> 資料讀取與匯出</a><ul>
<li class="chapter" data-level="5.1" data-path="io.html"><a href="io.html#file"><i class="fa fa-check"></i><b>5.1</b> 從檔案匯入基本資料格式</a><ul>
<li class="chapter" data-level="5.1.1" data-path="io.html"><a href="io.html#import-dataset-rstudio"><i class="fa fa-check"></i><b>5.1.1</b> Import Dataset功能 (RStudio)</a></li>
<li class="chapter" data-level="5.1.2" data-path="io.html"><a href="io.html#-.txt"><i class="fa fa-check"></i><b>5.1.2</b> 分隔文字檔 .txt</a></li>
<li class="chapter" data-level="5.1.3" data-path="io.html"><a href="io.html#csv"><i class="fa fa-check"></i><b>5.1.3</b> CSV檔案 .csv</a></li>
<li class="chapter" data-level="5.1.4" data-path="io.html"><a href="io.html#excel-.xls"><i class="fa fa-check"></i><b>5.1.4</b> Excel檔案 .xls</a></li>
<li class="chapter" data-level="5.1.5" data-path="io.html"><a href="io.html#r-.rds"><i class="fa fa-check"></i><b>5.1.5</b> R物件 .rds</a></li>
<li class="chapter" data-level="5.1.6" data-path="io.html"><a href="io.html#r-.r"><i class="fa fa-check"></i><b>5.1.6</b> R程式 .R</a></li>
<li class="chapter" data-level="5.1.7" data-path="io.html"><a href="io.html#-"><i class="fa fa-check"></i><b>5.1.7</b> 純文字資料 (無分隔)</a></li>
<li class="chapter" data-level="5.1.8" data-path="io.html"><a href="io.html#section-5.1.8"><i class="fa fa-check"></i><b>5.1.8</b> 其他格式</a></li>
<li class="chapter" data-level="5.1.9" data-path="io.html"><a href="io.html#section-5.1.9"><i class="fa fa-check"></i><b>5.1.9</b> 其他讀檔注意事項</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="io.html"><a href="io.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 從網路匯入資料</a><ul>
<li class="chapter" data-level="5.2.1" data-path="io.html"><a href="io.html#open-data"><i class="fa fa-check"></i><b>5.2.1</b> Open Data</a></li>
<li class="chapter" data-level="5.2.2" data-path="io.html"><a href="io.html#api"><i class="fa fa-check"></i><b>5.2.2</b> API (Application programming interfaces)</a></li>
<li class="chapter" data-level="5.2.3" data-path="io.html"><a href="io.html#json"><i class="fa fa-check"></i><b>5.2.3</b> JSON格式檔案</a></li>
<li class="chapter" data-level="5.2.4" data-path="io.html"><a href="io.html#xml"><i class="fa fa-check"></i><b>5.2.4</b> XML 可延伸標記式語言</a></li>
<li class="chapter" data-level="5.2.5" data-path="io.html"><a href="io.html#-webscraping"><i class="fa fa-check"></i><b>5.2.5</b> 網頁爬蟲 Webscraping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="io.html"><a href="io.html#facebook"><i class="fa fa-check"></i><b>5.3</b> Facebook資料擷取</a><ul>
<li class="chapter" data-level="5.3.1" data-path="io.html"><a href="io.html#graph-api-in-r"><i class="fa fa-check"></i><b>5.3.1</b> Graph API in R</a></li>
<li class="chapter" data-level="5.3.2" data-path="io.html"><a href="io.html#rfacebook-package"><i class="fa fa-check"></i><b>5.3.2</b> Rfacebook package</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="io.html"><a href="io.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 資料匯出</a><ul>
<li class="chapter" data-level="5.4.1" data-path="io.html"><a href="io.html#-.txt"><i class="fa fa-check"></i><b>5.4.1</b> 文字檔 .txt</a></li>
<li class="chapter" data-level="5.4.2" data-path="io.html"><a href="io.html#csv-.csv"><i class="fa fa-check"></i><b>5.4.2</b> CSV檔 .csv</a></li>
<li class="chapter" data-level="5.4.3" data-path="io.html"><a href="io.html#r-.rds-1"><i class="fa fa-check"></i><b>5.4.3</b> R物件 .rds</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="manipulation.html"><a href="manipulation.html"><i class="fa fa-check"></i><b>6</b> 資料處理與清洗</a><ul>
<li class="chapter" data-level="6.1" data-path="manipulation.html"><a href="manipulation.html#tidy-data"><i class="fa fa-check"></i><b>6.1</b> Tidy Data</a></li>
<li class="chapter" data-level="6.2" data-path="manipulation.html"><a href="manipulation.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 資料型別轉換處理</a><ul>
<li class="chapter" data-level="6.2.1" data-path="manipulation.html"><a href="manipulation.html#section-6.2.1"><i class="fa fa-check"></i><b>6.2.1</b> 資料型別檢查</a></li>
<li class="chapter" data-level="6.2.2" data-path="manipulation.html"><a href="manipulation.html#section-6.2.2"><i class="fa fa-check"></i><b>6.2.2</b> 資料型別轉換</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="manipulation.html"><a href="manipulation.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 文字字串處理</a><ul>
<li class="chapter" data-level="6.3.1" data-path="manipulation.html"><a href="manipulation.html#section-6.3.1"><i class="fa fa-check"></i><b>6.3.1</b> 基本處理</a></li>
<li class="chapter" data-level="6.3.2" data-path="manipulation.html"><a href="manipulation.html#section-6.3.2"><i class="fa fa-check"></i><b>6.3.2</b> 搜尋字串</a></li>
<li class="chapter" data-level="6.3.3" data-path="manipulation.html"><a href="manipulation.html#-regular-expression"><i class="fa fa-check"></i><b>6.3.3</b> 正規表示式 (Regular Expression)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="manipulation.html"><a href="manipulation.html#subset"><i class="fa fa-check"></i><b>6.4</b> 子集Subset</a><ul>
<li class="chapter" data-level="6.4.1" data-path="io.html"><a href="io.html#-"><i class="fa fa-check"></i><b>6.4.1</b> 一維資料 (向量)</a></li>
<li class="chapter" data-level="6.4.2" data-path="manipulation.html"><a href="manipulation.html#section-6.4.2"><i class="fa fa-check"></i><b>6.4.2</b> 二維資料</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="manipulation.html"><a href="manipulation.html#section-6.5"><i class="fa fa-check"></i><b>6.5</b> 排序</a><ul>
<li class="chapter" data-level="6.5.1" data-path="manipulation.html"><a href="manipulation.html#sort-"><i class="fa fa-check"></i><b>6.5.1</b> sort 向量排序</a></li>
<li class="chapter" data-level="6.5.2" data-path="manipulation.html"><a href="manipulation.html#order"><i class="fa fa-check"></i><b>6.5.2</b> order</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="manipulation.html"><a href="manipulation.html#section-6.6"><i class="fa fa-check"></i><b>6.6</b> 資料組合</a></li>
<li class="chapter" data-level="6.7" data-path="manipulation.html"><a href="manipulation.html#-join"><i class="fa fa-check"></i><b>6.7</b> 資料結合 (Join)</a></li>
<li class="chapter" data-level="6.8" data-path="manipulation.html"><a href="manipulation.html#reshape"><i class="fa fa-check"></i><b>6.8</b> 長表與寬表</a></li>
<li class="chapter" data-level="6.9" data-path="manipulation.html"><a href="manipulation.html#section-6.9"><i class="fa fa-check"></i><b>6.9</b> 遺漏值處理</a></li>
<li class="chapter" data-level="6.10" data-path="manipulation.html"><a href="manipulation.html#manCase"><i class="fa fa-check"></i><b>6.10</b> 綜合練習範例Case study</a><ul>
<li class="chapter" data-level="6.10.1" data-path="manipulation.html"><a href="manipulation.html#section-6.10.1"><i class="fa fa-check"></i><b>6.10.1</b> 載入資料</a></li>
<li class="chapter" data-level="6.10.2" data-path="manipulation.html"><a href="manipulation.html#section-6.10.2"><i class="fa fa-check"></i><b>6.10.2</b> 資料總覽</a></li>
<li class="chapter" data-level="6.10.3" data-path="manipulation.html"><a href="manipulation.html#section-6.10.3"><i class="fa fa-check"></i><b>6.10.3</b> 資料排序後篩選</a></li>
<li class="chapter" data-level="6.10.4" data-path="manipulation.html"><a href="manipulation.html#section-6.10.4"><i class="fa fa-check"></i><b>6.10.4</b> 欄位值篩選</a></li>
<li class="chapter" data-level="6.10.5" data-path="manipulation.html"><a href="manipulation.html#section-6.10.5"><i class="fa fa-check"></i><b>6.10.5</b> 字串條件搜尋後篩選</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>7</b> 探索式資料分析</a><ul>
<li class="chapter" data-level="7.1" data-path="eda.html"><a href="eda.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 什麼是探索式資料分析</a></li>
<li class="chapter" data-level="7.2" data-path="eda.html"><a href="eda.html#datatable"><i class="fa fa-check"></i><b>7.2</b> data.table</a><ul>
<li class="chapter" data-level="7.2.1" data-path="eda.html"><a href="eda.html#i-"><i class="fa fa-check"></i><b>7.2.1</b> i 觀察值篩選邏輯</a></li>
<li class="chapter" data-level="7.2.2" data-path="eda.html"><a href="eda.html#j-"><i class="fa fa-check"></i><b>7.2.2</b> j 欄位選擇運算</a></li>
<li class="chapter" data-level="7.2.3" data-path="eda.html"><a href="eda.html#by-"><i class="fa fa-check"></i><b>7.2.3</b> by 分組依據</a></li>
<li class="chapter" data-level="7.2.4" data-path="eda.html"><a href="eda.html#section-7.2.4"><i class="fa fa-check"></i><b>7.2.4</b> 參考文件與資源</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="eda.html"><a href="eda.html#dplyr"><i class="fa fa-check"></i><b>7.3</b> dplyr</a><ul>
<li class="chapter" data-level="7.3.1" data-path="eda.html"><a href="eda.html#select"><i class="fa fa-check"></i><b>7.3.1</b> select()</a></li>
<li class="chapter" data-level="7.3.2" data-path="eda.html"><a href="eda.html#filter"><i class="fa fa-check"></i><b>7.3.2</b> filter()</a></li>
<li class="chapter" data-level="7.3.3" data-path="eda.html"><a href="eda.html#mutate"><i class="fa fa-check"></i><b>7.3.3</b> mutate()</a></li>
<li class="chapter" data-level="7.3.4" data-path="eda.html"><a href="eda.html#summarise"><i class="fa fa-check"></i><b>7.3.4</b> summarise()</a></li>
<li class="chapter" data-level="7.3.5" data-path="eda.html"><a href="eda.html#group_by"><i class="fa fa-check"></i><b>7.3.5</b> group_by()</a></li>
<li class="chapter" data-level="7.3.6" data-path="eda.html"><a href="eda.html#arrange"><i class="fa fa-check"></i><b>7.3.6</b> arrange()</a></li>
<li class="chapter" data-level="7.3.7" data-path="eda.html"><a href="eda.html#rename"><i class="fa fa-check"></i><b>7.3.7</b> rename()</a></li>
<li class="chapter" data-level="7.3.8" data-path="eda.html"><a href="eda.html#-1"><i class="fa fa-check"></i><b>7.3.8</b> 參考文件與資源</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="vis.html"><a href="vis.html"><i class="fa fa-check"></i><b>8</b> 資料視覺化</a><ul>
<li class="chapter" data-level="8.1" data-path="vis.html"><a href="vis.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 資料視覺化的目的</a></li>
<li class="chapter" data-level="8.2" data-path="vis.html"><a href="vis.html#ggplot2"><i class="fa fa-check"></i><b>8.2</b> ggplot2簡介</a><ul>
<li class="chapter" data-level="8.2.1" data-path="vis.html"><a href="vis.html#qplot"><i class="fa fa-check"></i><b>8.2.1</b> qplot()</a></li>
<li class="chapter" data-level="8.2.2" data-path="vis.html"><a href="vis.html#ggplot"><i class="fa fa-check"></i><b>8.2.2</b> ggplot()</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="vis.html"><a href="vis.html#ggplot2"><i class="fa fa-check"></i><b>8.3</b> ggplot2+地圖</a><ul>
<li class="chapter" data-level="8.3.1" data-path="vis.html"><a href="vis.html#choropleth-map"><i class="fa fa-check"></i><b>8.3.1</b> Choropleth map面量圖</a></li>
<li class="chapter" data-level="8.3.2" data-path="vis.html"><a href="vis.html#ggmap"><i class="fa fa-check"></i><b>8.3.2</b> ggmap()</a></li>
<li class="chapter" data-level="8.3.3" data-path="vis.html"><a href="vis.html#density-map"><i class="fa fa-check"></i><b>8.3.3</b> Density Map</a></li>
<li class="chapter" data-level="8.3.4" data-path="eda.html"><a href="eda.html#-1"><i class="fa fa-check"></i><b>8.3.4</b> 參考資料</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="vis.html"><a href="vis.html#taiwan"><i class="fa fa-check"></i><b>8.4</b> Taiwan的面量圖</a><ul>
<li class="chapter" data-level="8.4.1" data-path="vis.html"><a href="vis.html#ggmap"><i class="fa fa-check"></i><b>8.4.1</b> ggmap+面量圖</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="vis.html"><a href="vis.html#heatmap"><i class="fa fa-check"></i><b>8.5</b> Heatmap</a></li>
<li class="chapter" data-level="8.6" data-path="vis.html"><a href="vis.html#treemap"><i class="fa fa-check"></i><b>8.6</b> Treemap</a></li>
<li class="chapter" data-level="8.7" data-path="vis.html"><a href="vis.html#-2"><i class="fa fa-check"></i><b>8.7</b> 參考文件與資源</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="InteractiveGraphics.html"><a href="InteractiveGraphics.html"><i class="fa fa-check"></i><b>9</b> 互動式資料呈現</a><ul>
<li class="chapter" data-level="9.1" data-path="InteractiveGraphics.html"><a href="InteractiveGraphics.html#ggvis"><i class="fa fa-check"></i><b>9.1</b> ggvis</a></li>
<li class="chapter" data-level="9.2" data-path="InteractiveGraphics.html"><a href="InteractiveGraphics.html#googlevis"><i class="fa fa-check"></i><b>9.2</b> googleVis</a></li>
<li class="chapter" data-level="9.3" data-path="InteractiveGraphics.html"><a href="InteractiveGraphics.html#plot.ly"><i class="fa fa-check"></i><b>9.3</b> Plot.ly</a></li>
<li class="chapter" data-level="9.4" data-path="InteractiveGraphics.html"><a href="InteractiveGraphics.html#shiny"><i class="fa fa-check"></i><b>9.4</b> Shiny簡介</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="datamining.html"><a href="datamining.html"><i class="fa fa-check"></i><b>10</b> 資料探勘</a><ul>
<li class="chapter" data-level="10.1" data-path="datamining.html"><a href="datamining.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 什麼是資料探勘</a></li>
<li class="chapter" data-level="10.2" data-path="datamining.html"><a href="datamining.html#regression-"><i class="fa fa-check"></i><b>10.2</b> Regression 迴歸</a><ul>
<li class="chapter" data-level="10.2.1" data-path="datamining.html"><a href="datamining.html#linear-regression-"><i class="fa fa-check"></i><b>10.2.1</b> Linear Regression 線性迴歸</a></li>
<li class="chapter" data-level="10.2.2" data-path="datamining.html"><a href="datamining.html#logistic-regression-"><i class="fa fa-check"></i><b>10.2.2</b> Logistic Regression 羅吉斯迴歸</a></li>
<li class="chapter" data-level="10.2.3" data-path="datamining.html"><a href="datamining.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 最佳模型篩選</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="datamining.html"><a href="datamining.html#decision-trees-"><i class="fa fa-check"></i><b>10.3</b> Decision Trees 決策樹</a></li>
<li class="chapter" data-level="10.4" data-path="datamining.html"><a href="datamining.html#clustering-"><i class="fa fa-check"></i><b>10.4</b> Clustering 分群</a><ul>
<li class="chapter" data-level="10.4.1" data-path="datamining.html"><a href="datamining.html#hierarchical-clustering-"><i class="fa fa-check"></i><b>10.4.1</b> Hierarchical clustering 階層式分群</a></li>
<li class="chapter" data-level="10.4.2" data-path="datamining.html"><a href="datamining.html#k-means-clustering"><i class="fa fa-check"></i><b>10.4.2</b> K-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="datamining.html"><a href="datamining.html#association-rules-"><i class="fa fa-check"></i><b>10.5</b> Association Rules 關聯式規則</a></li>
<li class="chapter" data-level="10.6" data-path="datamining.html"><a href="datamining.html#open-source-packages"><i class="fa fa-check"></i><b>10.6</b> Open Source Packages</a><ul>
<li class="chapter" data-level="10.6.1" data-path="datamining.html"><a href="datamining.html#prophet"><i class="fa fa-check"></i><b>10.6.1</b> Prophet</a></li>
<li class="chapter" data-level="10.6.2" data-path="datamining.html"><a href="datamining.html#tensorflow"><i class="fa fa-check"></i><b>10.6.2</b> TensorFlow</a></li>
<li class="chapter" data-level="10.6.3" data-path="datamining.html"><a href="datamining.html#mxnet"><i class="fa fa-check"></i><b>10.6.3</b> MXNet</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="datamining.html"><a href="datamining.html#section-10.7"><i class="fa fa-check"></i><b>10.7</b> 模型驗證</a><ul>
<li class="chapter" data-level="10.7.1" data-path="datamining.html"><a href="datamining.html#regression-"><i class="fa fa-check"></i><b>10.7.1</b> Regression 迴歸驗證</a></li>
<li class="chapter" data-level="10.7.2" data-path="datamining.html"><a href="datamining.html#logistic-regression-"><i class="fa fa-check"></i><b>10.7.2</b> Logistic Regression 邏輯迴歸驗證</a></li>
<li class="chapter" data-level="10.7.3" data-path="datamining.html"><a href="datamining.html#decision-trees-"><i class="fa fa-check"></i><b>10.7.3</b> Decision Trees 決策樹驗證</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="datamining.html"><a href="datamining.html#case-study"><i class="fa fa-check"></i><b>10.8</b> Case Study</a></li>
<li class="chapter" data-level="10.9" data-path="vis.html"><a href="vis.html#-2"><i class="fa fa-check"></i><b>10.9</b> 參考資料</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="big.html"><a href="big.html"><i class="fa fa-check"></i><b>11</b> 從小數據到大數據分析</a><ul>
<li class="chapter" data-level="11.1" data-path="big.html"><a href="big.html#r-hadoop"><i class="fa fa-check"></i><b>11.1</b> R + Hadoop</a></li>
<li class="chapter" data-level="11.2" data-path="big.html"><a href="big.html#rhadoop-cloudera"><i class="fa fa-check"></i><b>11.2</b> RHadoop安裝測試流程 (Cloudera)</a><ul>
<li class="chapter" data-level="11.2.1" data-path="big.html"><a href="big.html#section-11.2.1"><i class="fa fa-check"></i><b>11.2.1</b> 系統/軟體版本資訊</a></li>
<li class="chapter" data-level="11.2.2" data-path="big.html"><a href="big.html#-3"><i class="fa fa-check"></i><b>11.2.2</b> 參考資料</a></li>
<li class="chapter" data-level="11.2.3" data-path="big.html"><a href="big.html#section-11.2.3"><i class="fa fa-check"></i><b>11.2.3</b> 安裝步驟</a></li>
<li class="chapter" data-level="11.2.4" data-path="big.html"><a href="big.html#section-11.2.4"><i class="fa fa-check"></i><b>11.2.4</b> 測試前，先解決權限問題</a></li>
<li class="chapter" data-level="11.2.5" data-path="big.html"><a href="big.html#section-11.2.5"><i class="fa fa-check"></i><b>11.2.5</b> 測試</a></li>
<li class="chapter" data-level="11.2.6" data-path="big.html"><a href="big.html#rstudio-server"><i class="fa fa-check"></i><b>11.2.6</b> 安裝RStudio Server</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="big.html"><a href="big.html#rhadoop-mapreduce-easy-word-count"><i class="fa fa-check"></i><b>11.3</b> RHadoop MapReduce: easy word count</a></li>
<li class="chapter" data-level="11.4" data-path="big.html"><a href="big.html#r-spark"><i class="fa fa-check"></i><b>11.4</b> R + Spark</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="install.html"><a href="install.html"><i class="fa fa-check"></i><b>12</b> 軟體安裝介紹</a><ul>
<li class="chapter" data-level="12.1" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>12.1</b> R安裝</a></li>
<li class="chapter" data-level="12.2" data-path="install.html"><a href="install.html#rstudio"><i class="fa fa-check"></i><b>12.2</b> RStudio安裝</a></li>
<li class="chapter" data-level="12.3" data-path="install.html"><a href="install.html#rstudio"><i class="fa fa-check"></i><b>12.3</b> RStudio使用簡介</a><ul>
<li class="chapter" data-level="12.3.1" data-path="install.html"><a href="install.html#section-12.3.1"><i class="fa fa-check"></i><b>12.3.1</b> 專案</a></li>
<li class="chapter" data-level="12.3.2" data-path="install.html"><a href="install.html#rstudio"><i class="fa fa-check"></i><b>12.3.2</b> RStudio介面</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>作者資訊</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">資料科學與R語言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="datamining" class="section level1">
<h1><span class="header-section-number">10</span> 資料探勘</h1>
<p><strong>撰寫中</strong></p>
<div id="section-10.1" class="section level2">
<h2><span class="header-section-number">10.1</span> 什麼是資料探勘</h2>
<p><strong>資料探勘（Data mining）</strong>是用人工智慧、機器學習、統計學的交叉方法，在相對較大型的資料集中發現模式的計算過程。使用資料探勘技術可以建立從<strong>輸入資料</strong>學習新資訊，變成智慧的<strong>演算法</strong>或<strong>資料模式</strong>，用來<strong>預測事件</strong>或<strong>協助決策</strong>。所以，當資料太<code>少</code>或<code>太髒</code>的時候，資料探勘的效力會被影響。</p>
<p>資料探勘要派上用場，必須有以下條件：</p>
<ul>
<li>有一些模式/模型可<code>學</code></li>
<li>很難定義這些模式/模型</li>
<li>有資料可<code>學</code>這些模式/模型</li>
</ul>
<p>資料探勘的應用範例如下：</p>
<ul>
<li>天氣預測</li>
<li>搜尋建議、購物建議</li>
<li>股市預測</li>
<li>臉部辨識、指紋辨識</li>
<li>垃圾郵件標記</li>
<li>尿布啤酒</li>
</ul>
<p>資料探勘可分為<strong>監督式</strong>學習與<strong>非監督式</strong>學習，監督式學習的特點是訓練資料中有<strong>正確答案</strong>，由輸入物件和預期輸出所組成，而演算法可以由訓練資料中學到或建立一個模式，並依此模式推測新的實例；非監督式學習則不用提供<strong>正確答案</strong>，也就是不需要人力來輸入標籤，單純利用訓練資料的特性，將資料分群分組。</p>
<p>此兩種學習可解決不同的問題，條列如下：</p>
<ul>
<li>Supervised learning 監督式學習
<ul>
<li>Regression 迴歸：真實的’值’（股票、氣溫）</li>
<li>Classification 分類：分兩類（P/N, Yes/No, M/F, Sick/Not sick）/分多類 (A/B/C/D)</li>
</ul></li>
<li>Unsupervised learning 非監督式學習
<ul>
<li>Clustering 分群</li>
<li>Association Rules 關聯式規則</li>
</ul></li>
</ul>
<p>在<strong>監督式</strong>學習中常見的資料探勘演算法如下：</p>
<ul>
<li>Linear Regression 線性迴歸</li>
<li>Logistic Regression 羅吉斯迴歸、邏輯迴歸</li>
<li>Support Vector Machines 支持向量機</li>
<li>Decision Trees 決策樹</li>
<li>K-Nearest Neighbor</li>
<li>Neural Networks 神經網路</li>
<li>Deep Learning 深度學習</li>
</ul>
<p>在<strong>非監督式</strong>學習中常見的資料探勘演算法如下：</p>
<ul>
<li>Hierarchical clustering 階層式分群</li>
<li>K-means clustering</li>
<li>Neural Networks 神經網路</li>
<li>Deep Learning 深度學習</li>
</ul>
<p>以下介紹在R中使用各類演算法的方法</p>
</div>
<div id="regression-" class="section level2">
<h2><span class="header-section-number">10.2</span> Regression 迴歸</h2>
<p>Regression Analysis 迴歸分析主要用在了解兩個或多個變數間<code>是否相關</code>、<code>相關方向與強度</code>，並建立<code>數學模型</code>以便觀察特定變數來預測研究者感興趣的變數，常見的迴歸分析演算法包括：</p>
<ul>
<li>Linear Regression 線性迴歸</li>
<li>Logistic Regression 羅吉斯迴歸、邏輯迴歸</li>
</ul>
<div id="linear-regression-" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Linear Regression 線性迴歸</h3>
<p>首先，嘗試將Linear Regression 線性迴歸用在NBA的資料看看，做NBA<code>得分</code>與<code>上場分鐘數</code>的線性迴歸觀察</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#讀入SportsAnalytics package</span>
<span class="kw">library</span>(SportsAnalytics)
<span class="co">#擷取2015-2016年球季球員資料</span>
NBA1516&lt;-<span class="kw">fetch_NBAPlayerStatistics</span>(<span class="st">&quot;15-16&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(NBA1516,<span class="kw">aes</span>(<span class="dt">x=</span>TotalMinutesPlayed,<span class="dt">y=</span>TotalPoints))+
<span class="st">    </span><span class="kw">geom_point</span>()+<span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/linear2-1.png" width="672" /></p>
<p>在R中，最基本的簡單線性迴歸分析為<code>lm()</code>，使用方法為<code>lm(formula,data=資料名稱)</code>，搭配formula使用，formula的撰寫方法為：依變項~自變項1＋自變項2＋….</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(TotalPoints~TotalMinutesPlayed,<span class="dt">data =</span>NBA1516)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = TotalPoints ~ TotalMinutesPlayed, data = NBA1516)
## 
## Coefficients:
##        (Intercept)  TotalMinutesPlayed  
##            -85.907               0.493</code></pre>
<p>由此可知總得分數TotalPoints等於<code>0.4931</code> * 總出場分鐘數 <code>-85.9071</code></p>
<p>TotalPoints = <code>0.4931</code> * TotalMinutesPlayed <code>-85.9071</code></p>
<p>更被廣泛使用的是廣義線性迴歸模型generalized linear models (glm)，函數為<code>glm()</code>，使用方法與<code>lm()</code>類似，包括了線性迴歸模型和邏輯迴歸模型。 如果需要修改預設模型，可設定family參數：</p>
<pre><code>- `family=&quot;gaussian&quot;` 線性模型模型
- `family=&quot;binomial&quot;` 邏輯迴歸模型
- `family=&quot;poisson&quot;` 卜瓦松迴歸模型</code></pre>
<p>Gaussian distribution高斯函數是<code>常態分布</code>的密度函數</p>
<p>Binomial distribution二項分布是<code>n個獨立的是/非試驗中成功的次數</code>的離散機率分布</p>
<p>Poisson distribution<code>次數</code>分佈：</p>
<ul>
<li>某一服務設施在一定時間內受到的服務請求的次數</li>
<li>公車站的候客人數</li>
<li>機器故障數</li>
<li>自然災害發生的次數</li>
<li>DNA序列的變異數…..</li>
</ul>
<p>以下為使用多變量線性迴歸來分析<code>得分</code>與<code>上場分鐘數</code>和<code>兩分球出手數</code>的關係範例</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># e+01: 10^1 / e-04: 10^(-4)</span>
<span class="kw">glm</span>(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted,
    <span class="dt">data =</span>NBA1516)</code></pre></div>
<pre><code>## 
## Call:  glm(formula = TotalPoints ~ TotalMinutesPlayed + FieldGoalsAttempted, 
##     data = NBA1516)
## 
## Coefficients:
##         (Intercept)   TotalMinutesPlayed  FieldGoalsAttempted  
##           -1.80e+01            -2.35e-04             1.26e+00  
## 
## Degrees of Freedom: 475 Total (i.e. Null);  473 Residual
## Null Deviance:       9.9e+07 
## Residual Deviance: 2160000   AIC: 5370</code></pre>
<p>由此可知總得分數等於<code>-0.0002347</code> * 總出場分鐘數 + <code>1.255794</code> * 兩分球出手數 <code>-17.99</code> TotalPoints = <code>-0.0002347</code> * TotalMinutesPlayed + <code>1.255794</code> * FieldGoalsAttempted <code>-17.99</code></p>
<p>如需使用多變量線性迴歸來分析<code>得分</code>與<code>上場分鐘數</code>和<code>兩分球出手數</code>和<code>守備位置</code>的關係，可修改formula</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glm</span>(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+Position,
    <span class="dt">data =</span>NBA1516)</code></pre></div>
<pre><code>## 
## Call:  glm(formula = TotalPoints ~ TotalMinutesPlayed + FieldGoalsAttempted + 
##     Position, data = NBA1516)
## 
## Coefficients:
##         (Intercept)   TotalMinutesPlayed  FieldGoalsAttempted  
##            22.85222             -0.00654              1.27572  
##          PositionPF           PositionPG           PositionSF  
##           -39.41633            -65.03465            -38.52230  
##          PositionSG  
##           -52.17514  
## 
## Degrees of Freedom: 474 Total (i.e. Null);  468 Residual
##   (1 observation deleted due to missingness)
## Null Deviance:       9.9e+07 
## Residual Deviance: 2e+06     AIC: 5320</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># e+01: 10^1 / e-04: 10^(-4)</span></code></pre></div>
<p>由此可知總得分數TotalPoints和<code>上場分鐘數</code>和<code>兩分球出手數</code>和<code>守備位置</code>的關係為： TotalPoints = <code>-0.0065</code> * TotalMinutesPlayed + <code>1.28</code> <em>FieldGoalsAttempted <code>+22.85</code> + <code>22.85</code> </em> PositionPF + <code>-65.03</code> * PositionPG + <code>-38.52</code> * PositionSF + <code>-52.18</code> * PositionSG</p>
<p>由上述結果可發現，<code>守備位置</code>的變項被轉為<strong>虛擬變項 Dummy Variable</strong>：PositionPF、PositionPG、PositionSF、PositionSG，如果是控球後衛（PG），會得到：</p>
<ul>
<li>PositionPF=0</li>
<li>PositionPG=1</li>
<li>PositionSF=0</li>
<li>PositionSG=0</li>
</ul>
<p>可能有人會問，那中鋒去哪了？其實中鋒被當作基準項，也就是當守備位置是中鋒(C)時，會得到：</p>
<ul>
<li>PositionPF=0</li>
<li>PositionPG=0</li>
<li>PositionSF=0</li>
<li>PositionSG=0</li>
</ul>
<p>總結以上，多變量線性迴歸分析有下列特色：</p>
<ul>
<li>假設：各變數相互獨立！</li>
<li>若自變項X是類別變項，需要建立<code>虛擬變項</code></li>
<li>在R裡，<code>類別變項</code>請記得轉成factor，R會自動建立<code>虛擬變項</code></li>
<li>用在<code>依變數為連續變數</code>，<code>自變數為連續變數或虛擬變數</code>的場合</li>
</ul>
</div>
<div id="logistic-regression-" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Logistic Regression 羅吉斯迴歸</h3>
<p>Logistic Regression 羅吉斯迴歸常用在<code>依變數為二元變數（非0即1）</code>的場合，如： - 生病/沒生病 - 錄取/不錄取 - <code>family=&quot;binomial&quot;</code> 邏輯迴歸模型</p>
<p>以分數資料為例，分析為什麼錄取/不錄取？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydata &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/binary.csv&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GRE:某考試成績, GPA:在校平均成績, rank:學校聲望</span>
<span class="kw">head</span>(mydata)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">admit</th>
<th align="right">gre</th>
<th align="right">gpa</th>
<th align="right">rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">380</td>
<td align="right">3.6</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">660</td>
<td align="right">3.7</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">800</td>
<td align="right">4.0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">640</td>
<td align="right">3.2</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">520</td>
<td align="right">2.9</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">760</td>
<td align="right">3.0</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydata$rank &lt;-<span class="st"> </span><span class="kw">factor</span>(mydata$rank)
mylogit &lt;-<span class="st"> </span><span class="kw">glm</span>(admit ~<span class="st"> </span>gre +<span class="st"> </span>gpa +<span class="st"> </span>rank,
               <span class="dt">data =</span> mydata, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
sum&lt;-<span class="kw">summary</span>(mylogit)
sum$coefficients</code></pre></div>
<pre><code>##             Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept)  -3.9900     1.1400    -3.5  0.00047
## gre           0.0023     0.0011     2.1  0.03847
## gpa           0.8040     0.3318     2.4  0.01539
## rank2        -0.6754     0.3165    -2.1  0.03283
## rank3        -1.3402     0.3453    -3.9  0.00010
## rank4        -1.5515     0.4178    -3.7  0.00020</code></pre>
</div>
<div id="section-10.2.3" class="section level3">
<h3><span class="header-section-number">10.2.3</span> 最佳模型篩選</h3>
<p>到底該用哪個模型來預測，會得到最準確的結果？在迴歸模型中，常用的判斷準則包括：</p>
<ul>
<li>Akaike’s Information Criterion (AIC)</li>
<li>Bayesian Information Criterion (BIC)</li>
</ul>
<p>AIC和BIC都是數值越小越好，以下建立三個模型，並比較其AIC，</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OneVar&lt;-<span class="kw">glm</span>(TotalPoints~TotalMinutesPlayed,<span class="dt">data =</span>NBA1516)
TwoVar&lt;-<span class="kw">glm</span>(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted,
            <span class="dt">data =</span>NBA1516)
ThreeVar&lt;-<span class="kw">glm</span>(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+Position,
              <span class="dt">data =</span>NBA1516)
<span class="kw">c</span>(OneVar$aic,TwoVar$aic,ThreeVar$aic)</code></pre></div>
<pre><code>## [1] 6339 5367 5322</code></pre>
<p>在建立迴歸模型時，常會遇到到底該放多少參數？所有參數都有用嗎？這類的問題，我們可以藉由觀察coefficients來判斷參數在模型中的“實用程度”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sum2&lt;-<span class="kw">summary</span>(TwoVar)
sum2$coefficients</code></pre></div>
<pre><code>##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)         -1.8e+01     5.6598  -3.178  1.6e-03
## TotalMinutesPlayed  -2.3e-04     0.0095  -0.025  9.8e-01
## FieldGoalsAttempted  1.3e+00     0.0222  56.467 2.5e-212</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sum3&lt;-<span class="kw">summary</span>(ThreeVar)
sum3$coefficients</code></pre></div>
<pre><code>##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)          22.8522     9.0147    2.53  1.2e-02
## TotalMinutesPlayed   -0.0065     0.0092   -0.71  4.8e-01
## FieldGoalsAttempted   1.2757     0.0216   58.93 1.1e-218
## PositionPF          -39.4163     9.9365   -3.97  8.4e-05
## PositionPG          -65.0346    10.2693   -6.33  5.6e-10
## PositionSF          -38.5223    10.4882   -3.67  2.7e-04
## PositionSG          -52.1751     9.9853   -5.23  2.6e-07</code></pre>
</div>
</div>
<div id="decision-trees-" class="section level2">
<h2><span class="header-section-number">10.3</span> Decision Trees 決策樹</h2>
<p>決策樹是在<code>樹狀目錄</code>中建立一系列分割，以建立模型。這些分割會表示成<code>「節點」(Node)</code>。每次發現輸入資料行與可預測資料行有明顯地相互關聯時，此演算法就會在模型中加入一個<code>節點</code>。演算法決定分岔的方式不同，視它預測連續資料行或分隔資料行而定。</p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-189-1.png" width="672" /></p>
<p>以下介紹常見的Classification And Regression Tree (CART)，使用前須先安裝<code>rpart</code> packages <span class="citation">(Therneau, Atkinson, and Ripley <a href="#ref-R-rpart">2015</a>)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;rpart&quot;</span>)</code></pre></div>
<p>以前述NBA資料為例，嘗試用用籃板/三分/助攻/抄截數據來判斷守備位置，建立決策樹的函數為<code>rpart()</code>，使用方式為<code>rpart(formula, data)</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart)
DT&lt;-<span class="kw">rpart</span>(Position~Blocks+ThreesMade+Assists+Steals,<span class="dt">data=</span>NBA1516)
DT</code></pre></div>
<pre><code>## n=475 (1 observation deleted due to missingness)
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##   1) root 475 360 PF (0.15 0.23 0.21 0.18 0.23)  
##     2) ThreesMade&lt; 2.5 132  74 C (0.44 0.35 0.098 0.053 0.061)  
##       4) Blocks&gt;=4.5 89  37 C (0.58 0.38 0.011 0.011 0.011) *
##       5) Blocks&lt; 4.5 43  31 PF (0.14 0.28 0.28 0.14 0.16)  
##        10) Steals&lt; 2.5 29  19 PF (0.17 0.34 0.14 0.21 0.14) *
##        11) Steals&gt;=2.5 14   6 PG (0.071 0.14 0.57 0 0.21) *
##     3) ThreesMade&gt;=2.5 343 240 SG (0.035 0.19 0.25 0.23 0.29)  
##       6) Assists&gt;=1.7e+02 96  39 PG (0.031 0.052 0.59 0.15 0.18) *
##       7) Assists&lt; 1.7e+02 247 160 SG (0.036 0.24 0.12 0.26 0.34)  
##        14) Blocks&gt;=20 80  42 PF (0.062 0.48 0 0.26 0.2)  
##          28) Steals&lt; 60 58  21 PF (0.069 0.64 0 0.14 0.16) *
##          29) Steals&gt;=60 22   9 SF (0.045 0.045 0 0.59 0.32) *
##        15) Blocks&lt; 20 167  99 SG (0.024 0.13 0.17 0.26 0.41)  
##          30) Assists&lt; 82 110  68 SG (0.027 0.18 0.091 0.32 0.38)  
##            60) Blocks&gt;=4.5 63  39 SF (0.032 0.29 0.016 0.38 0.29)  
##             120) ThreesMade&lt; 14 19   9 PF (0.11 0.53 0 0.26 0.11) *
##             121) ThreesMade&gt;=14 44  25 SF (0 0.18 0.023 0.43 0.36)  
##               242) Blocks&lt; 9.5 17   7 SF (0 0.18 0.059 0.59 0.18) *
##               243) Blocks&gt;=9.5 27  14 SG (0 0.19 0 0.33 0.48) *
##            61) Blocks&lt; 4.5 47  23 SG (0.021 0.043 0.19 0.23 0.51) *
##          31) Assists&gt;=82 57  31 SG (0.018 0.035 0.33 0.16 0.46)  
##            62) ThreesMade&lt; 37 17   5 PG (0 0.12 0.71 0.059 0.12) *
##            63) ThreesMade&gt;=37 40  16 SG (0.025 0 0.17 0.2 0.6) *</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">4</span>)) <span class="co">#下,左,上,右</span>
<span class="kw">plot</span>(DT)
<span class="kw">text</span>(DT, <span class="dt">use.n=</span>F, <span class="dt">all=</span>F, <span class="dt">cex=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/rpart3-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）</span></code></pre></div>
<p>可以看出預設的<code>plot()</code>畫出來的圖很難看懂，可以改用<code>rpart.plot</code> package <span class="citation">(Milborrow <a href="#ref-R-rpart.plot">2016</a>)</span>裡面的<code>prp()</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;rpart.plot&quot;</span>) <span class="co">#第一次使用前須先安裝</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart.plot)
<span class="kw">prp</span>(DT) </code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/rpart4-1.png" width="672" /></p>
<p>決策樹演算法決定<code>節點</code>的方式如下：</p>
<ul>
<li>Gini impurity</li>
<li>Information gain</li>
<li>Variance reduction</li>
</ul>
<p>細節可參考<a href="https://en.wikipedia.org/wiki/Decision_tree_learning">維基百科</a></p>
</div>
<div id="clustering-" class="section level2">
<h2><span class="header-section-number">10.4</span> Clustering 分群</h2>
<p>Clustering 分群的目的是將相近的觀察值作做分群，分群過程中，可能會遇到以下問題：</p>
<ul>
<li>如何定義相近？</li>
<li>如何分群？</li>
<li>如何視覺化？</li>
<li>如何解釋分群？</li>
</ul>
<div id="hierarchical-clustering-" class="section level3">
<h3><span class="header-section-number">10.4.1</span> Hierarchical clustering 階層式分群</h3>
<ul>
<li>An agglomerative approach
<ul>
<li>Find closest two things</li>
<li>Put them together</li>
<li>Find next closest</li>
</ul></li>
<li>Requires
<ul>
<li>A defined distance</li>
<li>A merging approach</li>
</ul></li>
<li>Produces
<ul>
<li>A tree showing how close things are to each other</li>
</ul></li>
</ul>
<p>如何定義相近？用距離<code>distance</code>的概念來定義相近。</p>
<ul>
<li>Distance or similarity
<ul>
<li>Continuous - euclidean distance</li>
<li>Continuous - correlation similarity</li>
<li>Binary - manhattan distance</li>
</ul></li>
<li>Pick a distance/similarity that makes sense for your problem</li>
</ul>
<p>Example distances - Euclidean</p>
<p><span class="math display">\[\sqrt{(A_1-A_2)^2 + (B_1-B_2)^2 + \ldots + (Z_1-Z_2)^2}\]</span></p>
<p>Example distances - Manhattan</p>
<p><span class="math display">\[|A_1-A_2| + |B_1-B_2| + \ldots + |Z_1-Z_2|\]</span></p>
<p>Merging apporach</p>
<ul>
<li><p>Agglomerative 聚合</p>
<ul>
<li>Single-linkage：取最小值</li>
<li>Complete-linkage：取最大值</li>
<li>Average-linkage：取平均值</li>
</ul></li>
</ul>
<p>Hierarchical clustering - hp vs. mpg <img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-190-1.png" width="768" /></p>
<p>Hierarchical clustering - #1</p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-191-1.png" width="768" /></p>
<p>Hierarchical clustering - #2 <img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-192-1.png" width="768" /></p>
<p>Hierarchical clustering - #3</p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-193-1.png" width="768" /></p>
<p>可用<code>dist()</code>函數計算距離，使用method=“”設定計算距離的依據</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtcars.mxs&lt;-<span class="kw">as.matrix</span>(mtcars)
d&lt;-<span class="kw">dist</span>(mtcars.mxs) <span class="co">#預設為euclidean</span>
<span class="kw">head</span>(d)</code></pre></div>
<pre><code>## [1]   0.62  54.91  98.11 210.34  65.47 241.41</code></pre>
<p><code>dist()</code>函數可用方法包括： “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d&lt;-<span class="kw">dist</span>(mtcars.mxs, <span class="dt">method=</span><span class="st">&quot;manhattan&quot;</span>) <span class="co">#計算manhattan距離</span>
<span class="kw">head</span>(d)</code></pre></div>
<pre><code>## [1]   0.81  79.30 108.80 275.43  84.64 347.96</code></pre>
<p>用<code>hclust</code>函數畫圖，必要參數是各觀察值的距離（可用<code>dist()</code>函數計算）</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">rep</span>(<span class="dv">2</span>,<span class="dv">4</span>),<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
hc&lt;-<span class="kw">hclust</span>(<span class="kw">dist</span>(mtcars.mxs)) <span class="co">#可用method參數設定聚合方法，預設為complete</span>
<span class="kw">plot</span>(hc)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-196-1.png" width="576" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">rep</span>(<span class="dv">2</span>,<span class="dv">4</span>),<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
hc&lt;-<span class="kw">hclust</span>(<span class="kw">dist</span>(mtcars.mxs),<span class="dt">method=</span><span class="st">&quot;average&quot;</span>) <span class="co">#聚合方法為計算平均距離</span>
<span class="kw">plot</span>(hc)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-197-1.png" width="576" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clusterCut &lt;-<span class="st"> </span><span class="kw">cutree</span>(hc, <span class="dt">k=</span><span class="dv">5</span>) <span class="co">#分5群</span>
<span class="kw">sort</span>(clusterCut)</code></pre></div>
<pre><code>##           Mazda RX4       Mazda RX4 Wag          Datsun 710           Merc 240D 
##                   1                   1                   1                   1 
##            Merc 230            Merc 280           Merc 280C            Fiat 128 
##                   1                   1                   1                   1 
##         Honda Civic      Toyota Corolla       Toyota Corona           Fiat X1-9 
##                   1                   1                   1                   1 
##       Porsche 914-2        Lotus Europa        Ferrari Dino          Volvo 142E 
##                   1                   1                   1                   1 
##      Hornet 4 Drive             Valiant          Merc 450SE          Merc 450SL 
##                   2                   2                   2                   2 
##         Merc 450SLC    Dodge Challenger         AMC Javelin   Hornet Sportabout 
##                   2                   2                   2                   3 
##          Duster 360          Camaro Z28    Pontiac Firebird      Ford Pantera L 
##                   3                   3                   3                   3 
##  Cadillac Fleetwood Lincoln Continental   Chrysler Imperial       Maserati Bora 
##                   4                   4                   4                   5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>()+<span class="kw">geom_point</span>(<span class="dt">data=</span>mtcars,
                    <span class="kw">aes</span>(<span class="dt">x=</span>hp,<span class="dt">y=</span>mpg,<span class="dt">color=</span><span class="kw">as.factor</span>(clusterCut)))</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-199-1.png" width="576" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clusterCut &lt;-<span class="st"> </span><span class="kw">cutree</span>(hc,<span class="dt">h =</span><span class="dv">4</span>) <span class="co">#切在高度=4的地方（距離=4）</span>
<span class="kw">sort</span>(clusterCut)</code></pre></div>
<pre><code>##           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive 
##                   1                   1                   2                   3 
##   Hornet Sportabout             Valiant          Duster 360           Merc 240D 
##                   4                   5                   6                   7 
##            Merc 230            Merc 280           Merc 280C          Merc 450SE 
##                   8                   9                   9                  10 
##          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental 
##                  10                  10                  11                  12 
##   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla 
##                  13                  14                  15                  16 
##       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 
##                  17                  18                  19                  20 
##    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa 
##                  21                  22                  23                  24 
##      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E 
##                  25                  26                  27                  28</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">rep</span>(<span class="fl">0.2</span>,<span class="dv">4</span>),<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">heatmap</span>(mtcars.mxs)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-201-1.png" width="576" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">distxy &lt;-<span class="st"> </span><span class="kw">dist</span>(mtcars.mxs)
hClustering &lt;-<span class="st"> </span><span class="kw">hclust</span>(distxy)
<span class="kw">plot</span>(hClustering)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-202-1.png" width="384" /></p>
<p>Hierarchical clustering: summary - 可快速瀏覽觀察值與各欄位的關係</p>
<ul>
<li>分群結果可能被以下參數影響：
<ul>
<li>計算距離的方法</li>
<li>分群依據</li>
<li>更改數值的大小</li>
</ul></li>
<li>可能會遇到的問題：
<ul>
<li>有時會不太清楚要如何切割分群結果</li>
</ul></li>
</ul>
</div>
<div id="k-means-clustering" class="section level3">
<h3><span class="header-section-number">10.4.2</span> K-means clustering</h3>
<ul>
<li>執行步驟
<ul>
<li>指定要分幾群</li>
<li>計算每一群的中心點</li>
<li>將各個物件/觀察值指定給最近的中心點</li>
<li>依照新的分群計算新的中心點</li>
</ul></li>
<li>輸入
<ul>
<li>計算距離的資料（數值）</li>
<li>要分成幾群 # of clusters</li>
<li>預設個群的中間點位置</li>
</ul></li>
<li>產出
<ul>
<li>計算出每’群‘的中心點</li>
<li>指定每個觀察值所在的’群‘</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x&lt;-<span class="kw">scale</span>(mtcars$hp[-<span class="dv">1</span>]);y&lt;-<span class="kw">scale</span>(mtcars$mpg[-<span class="dv">1</span>])
<span class="kw">plot</span>(x,y,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">pch=</span><span class="dv">19</span>,<span class="dt">cex=</span><span class="dv">2</span>)
<span class="kw">text</span>(x<span class="fl">+0.05</span>,y<span class="fl">+0.05</span>,<span class="dt">labels=</span>labelCar)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-203-1.png" width="576" /></p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-204-1.png" width="480" /></p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-205-1.png" width="480" /></p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-206-1.png" width="480" /></p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-207-1.png" width="480" /></p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-208-1.png" width="480" /></p>
<p><code>kmeans()</code></p>
<ul>
<li>Important parameters: <code>x</code>, <code>centers</code>, <code>iter.max</code>, <code>nstart</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataFrame &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x,y)
kmeansObj &lt;-<span class="st"> </span><span class="kw">kmeans</span>(dataFrame,<span class="dt">centers=</span><span class="dv">3</span>)
<span class="kw">names</span>(kmeansObj)</code></pre></div>
<pre><code>## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot;
## [6] &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kmeansObj$cluster</code></pre></div>
<pre><code>##  [1] 1 3 1 1 1 2 3 3 1 1 1 1 1 2 2 2 3 3 3 1 1 1 2 1 3 3 3 2 1 2 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">rep</span>(<span class="fl">0.2</span>,<span class="dv">4</span>))
<span class="kw">plot</span>(x,y,<span class="dt">col=</span>kmeansObj$cluster,<span class="dt">pch=</span><span class="dv">19</span>,<span class="dt">cex=</span><span class="dv">2</span>)
<span class="kw">points</span>(kmeansObj$centers,<span class="dt">col=</span><span class="dv">1</span>:<span class="dv">3</span>,<span class="dt">pch=</span><span class="dv">3</span>,<span class="dt">cex=</span><span class="dv">3</span>,<span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-209-1.png" width="384" /></p>
<p>Heatmaps</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
dataMatrix &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(dataFrame)[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">12</span>),]
kmeansObj &lt;-<span class="st"> </span><span class="kw">kmeans</span>(dataMatrix,<span class="dt">centers=</span><span class="dv">3</span>)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>))
<span class="kw">image</span>(<span class="kw">t</span>(dataMatrix)[,<span class="kw">nrow</span>(dataMatrix):<span class="dv">1</span>],<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>)
<span class="kw">image</span>(<span class="kw">t</span>(dataMatrix)[,<span class="kw">order</span>(kmeansObj$cluster)],<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-210-1.png" width="768" /></p>
<p>K-means注意事項</p>
<ul>
<li>需要決定# of clusters
<ul>
<li>用眼睛/人工/特殊要求選</li>
<li>用 cross validation/information theory選</li>
<li><a href="http://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">Determining the number of clusters</a></li>
</ul></li>
<li>K-means 沒有一定的結果
<ul>
<li>不同的 # of clusters</li>
<li>不同的 # of iterations</li>
</ul></li>
</ul>
<p><code>kmeans()</code>, k=2</p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-211-1.png" width="384" /></p>
<p><code>kmeans()</code>, k=3</p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-212-1.png" width="384" /></p>
<p><code>kmeans()</code>, k=4</p>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-213-1.png" width="384" /></p>
<p>Use sum of squared error (SSE) scree plot to optimize the number of clusters</p>
<p>SSE: The sum of the squared distance between each member of a cluster and its cluster centroid.</p>
<p><a href="http://stackoverflow.com/questions/15376075/cluster-analysis-in-r-determine-the-optimal-number-of-clusters">參考資料</a></p>
<p><img src="Fig/SSE.png" width="500px"></p>
<p>SSE screen plot <code>withinss</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataMatrix &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(dataFrame)[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">12</span>),]
wss &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(dataMatrix)-<span class="dv">1</span>)*<span class="kw">sum</span>(<span class="kw">apply</span>(dataMatrix,<span class="dv">2</span>,var))
for (i in <span class="dv">2</span>:(<span class="kw">nrow</span>(dataMatrix)-<span class="dv">1</span>)) {
    wss[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">kmeans</span>(dataMatrix,<span class="dt">centers=</span>i)$withinss)
}
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co">#下,左,上,右</span>
<span class="kw">plot</span>(<span class="dv">1</span>:(<span class="kw">nrow</span>(dataMatrix)-<span class="dv">1</span>), wss, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-214-1.png" width="768" /></p>
</div>
</div>
<div id="association-rules-" class="section level2">
<h2><span class="header-section-number">10.5</span> Association Rules 關聯式規則</h2>
<p><strong>關聯式規則</strong>用於從大量數據中挖掘出有價值的數據項之間的相關關係，原則為不考慮項目的次序，而僅考慮其組合。著名的<code>購物籃分析 (Market Basket Analysis)</code>即為關聯式規則分析的應用。而<strong>Apriori演算法</strong>是挖掘<code>布林關聯規則</code> (Boolean association rules) 頻繁項集的算法，在R中，可以使用<code>arules</code><span class="citation">(Hahsler et al. <a href="#ref-R-arules">2016</a>)</span> 套件來執行關聯式規則分析。</p>
<p>以下以超市資料為例，使用關聯式規則分析執行購物籃分析。</p>
<p>首先先讀入超市消費資料</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the libraries</span>
if (!<span class="kw">require</span>(<span class="st">&#39;arules&#39;</span>)){
  <span class="kw">install.packages</span>(<span class="st">&quot;arules&quot;</span>);
  <span class="kw">library</span>(arules) <span class="co">#for Apriori演算法</span>
}
if (!<span class="kw">require</span>(<span class="st">&#39;datasets&#39;</span>)){
  <span class="kw">install.packages</span>(<span class="st">&quot;datasets&quot;</span>);
  <span class="kw">library</span>(datasets) <span class="co">#for Groceries data</span>
}
<span class="kw">data</span>(Groceries) <span class="co"># Load the data set</span>
Groceries@data@Dim <span class="co">#169 種商品，9835筆交易資料</span></code></pre></div>
<pre><code>## [1]  169 9835</code></pre>
<p>超市資料的原始樣貌為： <img src="figure/groceries.png" width="778" /></p>
<p>可使用arules套件中的apriori函數來實作apriori演算法</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get the rules</span>
rules &lt;-<span class="st"> </span><span class="kw">apriori</span>(Groceries, <span class="co"># data= Groceries</span>
                 <span class="dt">parameter =</span> <span class="kw">list</span>(<span class="dt">supp =</span> <span class="fl">0.001</span>, <span class="dt">conf =</span> <span class="fl">0.8</span>), <span class="co">#參數最低限度</span>
                 <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">verbose=</span>F)) <span class="co">#不要顯示output</span>
<span class="kw">options</span>(<span class="dt">digits=</span><span class="dv">2</span>) <span class="co"># Only 2 digits</span>
<span class="kw">inspect</span>(rules[<span class="dv">1</span>:<span class="dv">5</span>]) <span class="co"># Show the top 5 rules</span></code></pre></div>
<pre><code>##     lhs                        rhs            support confidence lift
## [1] {liquor,red/blush wine} =&gt; {bottled beer} 0.0019  0.90       11.2
## [2] {curd,cereals}          =&gt; {whole milk}   0.0010  0.91        3.6
## [3] {yogurt,cereals}        =&gt; {whole milk}   0.0017  0.81        3.2
## [4] {butter,jam}            =&gt; {whole milk}   0.0010  0.83        3.3
## [5] {soups,bottled beer}    =&gt; {whole milk}   0.0011  0.92        3.6</code></pre>
<p>根據計算結果，解讀模型的方法如下：</p>
<p>啤酒=&gt;尿布</p>
<ul>
<li><code>Support</code>: 一次交易中，包括規則內的物品的機率。買啤酒同時買尿布的機率。交集</li>
<li><code>Confidence</code>: 包含左邊物品A的交易也會包含右邊物品B的條件機率。在買了啤酒的顧客中，有買尿布的比例。</li>
<li><code>Lift</code>: 規則的信心比期望值高多少。（買了啤酒以後，有買尿布的機率）/（在所有顧客群中買尿布的機率）
<ul>
<li><code>lift</code>=1: items on the left and right are independent.</li>
</ul></li>
</ul>
<p>可用排序功能排序後，列出最有關連（confidence最高）的幾條規則</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rules&lt;-<span class="kw">sort</span>(rules, <span class="dt">by=</span><span class="st">&quot;confidence&quot;</span>, <span class="dt">decreasing=</span><span class="ot">TRUE</span>) <span class="co">#按照confidence排序</span>
<span class="kw">inspect</span>(rules[<span class="dv">1</span>:<span class="dv">5</span>]) <span class="co"># Show the top 5 rules</span></code></pre></div>
<pre><code>##     lhs                     rhs          support confidence lift
## [1] {rice,                                                      
##      sugar}              =&gt; {whole milk}  0.0012          1  3.9
## [2] {canned fish,                                               
##      hygiene articles}   =&gt; {whole milk}  0.0011          1  3.9
## [3] {root vegetables,                                           
##      butter,                                                    
##      rice}               =&gt; {whole milk}  0.0010          1  3.9
## [4] {root vegetables,                                           
##      whipped/sour cream,                                        
##      flour}              =&gt; {whole milk}  0.0017          1  3.9
## [5] {butter,                                                    
##      soft cheese,                                               
##      domestic eggs}      =&gt; {whole milk}  0.0010          1  3.9</code></pre>
<p>特別針對某項商品（右側變數），像是：買了什麼東西的人，會買<code>牛奶</code>呢？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rulesR&lt;-<span class="kw">apriori</span>(<span class="dt">data=</span>Groceries, <span class="dt">parameter=</span><span class="kw">list</span>(<span class="dt">supp=</span><span class="fl">0.001</span>,<span class="dt">conf =</span> <span class="fl">0.08</span>),
        <span class="dt">appearance =</span> <span class="kw">list</span>(<span class="dt">default=</span><span class="st">&quot;lhs&quot;</span>,<span class="dt">rhs=</span><span class="st">&quot;whole milk&quot;</span>), <span class="co">#設定右邊一定要是牛奶</span>
        <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">verbose=</span>F)) <span class="co">#不要顯示output</span>
rulesR&lt;-<span class="kw">sort</span>(rulesR, <span class="dt">decreasing=</span><span class="ot">TRUE</span>,<span class="dt">by=</span><span class="st">&quot;confidence&quot;</span>) <span class="co">#按照confidence排序</span>
<span class="kw">inspect</span>(rulesR[<span class="dv">1</span>:<span class="dv">5</span>]) <span class="co"># Show the top 5 rules</span></code></pre></div>
<pre><code>##     lhs                     rhs          support confidence lift
## [1] {rice,                                                      
##      sugar}              =&gt; {whole milk}  0.0012          1  3.9
## [2] {canned fish,                                               
##      hygiene articles}   =&gt; {whole milk}  0.0011          1  3.9
## [3] {root vegetables,                                           
##      butter,                                                    
##      rice}               =&gt; {whole milk}  0.0010          1  3.9
## [4] {root vegetables,                                           
##      whipped/sour cream,                                        
##      flour}              =&gt; {whole milk}  0.0017          1  3.9
## [5] {butter,                                                    
##      soft cheese,                                               
##      domestic eggs}      =&gt; {whole milk}  0.0010          1  3.9</code></pre>
<p>特別針對某項商品（左側變數），像是：買了<code>牛奶</code>的人，會買什麼呢？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rulesL&lt;-<span class="kw">apriori</span>(<span class="dt">data=</span>Groceries, <span class="dt">parameter=</span><span class="kw">list</span>(<span class="dt">supp=</span><span class="fl">0.001</span>,<span class="dt">conf =</span> <span class="fl">0.15</span>,<span class="dt">minlen=</span><span class="dv">2</span>),
        <span class="dt">appearance =</span> <span class="kw">list</span>(<span class="dt">default=</span><span class="st">&quot;rhs&quot;</span>,<span class="dt">lhs=</span><span class="st">&quot;whole milk&quot;</span>), <span class="co">#設定左邊一定要是牛奶</span>
        <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">verbose=</span>F)) <span class="co">#不要顯示output</span>
rulesL&lt;-<span class="kw">sort</span>(rulesL, <span class="dt">decreasing=</span><span class="ot">TRUE</span>,<span class="dt">by=</span><span class="st">&quot;confidence&quot;</span>) <span class="co">#按照confidence排序</span>
<span class="kw">inspect</span>(rulesL[<span class="dv">1</span>:<span class="dv">5</span>]) <span class="co"># Show the top 5 rules</span></code></pre></div>
<pre><code>##     lhs             rhs                support confidence lift
## [1] {whole milk} =&gt; {other vegetables} 0.075   0.29       1.5 
## [2] {whole milk} =&gt; {rolls/buns}       0.057   0.22       1.2 
## [3] {whole milk} =&gt; {yogurt}           0.056   0.22       1.6 
## [4] {whole milk} =&gt; {root vegetables}  0.049   0.19       1.8 
## [5] {whole milk} =&gt; {tropical fruit}   0.042   0.17       1.6</code></pre>
<p>規則視覺化</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">if (!<span class="kw">require</span>(<span class="st">&#39;arulesViz&#39;</span>)){
  <span class="kw">install.packages</span>(<span class="st">&quot;arulesViz&quot;</span>); 
  <span class="kw">library</span>(arulesViz)
}
<span class="co">#Mac-&gt;http://planspace.org/2013/01/17/fix-r-tcltk-dependency-problem-on-mac/</span>
<span class="kw">plot</span>(rules,<span class="dt">method=</span><span class="st">&quot;graph&quot;</span>,<span class="dt">interactive=</span><span class="ot">TRUE</span>,<span class="dt">shading=</span><span class="ot">NA</span>) <span class="co">#會跑一陣子</span></code></pre></div>
<p><img src="figure/arulesViz.png" width="531" /> <img src="figure/arulesVizBig.png" width="194" /></p>
</div>
<div id="open-source-packages" class="section level2">
<h2><span class="header-section-number">10.6</span> Open Source Packages</h2>
<div id="prophet" class="section level3">
<h3><span class="header-section-number">10.6.1</span> Prophet</h3>
<p>Prophet 是 Facebook在2017年開放出來的時序性預測演算法，用來預測各類資料的時序變化，像是顧客造訪數、溫度、疾病發生率等等，以下是Prophet for R的安裝使用範例</p>
<ul>
<li>C/C++ Tool</li>
<li><a href="https://cran.r-project.org/bin/windows/Rtools/">R Tools</a> on Windows</li>
<li><a href="http://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/">Command Line Tools</a> on OS X</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&#39;prophet&#39;</span>)</code></pre></div>
<p><a href="https://facebookincubator.github.io/prophet/docs/quick_start.html#r-api">R API</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(prophet)
<span class="kw">library</span>(dplyr)
df &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;https://raw.githubusercontent.com/facebookincubator/prophet/master/examples/example_wp_peyton_manning.csv&#39;</span>) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">log</span>(y))
m &lt;-<span class="st"> </span><span class="kw">prophet</span>(df)
future &lt;-<span class="st"> </span><span class="kw">make_future_dataframe</span>(m, <span class="dt">periods =</span> <span class="dv">365</span>)
<span class="kw">tail</span>(future)
forecast &lt;-<span class="st"> </span><span class="kw">predict</span>(m, future)
<span class="kw">tail</span>(forecast[<span class="kw">c</span>(<span class="st">&#39;ds&#39;</span>, <span class="st">&#39;yhat&#39;</span>, <span class="st">&#39;yhat_lower&#39;</span>, <span class="st">&#39;yhat_upper&#39;</span>)])
<span class="kw">plot</span>(m, forecast)
<span class="kw">prophet_plot_components</span>(m, forecast)</code></pre></div>
<p><a href="https://facebookincubator.github.io/prophet/">Prophet官網</a></p>
</div>
<div id="tensorflow" class="section level3">
<h3><span class="header-section-number">10.6.2</span> TensorFlow</h3>
<ul>
<li>Python 3.5.3 <strong>64 bit</strong> <a href="https://www.python.org/downloads/release/python-353/">網站</a></li>
<li>Windows x86-64 executable installer</li>
<li>TensorFlow 1.0.1 <a href="https://www.tensorflow.org/install/">網站</a></li>
<li>pip3 install –upgrade tensorflow</li>
<li>pip3 install –upgrade tensorflow-gpu</li>
<li>C/C++ Tool</li>
<li><a href="https://cran.r-project.org/bin/windows/Rtools/">R Tools</a> on Windows</li>
<li><a href="http://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/">Command Line Tools</a> on OS X</li>
<li>tensorflow package for R <a href="https://rstudio.github.io/tensorflow/index.html">網站</a></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools::<span class="kw">install_github</span>(<span class="st">&quot;rstudio/tensorflow&quot;</span>)</code></pre></div>
<p>TensorFlow for R</p>
<ul>
<li>Locating TensorFlow (optional)</li>
<li>Hello World</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tensorflow)
sess =<span class="st"> </span>tf$<span class="kw">Session</span>()
hello &lt;-<span class="st"> </span>tf$<span class="kw">constant</span>(<span class="st">&#39;Hello, TensorFlow!&#39;</span>)
sess$<span class="kw">run</span>(hello)</code></pre></div>
</div>
<div id="mxnet" class="section level3">
<h3><span class="header-section-number">10.6.3</span> MXNet</h3>
<p>Amazon <a href="http://mxnet.io/get_started/windows_setup.html#install-mxnet-for-r">Install MXNet for R</a> MXNet for R <a href="http://mxnet.io/tutorials/index.html#r">Tutorials</a></p>
<p>MXNet for R</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;drat&quot;</span>, <span class="dt">repos=</span><span class="st">&quot;https://cran.rstudio.com&quot;</span>)
drat:::<span class="kw">addRepo</span>(<span class="st">&quot;dmlc&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;mxnet&quot;</span>)</code></pre></div>
</div>
</div>
<div id="section-10.7" class="section level2">
<h2><span class="header-section-number">10.7</span> 模型驗證</h2>
<p>在完成模型訓練後，為了驗證模型訓練的好不好，需要用一組<strong>獨立</strong>的測試資料，來做模型的驗證。所以，在訓練模型前，必須特別留意是否有保留一份<strong>獨立的資料</strong>，並確保在訓練模型時都不用到此獨立資料集。因此，資料集可分為以下兩種：</p>
<ul>
<li><strong>訓練組</strong> Training set, Development set: 讓演算法<code>學</code>到<code>知識</code></li>
<li><strong>測試組</strong> Test set, Validation set: 驗證<code>學</code>的怎麼樣</li>
</ul>
<p>Training set和Test set通常會比例分配，如2/3的資料設為<code>Training set</code>，剩下的1/3做驗證<code>Test set</code>。以下圖的監督式學習流程圖為例，可以注意到綠色箭頭的資料集在訓練過程中從未被使用。</p>
<p><img src="figure/SupervisedLearning.png" width="450" /></p>
<div id="regression-" class="section level3">
<h3><span class="header-section-number">10.7.1</span> Regression 迴歸驗證</h3>
<p>以NBA資料為例，首先先將資料讀入</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#讀入SportsAnalytics package</span>
if (!<span class="kw">require</span>(<span class="st">&#39;SportsAnalytics&#39;</span>)){
    <span class="kw">install.packages</span>(<span class="st">&quot;SportsAnalytics&quot;</span>)
    <span class="kw">library</span>(SportsAnalytics)
}
<span class="co">#擷取2015-2016年球季球員資料</span>
NBA1516&lt;-<span class="kw">fetch_NBAPlayerStatistics</span>(<span class="st">&quot;15-16&quot;</span>)
NBA1516&lt;-NBA1516[<span class="kw">complete.cases</span>(NBA1516),]</code></pre></div>
<ul>
<li>以Training set來<code>選看起來最好的模型</code></li>
<li>用Test set來<code>驗證模型是不是真的很好</code></li>
<li>想像…..訓練出來題庫答得好的學生，寫到新題目不一定會寫！？</li>
<li>訓練模型時，只能看Training set，用Training set來選一個最好的模型</li>
<li>訓練模型時，不能偷看Test set，才是真正的驗證</li>
</ul>
<p>為分出訓練組與測試組，需使用隨機抽樣的方式</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">10</span>,<span class="dv">3</span>) <span class="co"># 從1到10，隨機取三個數字</span></code></pre></div>
<pre><code>## [1] 6 3 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(NBA1516),<span class="kw">nrow</span>(NBA1516)/<span class="dv">3</span>) <span class="co">#從第一行到最後一行，隨機取1/3行數</span></code></pre></div>
<pre><code>##   [1]  64 155  74  62 206  19 335  48 444  57 103 424 438 129 466 367 342 420
##  [19] 455 430 222 462 114 228 225 144 433 285 461 189 407 208 403 265 279 383
##  [37] 221 431 142 210 156 273 322 245 423 249 446  98  36 363 100 419 255 422
##  [55] 159 234 180 241 181  94 427 264 179  30 330 134 310 239 289 174 140 307
##  [73] 171 226  47 122 192 138 408  31 378   9 331 248 400 290 456 386  50 341
##  [91] 312 316 320 280 375 243 251 200 120 445 198 274 115 151  76 365 209 104
## [109]  68 278 207 340 232 254 173 404 152  12  93 377 468 177 284 119 413 406
## [127] 441 381  38 382 196 473 258 106 167 337 450  83 344 426 329 160 343 191
## [145] 440 263 175 345  87  92  22 183  85   2 190 388 270  10</code></pre>
<p>使用上述方法，選出1/3的元素位置，把NBA的資料分成Training 和 Test set</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NBA1516$Test&lt;-F <span class="co">#新增一個參數紀錄分組</span>
<span class="co">#隨機取1/3當Test set</span>
NBA1516[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(NBA1516),<span class="kw">nrow</span>(NBA1516)/<span class="dv">3</span>),]$Test&lt;-T
<span class="co"># Training set : Test set球員數</span>
<span class="kw">c</span>(<span class="kw">sum</span>(NBA1516$Test==F),<span class="kw">sum</span>(NBA1516$Test==T))</code></pre></div>
<pre><code>## [1] 317 158</code></pre>
<p>並用訓練組的資料（NBA1516$Test==F），訓練一個多變數線性迴歸模型</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit&lt;-<span class="kw">glm</span>(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+
<span class="st">             </span>Position+ThreesAttempted+FreeThrowsAttempted,
              <span class="dt">data =</span>NBA1516[NBA1516$Test==F,])
<span class="kw">summary</span>(fit)$coefficients</code></pre></div>
<pre><code>##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)          1.2e+01      8.186   1.487  1.4e-01
## TotalMinutesPlayed   6.8e-04      0.008   0.085  9.3e-01
## FieldGoalsAttempted  9.7e-01      0.027  35.796 9.0e-112
## PositionPF          -1.5e+01      8.741  -1.670  9.6e-02
## PositionPG          -3.8e+01      9.640  -3.892  1.2e-04
## PositionSF          -2.4e+01      9.667  -2.506  1.3e-02
## PositionSG          -3.6e+01      9.465  -3.812  1.7e-04
## ThreesAttempted      1.9e-01      0.032   5.807  1.6e-08
## FreeThrowsAttempted  7.6e-01      0.042  18.030  4.1e-50</code></pre>
<p>逐步選擇模型 stepwise 後退學習：一開始先將所有參數加到模型裡，再一個一個拿掉</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
##根據AIC，做逐步選擇, 預設倒退學習 direction = &quot;backward&quot;
##trace=FALSE: 不要顯示步驟
finalModel_B&lt;-<span class="kw">stepAIC</span>(fit,<span class="dt">direction =</span> <span class="st">&quot;backward&quot;</span>,<span class="dt">trace=</span><span class="ot">FALSE</span>)
<span class="kw">summary</span>(finalModel_B)$coefficients</code></pre></div>
<pre><code>##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)            12.43      7.565     1.6  1.0e-01
## FieldGoalsAttempted     0.97      0.020    49.9 6.5e-150
## PositionPF            -14.70      8.651    -1.7  9.0e-02
## PositionPG            -37.65      9.502    -4.0  9.2e-05
## PositionSF            -24.26      9.639    -2.5  1.2e-02
## PositionSG            -36.16      9.401    -3.8  1.5e-04
## ThreesAttempted         0.19      0.032     5.8  1.5e-08
## FreeThrowsAttempted     0.76      0.042    18.1  1.5e-50</code></pre>
<p>逐步選擇模型 stepwise 往前學習：一開始先做一個沒有參數的模型，再把參數一個一個加進去</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##根據AIC，做逐步選擇, 往前學習 direction = &quot;forward&quot;
finalModel_F&lt;-<span class="kw">stepAIC</span>(fit,<span class="dt">direction =</span> <span class="st">&quot;forward&quot;</span>,<span class="dt">trace=</span><span class="ot">FALSE</span>)
<span class="kw">summary</span>(finalModel_F)$coefficients</code></pre></div>
<pre><code>##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)          1.2e+01      8.186   1.487  1.4e-01
## TotalMinutesPlayed   6.8e-04      0.008   0.085  9.3e-01
## FieldGoalsAttempted  9.7e-01      0.027  35.796 9.0e-112
## PositionPF          -1.5e+01      8.741  -1.670  9.6e-02
## PositionPG          -3.8e+01      9.640  -3.892  1.2e-04
## PositionSF          -2.4e+01      9.667  -2.506  1.3e-02
## PositionSG          -3.6e+01      9.465  -3.812  1.7e-04
## ThreesAttempted      1.9e-01      0.032   5.807  1.6e-08
## FreeThrowsAttempted  7.6e-01      0.042  18.030  4.1e-50</code></pre>
<p>逐步選擇模型 stepwise 雙向學習：參數加加減減</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##根據AIC，做逐步選擇, 雙向學習 direction = &quot;both&quot;
finalModel_Both&lt;-<span class="kw">stepAIC</span>(fit,<span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>,<span class="dt">trace=</span><span class="ot">FALSE</span>)
<span class="kw">summary</span>(finalModel_Both)$coefficients</code></pre></div>
<pre><code>##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)            12.43      7.565     1.6  1.0e-01
## FieldGoalsAttempted     0.97      0.020    49.9 6.5e-150
## PositionPF            -14.70      8.651    -1.7  9.0e-02
## PositionPG            -37.65      9.502    -4.0  9.2e-05
## PositionSF            -24.26      9.639    -2.5  1.2e-02
## PositionSG            -36.16      9.401    -3.8  1.5e-04
## ThreesAttempted         0.19      0.032     5.8  1.5e-08
## FreeThrowsAttempted     0.76      0.042    18.1  1.5e-50</code></pre>
<p>用Test set來評估模型好不好，使用predict函數，將測試組資料放入預測模型中，預測測試組的結果</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictPoint&lt;-<span class="kw">predict</span>(finalModel_Both, <span class="co">#Test==T, test data</span>
                      <span class="dt">newdata =</span> NBA1516[NBA1516$Test==T,])
<span class="kw">cor</span>(<span class="dt">x=</span>predictPoint,<span class="dt">y=</span>NBA1516[NBA1516$Test==T,]$TotalPoints) <span class="co">#相關係數</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="dt">x=</span>predictPoint,<span class="dt">y=</span>NBA1516[NBA1516$Test==T,]$TotalPoints)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-237-1.png" width="672" /></p>
</div>
<div id="logistic-regression-" class="section level3">
<h3><span class="header-section-number">10.7.2</span> Logistic Regression 邏輯迴歸驗證</h3>
<p>首先，先把入學資料分成Training 和 Test set。這邊要特別留意，當答案有正反兩面時，<code>Level 1 要放正面答案</code>–&gt;有病/錄取…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydata &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/binary.csv&quot;</span>)
mydata$admit &lt;-<span class="st"> </span><span class="kw">factor</span>(mydata$admit) <span class="co"># 類別變項要轉為factor</span>
mydata$rank &lt;-<span class="st"> </span><span class="kw">factor</span>(mydata$rank) <span class="co"># 類別變項要轉為factor</span>
mydata$Test&lt;-F <span class="co">#新增一個參數紀錄分組</span>
mydata[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(mydata),<span class="kw">nrow</span>(mydata)/<span class="dv">3</span>),]$Test&lt;-T <span class="co">#隨機取1/3當Test set</span>
<span class="kw">c</span>(<span class="kw">sum</span>(mydata$Test==F),<span class="kw">sum</span>(mydata$Test==T)) <span class="co"># Training set : Test set學生數</span></code></pre></div>
<pre><code>## [1] 267 133</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#修改一下factor的level: 改成Level 1為錄取，2為不錄取--&gt;Level 1 要放正面答案</span>
mydata$admit&lt;-<span class="kw">factor</span>(mydata$admit,<span class="dt">levels=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))</code></pre></div>
<p>逐步選擇最好的模型</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GRE:某考試成績, GPA:在校平均成績, rank:學校聲望</span>
mylogit &lt;-<span class="st"> </span><span class="kw">glm</span>(admit ~<span class="st"> </span>gre +<span class="st"> </span>gpa +<span class="st"> </span>rank,
               <span class="dt">data =</span> mydata[mydata$Test==F,], <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
finalFit&lt;-<span class="kw">stepAIC</span>(mylogit,<span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>,<span class="dt">trace=</span><span class="ot">FALSE</span>) <span class="co"># 雙向逐步選擇模型</span>
<span class="kw">summary</span>(finalFit)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = admit ~ gpa + rank, family = &quot;binomial&quot;, data = mydata[mydata$Test == 
##     F, ])
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -2.241  -1.080   0.670   0.886   1.728  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    4.750      1.412    3.36  0.00077 ***
## gpa           -1.497      0.400   -3.74  0.00018 ***
## rank2          0.924      0.397    2.33  0.01996 *  
## rank3          1.645      0.432    3.80  0.00014 ***
## rank4          1.539      0.488    3.16  0.00160 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 341.27  on 266  degrees of freedom
## Residual deviance: 308.76  on 262  degrees of freedom
## AIC: 318.8
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>用預測組預測新學生可不可以錄取，並驗證答案</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AdmitProb&lt;-<span class="kw">predict</span>(finalFit, <span class="co"># 用Training set做的模型</span>
                   <span class="dt">newdata =</span> mydata[mydata$Test==T,], <span class="co">#Test==T, test data</span>
                   <span class="dt">type=</span><span class="st">&quot;response&quot;</span>) <span class="co">#結果為每個人被錄取的機率</span>
<span class="kw">head</span>(AdmitProb)</code></pre></div>
<pre><code>##    1    2    3    5   10   12 
## 0.87 0.61 0.50 0.42 0.60 0.45</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(AdmitProb&lt;<span class="fl">0.5</span>,mydata[mydata$Test==T,]$admit) <span class="co"># row,column</span></code></pre></div>
<pre><code>##        
##          1  0
##   FALSE 27 82
##   TRUE  12 12</code></pre>
<p>當答案是二元時：效能指標</p>
<ul>
<li>Sensitivity 敏感性</li>
<li>Specificity 特異性</li>
<li>Positive Predictive Value (PPV) 陽性預測值</li>
<li>Negative Predictive Value (NPV) 陰性預測值</li>
</ul>
<p>名詞解釋</p>
<p><img src="figure/Cond.png" width="720" /></p>
<ul>
<li>TP: 有病且預測也有病</li>
<li>TN: 沒病且預測也沒病</li>
<li>FP: 沒病但是預測有病</li>
<li>FN: 有病但預測沒病</li>
</ul>
<p><img src="figure/para.png" width="598" /></p>
<p>當答案是二元時：效能指標公式</p>
<ul>
<li>Sensitivity 敏感性：所有<code>真的有病</code>的人，被<code>預測有病</code>的比例</li>
<li>Specificity 特異性：所有<code>真的沒病</code>的人，被<code>預測沒病</code>的比例</li>
<li>Positive Predictive Value (PPV) 陽性預測值：所有被<code>預測有病</code>的人，<code>真的有病</code>的比例</li>
<li>Negative Predictive Value (NPV) 陰性預測值：所有被<code>預測沒病</code>的人，<code>真的沒病</code>的比例</li>
</ul>
<p>回想一下剛剛的驗證結果</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(AdmitProb&lt;<span class="fl">0.5</span>,mydata[mydata$Test==T,]$admit) <span class="co"># row,column</span></code></pre></div>
<pre><code>##        
##          1  0
##   FALSE 27 82
##   TRUE  12 12</code></pre>
<p><img src="figure/para.png" width="598" /></p>
<p>計算預測效能參數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AdmitProb&lt;-<span class="kw">predict</span>(finalFit,
                   <span class="dt">newdata =</span> mydata[mydata$Test==T,], <span class="co">#Test==T, test data</span>
                   <span class="dt">type=</span><span class="st">&quot;response&quot;</span>) <span class="co">#結果為每個人『不』被錄取的機率</span>
AdmitAns&lt;-<span class="kw">factor</span>(<span class="kw">ifelse</span>(AdmitProb&lt;<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="dt">levels=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))
<span class="kw">str</span>(AdmitAns)</code></pre></div>
<pre><code>##  Factor w/ 2 levels &quot;1&quot;,&quot;0&quot;: 2 2 2 1 2 1 2 2 2 2 ...
##  - attr(*, &quot;names&quot;)= chr [1:133] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;5&quot; ...</code></pre>
<p>計算預測效能參數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret) <span class="co"># install.packages(&quot;caret&quot;) #計算參數的packages</span>
<span class="kw">sensitivity</span>(AdmitAns,mydata[mydata$Test==T,]$admit)</code></pre></div>
<pre><code>## [1] 0.31</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">specificity</span>(AdmitAns,mydata[mydata$Test==T,]$admit)</code></pre></div>
<pre><code>## [1] 0.87</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">posPredValue</span>(AdmitAns,mydata[mydata$Test==T,]$admit)</code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">negPredValue</span>(AdmitAns,mydata[mydata$Test==T,]$admit)</code></pre></div>
<pre><code>## [1] 0.75</code></pre>
</div>
<div id="decision-trees-" class="section level3">
<h3><span class="header-section-number">10.7.3</span> Decision Trees 決策樹驗證</h3>
<p>阻攻/籃板/三分/助攻/抄截判斷位置-訓練</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">if (!<span class="kw">require</span>(<span class="st">&#39;rpart&#39;</span>)){
    <span class="kw">install.packages</span>(<span class="st">&quot;rpart&quot;</span>); <span class="kw">library</span>(rpart)
}
DT&lt;-<span class="kw">rpart</span>(Position~Blocks+TotalRebounds+ThreesMade+Assists+Steals,
          <span class="dt">data=</span>NBA1516[NBA1516$Test==F,]) <span class="co">#訓練組 Training set</span>
<span class="co">#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）</span>
DT</code></pre></div>
<pre><code>## n= 317 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##   1) root 317 240 SG (0.15 0.23 0.2 0.18 0.24)  
##     2) ThreesMade&lt; 0.5 72  35 C (0.51 0.38 0.069 0.028 0.014)  
##       4) TotalRebounds&gt;=3 65  28 C (0.57 0.4 0.031 0 0)  
##         8) Blocks&gt;=18 40  13 C (0.67 0.32 0 0 0) *
##         9) Blocks&lt; 18 25  12 PF (0.4 0.52 0.08 0 0) *
##       5) TotalRebounds&lt; 3 7   4 PG (0 0.14 0.43 0.29 0.14) *
##     3) ThreesMade&gt;=0.5 245 170 SG (0.049 0.18 0.23 0.23 0.31)  
##       6) Assists&gt;=1.5e+02 78  41 PG (0.064 0.064 0.47 0.15 0.24)  
##        12) TotalRebounds&gt;=2.9e+02 31  20 SF (0.13 0.16 0.13 0.35 0.23)  
##          24) Blocks&gt;=64 9   5 C (0.44 0.33 0 0.22 0) *
##          25) Blocks&lt; 64 22  13 SF (0 0.091 0.18 0.41 0.32)  
##            50) Steals&lt; 79 9   3 SF (0 0.22 0 0.67 0.11) *
##            51) Steals&gt;=79 13   7 SG (0 0 0.31 0.23 0.46) *
##        13) TotalRebounds&lt; 2.9e+02 47  14 PG (0.021 0 0.7 0.021 0.26)  
##          26) Assists&gt;=2.2e+02 21   1 PG (0 0 0.95 0 0.048) *
##          27) Assists&lt; 2.2e+02 26  13 PG (0.038 0 0.5 0.038 0.42)  
##            54) TotalRebounds&lt; 1.4e+02 10   0 PG (0 0 1 0 0) *
##            55) TotalRebounds&gt;=1.4e+02 16   5 SG (0.063 0 0.19 0.062 0.69) *
##       7) Assists&lt; 1.5e+02 167 110 SG (0.042 0.24 0.12 0.26 0.34)  
##        14) Blocks&gt;=6.5 105  68 PF (0.067 0.35 0.019 0.29 0.28)  
##          28) ThreesMade&lt; 14 28  10 PF (0.18 0.64 0 0.18 0) *
##          29) ThreesMade&gt;=14 77  48 SG (0.026 0.25 0.026 0.32 0.38)  
##            58) TotalRebounds&gt;=2.1e+02 37  22 PF (0.054 0.41 0 0.32 0.22)  
##             116) Steals&lt; 38 15   4 PF (0.067 0.73 0 0.067 0.13) *
##             117) Steals&gt;=38 22  11 SF (0.045 0.18 0 0.5 0.27) *
##            59) TotalRebounds&lt; 2.1e+02 40  19 SG (0 0.1 0.05 0.33 0.53)  
##             118) Assists&lt; 75 26  14 SF (0 0.15 0 0.46 0.38)  
##               236) Blocks&lt; 18 16   6 SF (0 0.12 0 0.62 0.25) *
##               237) Blocks&gt;=18 10   4 SG (0 0.2 0 0.2 0.6) *
##             119) Assists&gt;=75 14   3 SG (0 0 0.14 0.071 0.79) *
##        15) Blocks&lt; 6.5 62  35 SG (0 0.048 0.29 0.23 0.44)  
##          30) Assists&gt;=72 11   3 PG (0 0 0.73 0.18 0.091) *
##          31) Assists&lt; 72 51  25 SG (0 0.059 0.2 0.24 0.51) *</code></pre>
<p>阻攻/籃板/三分/助攻/抄截判斷位置-訓練</p>
<p>預設的<code>plot()</code>真的太難用，改用<code>rpart.plot</code> package的<code>prp()</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">if (!<span class="kw">require</span>(<span class="st">&#39;rpart.plot&#39;</span>)){
  <span class="kw">install.packages</span>(<span class="st">&quot;rpart.plot&quot;</span>); 
  <span class="kw">library</span>(rpart.plot)
}
<span class="kw">prp</span>(DT) <span class="co"># 把決策樹畫出來</span></code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-248-1.png" width="672" /></p>
<p>阻攻/籃板/三分/助攻/抄截判斷位置-訓練</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prp</span>(DT)</code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-249-1.png" width="672" /></p>
<p>有批球員沒寫守備位置？–預測</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">posPred&lt;-<span class="kw">predict</span>(DT,<span class="dt">newdata=</span> NBA1516[NBA1516$Test==T,]) <span class="co">#Test==T, test data</span>
<span class="co"># 預設為class probabilities, type = &quot;prob&quot;</span>
<span class="kw">head</span>(posPred)</code></pre></div>
<pre><code>##        C    PF   PG    SF   SG
## 1  0.000 0.000 0.14 0.071 0.79
## 14 0.000 0.059 0.20 0.235 0.51
## 15 0.000 0.059 0.20 0.235 0.51
## 20 0.063 0.000 0.19 0.062 0.69
## 22 0.067 0.733 0.00 0.067 0.13
## 26 0.000 0.000 0.31 0.231 0.46</code></pre>
<p>有個人沒寫守備位置–對答案</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result&lt;-<span class="kw">cbind</span>(<span class="kw">round</span>(posPred,<span class="dt">digits =</span> <span class="dv">2</span>),
              NBA1516[NBA1516$Test==T,]$Name,
      <span class="kw">as.character</span>(NBA1516[NBA1516$Test==T,]$Position))
<span class="kw">head</span>(result)</code></pre></div>
<pre><code>##    C      PF     PG     SF     SG                            
## 1  &quot;0&quot;    &quot;0&quot;    &quot;0.14&quot; &quot;0.07&quot; &quot;0.79&quot; &quot;Corey Brewer&quot;     &quot;SG&quot;
## 14 &quot;0&quot;    &quot;0.06&quot; &quot;0.2&quot;  &quot;0.24&quot; &quot;0.51&quot; &quot;Brian Roberts&quot;    &quot;PG&quot;
## 15 &quot;0&quot;    &quot;0.06&quot; &quot;0.2&quot;  &quot;0.24&quot; &quot;0.51&quot; &quot;Aaron Harrison&quot;   &quot;SG&quot;
## 20 &quot;0.06&quot; &quot;0&quot;    &quot;0.19&quot; &quot;0.06&quot; &quot;0.69&quot; &quot;Jared Dudley&quot;     &quot;SG&quot;
## 22 &quot;0.07&quot; &quot;0.73&quot; &quot;0&quot;    &quot;0.07&quot; &quot;0.13&quot; &quot;Anthony Tolliver&quot; &quot;PF&quot;
## 26 &quot;0&quot;    &quot;0&quot;    &quot;0.31&quot; &quot;0.23&quot; &quot;0.46&quot; &quot;Trevor Ariza&quot;     &quot;SF&quot;</code></pre>
<p>有個人沒寫守備位置–預測-2</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">posPredC&lt;-<span class="kw">predict</span>(DT,<span class="dt">newdata=</span> NBA1516[NBA1516$Test==T,],<span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)
<span class="co"># type = &quot;class&quot; 直接預測類別</span>
<span class="kw">head</span>(posPredC)</code></pre></div>
<pre><code>##  1 14 15 20 22 26 
## SG SG SG SG PF SG 
## Levels: C PF PG SF SG</code></pre>
<p>有個人沒寫守備位置–對答案-2</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resultC&lt;-<span class="kw">cbind</span>(<span class="kw">as.character</span>(posPredC),NBA1516[NBA1516$Test==T,]$Name,
      <span class="kw">as.character</span>(NBA1516[NBA1516$Test==T,]$Position))
<span class="kw">head</span>(resultC)</code></pre></div>
<pre><code>##      [,1] [,2]               [,3]
## [1,] &quot;SG&quot; &quot;Corey Brewer&quot;     &quot;SG&quot;
## [2,] &quot;SG&quot; &quot;Brian Roberts&quot;    &quot;PG&quot;
## [3,] &quot;SG&quot; &quot;Aaron Harrison&quot;   &quot;SG&quot;
## [4,] &quot;SG&quot; &quot;Jared Dudley&quot;     &quot;SG&quot;
## [5,] &quot;PF&quot; &quot;Anthony Tolliver&quot; &quot;PF&quot;
## [6,] &quot;SG&quot; &quot;Trevor Ariza&quot;     &quot;SF&quot;</code></pre>
</div>
</div>
<div id="case-study" class="section level2">
<h2><span class="header-section-number">10.8</span> Case Study</h2>
<p>完整的模型建立步驟範例：</p>
<ul>
<li>標題：以聲波撞擊礦石的回聲預測礦石是否為礦物</li>
<li>以Sonar, Mines vs. Rocks為例</li>
</ul>
<p><strong>步驟1.1:讀資料</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#install.packages(&quot;mlbench&quot;) # 此package內有很多dataset可練習</span>
<span class="kw">library</span>(mlbench)
<span class="kw">data</span>(Sonar)
<span class="kw">str</span>(Sonar) <span class="co">#看一下資料型別，有沒有缺值，類別變項是不是factor</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    208 obs. of  61 variables:
##  $ V1   : num  0.02 0.0453 0.0262 0.01 0.0762 0.0286 0.0317 0.0519 0.0223 0.0164 ...
##  $ V2   : num  0.0371 0.0523 0.0582 0.0171 0.0666 0.0453 0.0956 0.0548 0.0375 0.0173 ...
##  $ V3   : num  0.0428 0.0843 0.1099 0.0623 0.0481 ...
##  $ V4   : num  0.0207 0.0689 0.1083 0.0205 0.0394 ...
##  $ V5   : num  0.0954 0.1183 0.0974 0.0205 0.059 ...
##  $ V6   : num  0.0986 0.2583 0.228 0.0368 0.0649 ...
##  $ V7   : num  0.154 0.216 0.243 0.11 0.121 ...
##  $ V8   : num  0.16 0.348 0.377 0.128 0.247 ...
##  $ V9   : num  0.3109 0.3337 0.5598 0.0598 0.3564 ...
##  $ V10  : num  0.211 0.287 0.619 0.126 0.446 ...
##  $ V11  : num  0.1609 0.4918 0.6333 0.0881 0.4152 ...
##  $ V12  : num  0.158 0.655 0.706 0.199 0.395 ...
##  $ V13  : num  0.2238 0.6919 0.5544 0.0184 0.4256 ...
##  $ V14  : num  0.0645 0.7797 0.532 0.2261 0.4135 ...
##  $ V15  : num  0.066 0.746 0.648 0.173 0.453 ...
##  $ V16  : num  0.227 0.944 0.693 0.213 0.533 ...
##  $ V17  : num  0.31 1 0.6759 0.0693 0.7306 ...
##  $ V18  : num  0.3 0.887 0.755 0.228 0.619 ...
##  $ V19  : num  0.508 0.802 0.893 0.406 0.203 ...
##  $ V20  : num  0.48 0.782 0.862 0.397 0.464 ...
##  $ V21  : num  0.578 0.521 0.797 0.274 0.415 ...
##  $ V22  : num  0.507 0.405 0.674 0.369 0.429 ...
##  $ V23  : num  0.433 0.396 0.429 0.556 0.573 ...
##  $ V24  : num  0.555 0.391 0.365 0.485 0.54 ...
##  $ V25  : num  0.671 0.325 0.533 0.314 0.316 ...
##  $ V26  : num  0.641 0.32 0.241 0.533 0.229 ...
##  $ V27  : num  0.71 0.327 0.507 0.526 0.7 ...
##  $ V28  : num  0.808 0.277 0.853 0.252 1 ...
##  $ V29  : num  0.679 0.442 0.604 0.209 0.726 ...
##  $ V30  : num  0.386 0.203 0.851 0.356 0.472 ...
##  $ V31  : num  0.131 0.379 0.851 0.626 0.51 ...
##  $ V32  : num  0.26 0.295 0.504 0.734 0.546 ...
##  $ V33  : num  0.512 0.198 0.186 0.612 0.288 ...
##  $ V34  : num  0.7547 0.2341 0.2709 0.3497 0.0981 ...
##  $ V35  : num  0.854 0.131 0.423 0.395 0.195 ...
##  $ V36  : num  0.851 0.418 0.304 0.301 0.418 ...
##  $ V37  : num  0.669 0.384 0.612 0.541 0.46 ...
##  $ V38  : num  0.61 0.106 0.676 0.881 0.322 ...
##  $ V39  : num  0.494 0.184 0.537 0.986 0.283 ...
##  $ V40  : num  0.274 0.197 0.472 0.917 0.243 ...
##  $ V41  : num  0.051 0.167 0.465 0.612 0.198 ...
##  $ V42  : num  0.2834 0.0583 0.2587 0.5006 0.2444 ...
##  $ V43  : num  0.282 0.14 0.213 0.321 0.185 ...
##  $ V44  : num  0.4256 0.1628 0.2222 0.3202 0.0841 ...
##  $ V45  : num  0.2641 0.0621 0.2111 0.4295 0.0692 ...
##  $ V46  : num  0.1386 0.0203 0.0176 0.3654 0.0528 ...
##  $ V47  : num  0.1051 0.053 0.1348 0.2655 0.0357 ...
##  $ V48  : num  0.1343 0.0742 0.0744 0.1576 0.0085 ...
##  $ V49  : num  0.0383 0.0409 0.013 0.0681 0.023 0.0264 0.0507 0.0285 0.0777 0.0092 ...
##  $ V50  : num  0.0324 0.0061 0.0106 0.0294 0.0046 0.0081 0.0159 0.0178 0.0439 0.0198 ...
##  $ V51  : num  0.0232 0.0125 0.0033 0.0241 0.0156 0.0104 0.0195 0.0052 0.0061 0.0118 ...
##  $ V52  : num  0.0027 0.0084 0.0232 0.0121 0.0031 0.0045 0.0201 0.0081 0.0145 0.009 ...
##  $ V53  : num  0.0065 0.0089 0.0166 0.0036 0.0054 0.0014 0.0248 0.012 0.0128 0.0223 ...
##  $ V54  : num  0.0159 0.0048 0.0095 0.015 0.0105 0.0038 0.0131 0.0045 0.0145 0.0179 ...
##  $ V55  : num  0.0072 0.0094 0.018 0.0085 0.011 0.0013 0.007 0.0121 0.0058 0.0084 ...
##  $ V56  : num  0.0167 0.0191 0.0244 0.0073 0.0015 0.0089 0.0138 0.0097 0.0049 0.0068 ...
##  $ V57  : num  0.018 0.014 0.0316 0.005 0.0072 0.0057 0.0092 0.0085 0.0065 0.0032 ...
##  $ V58  : num  0.0084 0.0049 0.0164 0.0044 0.0048 0.0027 0.0143 0.0047 0.0093 0.0035 ...
##  $ V59  : num  0.009 0.0052 0.0095 0.004 0.0107 0.0051 0.0036 0.0048 0.0059 0.0056 ...
##  $ V60  : num  0.0032 0.0044 0.0078 0.0117 0.0094 0.0062 0.0103 0.0053 0.0022 0.004 ...
##  $ Class: Factor w/ 2 levels &quot;M&quot;,&quot;R&quot;: 2 2 2 2 2 2 2 2 2 2 ...</code></pre>
<p>在建立模型之前…別忘了基本的資料分析，使用<code>探索性分析 Exploratory data analysis</code>，看看資料長怎麼樣，要是有一個參數可以完美的把礦物跟石頭分開，那就不用麻煩建模了…</p>
<p>探索性分析 Exploratory data analysis</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2);<span class="kw">library</span>(reshape2) <span class="co">#install.packages(c(&quot;ggplot2&quot;,&quot;reshape2&quot;))</span>
Sonar.m&lt;-<span class="kw">melt</span>(Sonar,<span class="dt">id.vars =</span> <span class="kw">c</span>(<span class="st">&quot;Class&quot;</span>))
<span class="kw">ggplot</span>(Sonar.m)+<span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Class,<span class="dt">y=</span>value))+
<span class="st">    </span><span class="kw">facet_wrap</span>(~variable, <span class="dt">nrow=</span><span class="dv">5</span>,<span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="co">#圖片太小了</span></code></pre></div>
<p><img src="DataAnalyticsWithR_files/figure-html/unnamed-chunk-255-1.png" width="672" /></p>
<p><strong>步驟1.2: 資料前處理</strong></p>
<ul>
<li>缺值？
<ul>
<li>沒有缺值，不需要處理</li>
</ul></li>
<li>答案種類？
<ul>
<li>類別變項叫<code>Class</code>，M: mine礦–&gt;+, R: rock–&gt;-，不需要處理</li>
</ul></li>
<li>類別變項的型別是不是factor？
<ul>
<li>是，不需要處理</li>
</ul></li>
<li>有沒有無關的參數？
<ul>
<li>沒有無關的參數，不需要處理</li>
</ul></li>
</ul>
<p><strong>步驟2:分成訓練組與測試組</strong></p>
<p>該怎麼分可以自己決定，1/3，1/5…都可以</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Sonar$Test&lt;-F <span class="co">#新增一個參數紀錄分組</span>
<span class="co">#隨機取1/3當Test set</span>
Sonar[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(Sonar),<span class="kw">nrow</span>(Sonar)/<span class="dv">3</span>),]$Test&lt;-T
<span class="co"># 看一下 Training set : Test set 案例數</span>
<span class="kw">c</span>(<span class="kw">sum</span>(Sonar$Test==F),<span class="kw">sum</span>(Sonar$Test==T))</code></pre></div>
<pre><code>## [1] 139  69</code></pre>
<p><strong>步驟3:訓練模型</strong></p>
<ul>
<li>注意只能用<code>訓練組</code>的資料，<code>Test</code>參數==F，忘記可以看前面範例</li>
<li>數值自變項X很多，先用迴歸好了～</li>
<li>要解釋一下模型</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit&lt;-<span class="kw">glm</span>(Class~., Sonar[Sonar$Test==F,],<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
finalFit&lt;-<span class="kw">stepAIC</span>(fit,<span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>,<span class="dt">trace =</span> F)
<span class="kw">summary</span>(finalFit)$coefficients</code></pre></div>
<pre><code>##             Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept)     4047     174293   0.023     0.98
## V1            -40789    1776026  -0.023     0.98
## V4             -5195     270110  -0.019     0.98
## V9             -2411     167303  -0.014     0.99
## V13            -4290     188123  -0.023     0.98
## V17             5684     242345   0.023     0.98
## V18            -2057      89134  -0.023     0.98
## V22            -2956     127113  -0.023     0.98
## V27            -1518      67185  -0.023     0.98
## V29             3648     164011   0.022     0.98
## V30            -9116     405516  -0.022     0.98
## V31             9919     444721   0.022     0.98
## V32            -5104     253668  -0.020     0.98
## V34             5067     243722   0.021     0.98
## V35            -8418     375419  -0.022     0.98
## V36             7164     310629   0.023     0.98
## V49           -42033    1797213  -0.023     0.98
## V50            64865    2866786   0.023     0.98
## V51           -63687    2801711  -0.023     0.98
## V53           -47779    2557421  -0.019     0.99
## V55           133849    5729669   0.023     0.98</code></pre>
<p><strong>步驟4.1:用測試組驗證模型-預測</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MinePred&lt;-<span class="kw">predict</span>(finalFit,<span class="dt">newdata =</span> Sonar[Sonar$Test==T,])
MineAns&lt;-<span class="kw">ifelse</span>(MinePred&lt;<span class="fl">0.5</span>,<span class="st">&quot;M&quot;</span>,<span class="st">&quot;R&quot;</span>) <span class="co">#&lt;0.5: Level 1</span>
MineAns&lt;-<span class="kw">factor</span>(MineAns,<span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;M&quot;</span>,<span class="st">&quot;R&quot;</span>))
MineAns</code></pre></div>
<pre><code>##   1   9  10  11  12  13  14  19  21  24  33  35  36  37  40  41  42  47  52  59 
##   M   R   R   R   R   R   R   M   M   R   M   R   M   M   R   M   M   M   M   M 
##  65  66  67  72  73  78  79  80  81  84  85  87  88  89  91  97  98  99 100 104 
##   R   R   R   R   M   M   R   M   R   R   M   M   R   R   R   R   R   R   R   R 
## 105 106 109 110 115 117 120 122 126 130 134 135 139 145 151 153 154 155 163 167 
##   M   M   M   M   M   M   R   M   R   R   M   M   R   M   R   M   M   M   R   M 
## 168 171 180 181 188 190 195 199 208 
##   M   R   R   R   M   M   R   R   R 
## Levels: M R</code></pre>
<p><strong>步驟4.2:用測試組驗證模型-效能</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret) <span class="co"># install.packages(&quot;caret&quot;) #計算參數的packages</span>
<span class="kw">sensitivity</span>(MineAns,Sonar[Sonar$Test==T,]$Class)</code></pre></div>
<pre><code>## [1] 0.91</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">specificity</span>(MineAns,Sonar[Sonar$Test==T,]$Class)</code></pre></div>
<pre><code>## [1] 0.97</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">posPredValue</span>(MineAns,Sonar[Sonar$Test==T,]$Class)</code></pre></div>
<pre><code>## [1] 0.97</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">negPredValue</span>(MineAns,Sonar[Sonar$Test==T,]$Class)</code></pre></div>
<pre><code>## [1] 0.92</code></pre>
<p><strong>解釋範例 - 資料說明</strong></p>
<p>此資料來源為UCI Machine Learning Repository。</p>
<p>記載礦物與石頭接受各個不同角度的聲波撞擊後，接收到的回聲數值，一共有60個參數，代表使用一特別角度的聲波撞擊礦石所得回聲。另外，分類結果為二元分類，包括礦物 (M) 與石頭 (R) 。</p>
<p><strong>解釋範例 - 模型說明</strong></p>
<p>使用聲波在不同角度撞擊<code>礦石</code>所得到的回聲資料，以邏輯迴歸建立模型預測礦石是否為礦物，經最佳化後，模型使用參數為V1 + V2 + V3 + V4 + V7 + V11 + V12 + V13 + V17 + V18 + V22 + V24 + V25 + V26 + V30 + V31 + V32 + V38 + V39 + V48 + V50 + V52 + V53 + V58 + V59，共25個參數，各參數代表從一特別角度所得的礦石回聲</p>
<p><strong>解釋範例 - 預測效能說明</strong></p>
<p>使用聲波在不同角度撞擊<code>礦石</code>所得到的回聲資料，以邏輯迴歸模型預測礦石是否為礦物，可得敏感度97%，特異性89%，陽性預測率89%，陰性預測率97%。</p>
</div>
<div id="-2" class="section level2">
<h2><span class="header-section-number">10.9</span> 參考資料</h2>
<ul>
<li>台大資工林軒田教授：
<ul>
<li><a href="www.coursera.org/course/ntumlone">Machine Learning Foundations</a></li>
<li><a href="www.coursera.org/course/ntumltwo">Machine Learning Techniques</a></li>
</ul></li>
<li><p><a href="http://www.salemmarafi.com/code/market-basket-analysis-with-r/">Market Basket Analysis with R</a></p></li>
<li><p><a href="https://www.r-bloggers.com/deep-learning-in-r-2/">Deep Learning in R</a></p></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-rpart">
<p>Therneau, Terry, Beth Atkinson, and Brian Ripley. 2015. <em>Rpart: Recursive Partitioning and Regression Trees</em>. <a href="https://CRAN.R-project.org/package=rpart" class="uri">https://CRAN.R-project.org/package=rpart</a>.</p>
</div>
<div id="ref-R-rpart.plot">
<p>Milborrow, Stephen. 2016. <em>Rpart.plot: Plot ’Rpart’ Models: An Enhanced Version of ’Plot.rpart’</em>. <a href="https://CRAN.R-project.org/package=rpart.plot" class="uri">https://CRAN.R-project.org/package=rpart.plot</a>.</p>
</div>
<div id="ref-R-arules">
<p>Hahsler, Michael, Christian Buchta, Bettina Gruen, and Kurt Hornik. 2016. <em>Arules: Mining Association Rules and Frequent Itemsets</em>. <a href="https://CRAN.R-project.org/package=arules" class="uri">https://CRAN.R-project.org/package=arules</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="InteractiveGraphics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="big.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "Microsoft JhengHei",
"size": 2
},
"edit": {
"link": "https://github.com/yijutseng/DataAnalyticsWithRBook/edit/master/10-DataMining.Rmd",
"text": "Edit"
},
"download": ["DataAnalyticsWithR.pdf", "DataAnalyticsWithR.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
