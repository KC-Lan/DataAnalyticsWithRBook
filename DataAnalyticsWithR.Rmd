--- 
title: "資料科學與R語言"
author: "曾意儒 Yi-Ju Tseng"
date: "`r Sys.Date()`"
knit: "bookdown::render_book"
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
colorlinks: yes
lot: yes
lof: yes
download: no
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    config:
      fontsettings:
        family: Microsoft JhengHei
      download: null
documentclass: book
github-repo: yijutseng/DataAnalyticsWithRBook
description: "介紹如何使用R語言完成資料讀取、處理、分析與呈現，以及大數據技術與R的整合"
url: 'http\://yijutseng.github.io/DataScienceRBook'


---
```{r setup, include=FALSE}
options(
  htmltools.dir.version = FALSE, formatR.indent = 2, width = 80, digits = 2
)

pkg<-c('ggplot2', 'dplyr','lubridate','bit64','bookdown','knitr','rmarkdown','RCurl','data.table','stringr','reshape2','SportsAnalytics','readr','readxl','jsonlite','XML','Rfacebook','rvest','rgdal','rgeos','maptools','ggmap','choroplethr','choroplethrMaps','WDI','treemapify','shiny','plotly','ggvis','googleVis','rpart',
        'rpart.plot','fields','arules','datasets','arulesViz','MASS','caret','purrr','treemap')
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

ipak(pkg)
```

# {- #preface}
本書介紹如何使用[R語言](http://www.r-project.org/){target="_blank"}完成資料讀取 (檔案、透過API擷取或爬蟲)、資料清洗與處理、探索式資料分析、資料視覺化、互動式資料呈現 (搭配Shiny) 與資料探勘等，並介紹R與Hadoop Ecosystems介接方法。

資料探勘章節尚未完成，epub版本格式微調中。

如要一次安裝所有本書會使用到的套件，可在R內執行以下程式碼：
```{r eval=F}
install.packages("devtools")
devtools::install_github("yijutseng/DataAnalyticsWithRBook")
```

本書為[長庚大學資訊管理學系](http://im.cgu.edu.tw/bin/home.php){target="_blank"} [大數據分析方法](https://github.com/yijutseng/BigDataCGUIM){target="_blank"}課程教學使用書籍

如果您想修改文字或範例，歡迎透過[此連結](https://goo.gl/forms/5Htobvwy2vsB7yiF3){target="_blank"}或是透過[GitHub](https://github.com/yijutseng/DataAnalyticsWithRBook/issues){target="_blank"} issue提供建議與回饋。


本書程式碼執行環境：
```{r}
sessionInfo()
```

本書使用套件版本：
```{r}
pkgInfo<-lapply(pkg, packageDescription, fields = c("Package", "Version"))
knitr::kable(data.frame(Package=sapply(pkgInfo, `[[`, 1),
  Version=sapply(pkgInfo, `[[`, 2)))
```

本著作係採用創用 CC 姓名標示-非商業性-禁止改作 3.0 台灣 授權條款授權。

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), pkg
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# R語言101 {#intro}

本章節介紹學習R語言的基本知識，包括基本指令操作、運算子介紹等。

## 什麼是R語言

[R語言](http://www.r-project.org/){target="_blank"}是一種自由軟體程式語言，主要用於資料分析與統計運算，2000年時終於發表R 1.0.0，有關R語言的發展歷史可參考[維基百科](https://zh.wikipedia.org/wiki/R%E8%AF%AD%E8%A8%80){target="_blank"}。基本的R軟體已經內建多種統計及分析功能，其餘功能可以透過安裝**套件（Packages）**加載，眾多的套件使R的使用者可以【站在巨人的肩膀上(Standing on the shoulders of
giants (Hal R. Varian, Google))】做資料分析，截至2017年1月為止，R軟體可另外安裝的套件數目共有10,000個以上 ([R Studio報導](https://www.rstudio.com/rviews/2017/01/06/10000-cran-packages/){target="_blank"})。常用的套件清單可參考各項網路資訊，如[R Studio的整理：Quick list of useful R packages](https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages){target="_blank"}

安裝套件Package的方法如下：
```{r eval=F}
install.packages("套件名稱")
```

值得注意的是，套件名稱需要加上雙引號，舉例來說，若要安裝`ggplot2`套件，則要在R的Console視窗內輸入：
```{r eval=F}
install.packages("ggplot2")
```

若要載入**已安裝**的套件，則輸入`library(套件名稱)`，範例：
```{r eval=F}
library(ggplot2)
```
載入已安裝的套件時，可以**不用**在套件名稱前後加雙引號，但也可以加 （[參考資料](http://stackoverflow.com/questions/25210455/how-can-library-accept-both-quoted-and-unquoted-strings){target="_blank"}）。

## 函數使用
在R中有許多內建函數，安裝套件後各套件也會提供各式各樣寫好的函數，函數使用方式為`函數名稱(參數1,參數2,....)`，以計算平均數為例，可使用`mean()`函數，範例如下:

```{r}
mean(c(1,2,3,4,5,6)) ##計算1~6的平均數
```

若想知道各函數所需參數，可使用`?函數名稱`觀看函數作者所撰寫的說明文件
```{r eval=F}
?mean
```

除非有指定參數名稱，函數的參數設定有順序性，如序列產生函數`seq()`，參數順序為`from, to, by`，代表序列起點、序列終點，以及相隔單位。
```{r}
seq(from=1,to=9,by=2)#1~9，每隔2產生一數字
seq(1,9,2)#按照順序輸入參數，可省去參數名稱
seq(by=2,to=9,from=1)#若不想照順序輸入參數，需要指定參數名稱
```

## 變數設定

在開始深入學習R語言之前，首要任務是學習最基本的R程式碼：**變數設定**，在R語言中，主要使用`<-`設定變數，設定方法為：**變數名稱**`<-`**變數內容(值)**，雖然**變數名稱**可依箭頭方向放置於左側`<-`或右側`->`，但為方便閱讀，**變數名稱**多放置於左側。

```{r first}
a<-1 
2->b
a
b
```

R語言也接受使用`=`設定變數，此時**變數名稱**必須在左側，如：**變數名稱**`=`**變數內容**

```{r first2}
c=1 
c
```

除了**變數設定**外，`str()`函數也為常用基本函數，`str()`用在檢查與總覽各類變數型態。

```{r first3}
d<-3
str(d)
```

變數的命名有以下規則:

- 不可使用保留字，如break, else, FALSE, for, function, if, Inf, NA, NaN,
next, repeat, return, TRUE, while等
- 開頭只能是英文字，或 `.`
- 大小寫敏感

## 執行視窗
R是可直譯的語言，也就是說，可以在執行視窗(Console)直接打程式碼，在視窗出現`>`時，表示可輸入指令，若視窗出現`+`時，表示前面的程式碼還沒打完，必須鍵入完整的程式碼讓R執行。

## 資料型態 {#DataType}
在R語言中，常用的資料型態包括**數值 (numeric)**、**字串 (character)**、**布林變數 (logic)**以及**日期 (Date)**等。

### 數值 numeric

數值包括整數（沒有小數點）與浮點數（有小數點）的數值

```{r num1}
num1<-100 
num2<-1000.001
```

值得注意的是，若數值長度超過 `2^53`，必須導入`bit64` package [@R-bit64]，將數值長度上限提高為`2^63`，才能表示完整數值
```{r bit64, message=F}
print(2^53, digits=20) 
print(2^53+1, digits=20) # +1後，數值仍與2^53相同
library(bit64) # 導入bit64 package
print(as.integer64(2)^53, digits=20)
print(as.integer64(2)^53+1, digits=20)# 導入bit64後，可得正確答案
```


### 字串 character
用雙引號`"`框起的文字會被儲存為字串格式，若在數字前後加上雙引號，數字也會被儲存為文字形式，無法進行數值的加減乘除等運算。
```{r char1}
char1<-"abcTest" 
char2<-"100"
char3<-"200"
#char2+char3 #會輸出Error message: non-numeric argument to binary operator
```

### 布林變數 logic
用於邏輯判斷，可使用大寫**TRUE**或**T**代表**真**，大寫**FALSE**或**F**代表假。
```{r bool1}
boolT<-TRUE
boolT1<-T
boolF<-FALSE
boolF1<-F
```

### 日期 (Date)
用於表示日期，於資料分析中常用，使用`Sys.Date()`指令可得系統日期。

```{r date1}
dateBook<-Sys.Date()
dateBook

```

日期與字串的相關轉換操作可考慮使用簡單易懂的`lubridate`[@R-lubridate] package，如果想要將`年/月/日`格式的文字轉換為日期物件，可使用`ymd()`函數（y表年year，m表月month，d表日day），如果想要將`月/日/年`格式的文字轉換為日期物件，則使用`mdy()`函數，以此類推。

```{r date2,message=F}
library(lubridate)
ymd('2012/3/3')
mdy('3/3/2012')
```

其他使用方式可參考 [The Yhat Blog](http://blog.yhat.com/static/pdf/R_date_cheat_sheet.pdf){target="_blank"}。

## 基本運算子

### 數學基本運算
在R中，數學運算與其他程式語言相同

- 加 `+`
- 減 `-`
- 乘 `*`
- 除 `/`
- 餘數 `%%`
- 次方 `^`

```{r math1}
num1<-1
num2<-100
num1+num2
num1-num2
num1*num2
num1/num2
100%%3 ##100除以3後所得餘數
2^3 ##2的3次方
```

###進階數學函數
- 四捨五入 `round()`
- 無條件捨去 `floor()`
- 無條件進位 `ceiling()`

```{r math2}
num1<-1.568
num2<-2.121
round(num2,digits = 1) #2.121四捨五入至小數點第一位
floor(num1) ##1.568
ceiling(num2) ##2.121
```

### 邏輯運算
常用之邏輯判斷也可在R中直接使用

- 大於 `>`
- 小於 `<`
- 等於 `==`，為了不與變數設定混淆，判斷兩變數是否相等，要用**雙等號**
- 大於等於 `>=`
- 小於等於 `<=`

```{r log1}
num1<-1
num2<-100
num1>num2
num1<num2
```


文字字串也可比較大小
```{r log2}
char1<-"abcTest" 
char2<-"defTest"
char1>char2
```

邏輯混合判斷，和JAVA等語言不同的是，在R中使用**單符號**即可表示且`&`和或`|`

- 且 `&`
- 或 `|`
```{r log3}
TRUE & TRUE
TRUE & FALSE
TRUE | TRUE
TRUE | FALSE
```

反向布林變數`!`
```{r log4}
!TRUE
!FALSE
```
## 錯誤訊息
- Message：有可能的錯誤通知，程式會繼續執行
- Warning：有錯誤，但是不會影響太多，程式會繼續執行
- Error：有錯，而且無法繼續執行程式
- Condition：可能會發生的情況
```{r}
log(-1)
```
```{r, error=T}
mena(NA)
```
錯誤訊息範例1:
```
# Error: could not find function "fetch_NBAPlayerStatistics"
# 找不到"fetch_NBAPlayerStatistics" function
```
可能原因：沒安裝或沒讀入SportsAnalytics package

錯誤訊息範例2:
```
# Error in library(knitr): there is no package called 'knitr'
# 找不到"knitr" package
```
可能原因：沒安裝knitr package

## Help
R語言與套件均有完整的文件與範例可以參考，在R的執行視窗中，輸入`?函數名稱`或`?套件名稱`即可看到函數或套件的使用說明
```{r eval=F}
?ggplot2
?ymd
```

除此之外，[Stack Overflow](http://stackoverflow.com/){target="_blank"}中也有許多問答，可直接在網站中搜尋關鍵字與錯誤訊息。

如果找不到解答，發問時請附上可以重現錯誤的**程式碼**與**資料**，以及系統/套件的版本資訊，版本資訊可以透過執行下列程式碼取得：

```{r}
sessionInfo()
```




<!--chapter:end:01-intro.Rmd-->

# R 資料結構 {#RDataStructure}

## 向量 vector
向量為一維資料的表現和儲存方式，用`c()`函數可定義向量，如：
```{r vector1}
vec<-c('a','b','c','d','e')
```
a~e為vec向量中的**元素(element)**，各元素在向量中的順序固定，`a`為`vec`向量中的第**1**個元素，`b`則為第**2**個元素，以此類推，若要將`vec`向量的第**4**個元素取出，可使用
```{r vector2}
vec[4] ## 第4個元素
```
也可同時取出多個元素
```{r vector21}
vec[c(2,3)] ## 第2與第3個元素
```

此外，在同一向量中，所有元素之**資料型態必須相同**，如上述`vec`向量，元素均為文字型態，若放不同類別的資料進同一個向量，資料型態會被自動轉成一樣的，範例如下
```{r vector211}
a<-c(TRUE, "a",1)
str(a)
```

和變數指定類似，向量中的元素也可以使用`<-`重新指定
```{r vector22}
vec[3]
vec[3]<-'z' ##第三個元素值設定為“z”
vec
```
### 快速產生向量函數
若要產生連續向量，如1~20，可使用`:`來串連首字與最後一字
```{r vector3}
1:20 ## c(1,2,...,19,20)
```
或是使用`seq()`函數

```{r vector4}
seq(from=1,to=20,by=1) ##1~20，中間相隔1
seq(from=1,to=50,by=2) ##1~50，中間相隔2
```

### 向量運算
向量也可直接做加減乘除運算，如
```{r vector5}
numvec<-1:10 ## c(1,2,3,4,5,6,7,8,9,10)
numvec+3 ## 所有元素+3
numvec*2 ## 所有元素*2
```
向量和向量也可做運算，如
```{r vector6}
numvec1<-1:3 ## c(1,2,3)
numvec2<-4:6 ## c(4,5,6)
numvec1+numvec2
numvec1*numvec2
```

## 因子 factor
因子是由向量轉換而成，多用於表示**類別**數據，如大學中有大學生、碩士班學生與博士班學生三種類別的學生，使用方法為`factor(資料向量,levels=類別次序)`，`levels`參數可設定各類別的次序
```{r factor1}
factor(c("大學生","碩士班學生","博士班學生"),
       levels = c("大學生","碩士班學生","博士班學生"))
```
因子變量一但決定其類別的種類與數目時，通常不會再作更動，也就是任何新增的元素都要是大學生、碩士班學生與博士班學生其中一種。


## 列表 list
由於向量和因子都只能儲存一種元素，使用上彈性較不足，在R語言中，有一彈性很大的資料型態**列表list**，在列表中，元素可分屬不同資料類別，除了可包括**數值**與**文字**外，也可以包括資料集，如**向量**和**因子**等，更進階的使用，還可以包括矩陣與資料框。如要建立列表，可使用`list()`函數
```{r list1}
listSample<-list(Students=c("Tom","Kobe","Emma","Amy"),Year=2017,
                 Score=c(60,50,80,40),School="CGU")
listSample
```

### 列表資料擷取
列表可用`$`符號做資料擷取
```{r}
listSample$Students ##取得中表中的Students變量
```
也可和向量一樣，使用索引值來擷取資料，和向量不同的是，若要取得**值**，要使用雙中括號`[[ ]]`
```{r}
listSample[[1]] ##取得中表中第一個變量的值
```
如果只使用單中括號，回傳的資料型態會是列表list，並非列表中的值
```{r}
listSample[1] ##取得中表中第一個變量（列表型態）
```


### 列表資料編輯設定
列表資料也可和向量資料一樣，重新編輯設定
```{r}
listSample[[1]] 
listSample[[1]]<-c("小明","大雄","胖虎","小新","大白") ##將Students變量重新設定
listSample[[1]] 
```

除了編輯以外，列表資料也能用`$`符號與`<-`變數設定符號新增
```{r}
listSample$Gender<-c("M","F","M","F","M") ##新增Gender變量，並設定向量值
```

若需刪除某變量，可將變量值設定為`NULL`
```{r}
listSample$Score<-NULL ##刪除Score變量
listSample
```


## 矩陣 matrix
```{r matrix1}
a <- matrix(c(1:6), nrow=3, ncol=2) ##建立3x2的矩陣，分別填入1~6的值
a
```

## 資料框 data.frame
資料框是非常常見的二維資料格式，由一系列的欄位（Column）和列（Row）所組成，常見的Excel試算表也是類似的資料表現形式，可使用`data.frame()`來創建新的資料框
```{r dataframe1}
StuDF <- data.frame(StuID=c(1,2,3,4,5), ##欄位名稱=欄位值
                  name=c("小明","大雄","胖虎","小新","大白"),
                  score=c(80,60,90,70,50))
StuDF 
```
如範例所示，每個欄位都有名稱（StuID, name, score），若沒有設定欄位名稱，R會自動指派 V1 - Vn 作為欄位名稱。在R中，每個欄位的資料型態必須相同，如StuID和score為數值型態，name為文字型態。每一列也有預設的列名，R自動依序指派 1 - n 作為列名。
如需檢查欄位名稱與列名，可使用`colnames()`和`rownames()`

```{r}
colnames(StuDF) ##欄位名稱
rownames(StuDF) ##列名
```

如需檢查個欄位之資料型別，可使用`str()`函數
```{r}
str(StuDF) 
```


資料框可用`$`符號做**欄位**資料擷取
```{r}
iris$Species ##取得iris資料框中的Species欄位
```

資料框可用`$`符號做**欄位**資料擷取後，當成**向量**，並使用**[ ]**做資料編輯。
```{r}
iris$Species[2]<-"versicolor"
head(iris$Species)
```

若需刪除某欄位，可將欄位值設定為`NULL`
```{r}
iris$Species<-NULL ##刪除Species欄位
head(iris)
```


## 資料表 data.table
data.table是data.frame資料框型別的延伸，如要使用必須安裝data.table [@R-data.table] package，使用`data.table`讀取大型資料的速度比使用資料框快上數倍，進階處理語言也相當好用，在探索式資料分析章節Chapter \@ref(eda)會詳細介紹。其他詳細教學可見 Chapter \@ref(datatable) ，DataCamp也提供[互動式教學課程](https://www.datacamp.com/courses/data-table-data-manipulation-r-tutorial){target="_blank"}，可自行參閱。

## 資料屬性查詢函數
資料屬性可透過下列函數查詢:

- 名稱 `names()`
- 各維度名稱 `dimnames()`
- 長度 `length()`
- 各維度長度 `dim()`
- 資料型態 `class()`
- 各類資料計數 `table()`
- 總覽資料 `str()`

透過`names()`函數，可取得各種資料之名稱
```{r names1}
head(islands) ##R內建的資料
head(names(islands)) ##顯示上述資料之資料名稱
```
若為資料框，則會顯示行（欄位）名稱
```{r names2}
head(USArrests) ##R內建的資料
head(names(USArrests)) ##顯示上述資料之資料名稱
```
透過`dimnames()`函數可顯示資料框列與行的名稱，先顯示列，再顯示行
```{r dimnames１}
dimnames(USArrests) 
```
透過`length()`函數可顯示資料長度，包括向量與資料框，若資料行態為資料框，則會顯示行（欄位）數
```{r length１}
length(islands) 
length(USArrests) 
```
透過`dim()`函數可顯示資料框列與行的長度，與`dimnames()`相同，先顯示列，後顯示行
```{r dim1}
dim(USArrests) 
```
使用`class()`函數可知道變數類別
```{r class1}
class(1)
class("Test")
class(Sys.Date())
```

使用`table()`函數可知道向量中每個值出現幾次
```{r table1}
iris$Species ##原始值
table(iris$Species) ##統計結果
```
使用`str()`函數可總覽變數資訊
```{r str1}
str(iris)
str(listSample)
```


<!--chapter:end:02-data.Rmd-->

# 控制流程 {#controlstructure}


## 條件判斷
### if-else敘述
**if-else**敘述使用在邏輯判斷，若需要依條件改變需要執行的程式碼，就會使用**if-else**，若**if**後所接邏輯判斷為**真(TRUE)**，就會執行if下方之程式碼，若為**偽(FALSE)**，則執行**else**下方之程式碼，若程式中沒有**else**片段，則不執行任何程式碼。
```{r echo=FALSE}
knitr::include_graphics("figure/ifelse.png")
```

`if`與`else`下方的程式碼必須要使用`{}`將程式碼包起來，若程式碼只有一行，可省略`{}`，但為閱讀方便，建議不要省略`{}`。

舉例來說，若考試分數**大於等於60分**，則印出**及格**字樣，小於60分則印出**不及格**字樣，程式範例如下:

```{r}
score<-59
if(score>=60){
  print("及格")
}else{
  print("不及格")
}
```

```{r}
score<-80
if(score>=60){
  print("及格")
}else{
  print("不及格")
}
```

### if-else if-else
很多時候必須要使用多重邏輯判斷，若考試分數大於等於90分，印出**優良**，介於60到90分間，印出**及格**，小於60分則印出**不及格**，此時就會用到多重邏輯，使用多重邏輯時，會在`if`和`else`間新增邏輯區段**else if**，程式範例如下:

```{r}
score<-95
if(score>=90){
  print("優秀")
}else if(score>=60){
  print("及格")
}else{
  print("不及格")
}
```

`if-else if-else`敘述是有順序的，若在`if`敘述判斷為真，就算後方`else if`判斷也為真，也只會執行`if`區段的程式碼，如上述範例，95分大於等於90分(if邏輯)，也大於等於60分(else if邏輯)，但最後只印出**優秀**字樣。

###巢狀if
巢狀if是指在`if`區段程式碼內包含其他`if-else`判斷，舉例來說，若國文分數與英文分數皆大於等於60分，印出**全部及格**，國文分數大於等於60分，英文小於60分，則印**國文及格，英文再加油**，以此類推，程式範例如下:

```{r}
CHscore<-95 ##國文成績
ENscore<-55 ##英文成績
if(CHscore>=60){
  if(ENscore>=60){
    print("全部及格")
  }else{
    print("國文及格，英文再加油")
  }
}else{
  if(ENscore>=60){
    print("英文及格，國文再加油")
  }else{
    print("全部不及格")
  }
}
```

###ifelse() 
`ifelse()`函數可用最短的方式取代`if-else`敘述，使用方法為`ifelse(邏輯判斷,判斷為真要執行的程式碼,判斷為偽要執行的程式碼)`，依上述範例，重寫程式碼如下:

```{r}
score<-80
ifelse(score>=60,"及格","不及格")
```

值得注意的是，`ifelse()`可判斷向量，也就是可一次**判斷多個元素**
```{r}
scoreVector<-c(30,90,50,60,80)
ifelse(scoreVector>=60,"及格", "不及格")
```
##迴圈

###for
R語言的`for`迴圈寫法和其他語言不同，首先必須建立需要逐一執行的參數向量或序列，再使用`for`迴圈逐一執行，程式寫法為`for (單一變數 in 參數向量){ 程式碼 }`，範例如下:
```{r}
for (n in 1:10){ #n為單一變數，1:10為需要逐一執行的參數向量
  print(n)
}
```
`for`迴圈也可和`if-else`函數合併使用，如:
```{r}
for (n in 1:10){
  if(n%%2==0){ #偶數直接輸出數字
    print(n)
  }else{
    print("奇數") #奇數則輸出"奇數"
  }
}
```
###while
`while`函數則是在每次執行迴圈時檢查while邏輯判斷是否為真，若邏輯判斷為真，就會執行區段程式碼，若邏輯判斷為偽，則會結束迴圈執行。
```{r}
x<-0
while(x<=5){
  print(x)
  x<-x+1
}
```
###break
若遇特殊情形想**結束**迴圈執行，可使用`break`指令
```{r}
for(n in 1:10){
  if(n==5){
    break ##一執行到5，跳出迴圈，不再執行之後的迴圈
  }
  print(n)
}
```
###next
若遇特殊情形想**跳過**迴圈執行，可使用`next`指令
```{r}
for(n in 1:10){
  if(n==5){
    next ##跳過5，直接執行下一個迴圈
  }
  print(n)
}
```

##purrr
better than sapply() and lapply()


<!--chapter:end:03-controlstructure.Rmd-->

# 函數 {#function}
**撰寫中**

如果同一段程式碼已經被剪下貼上兩次，那就是寫一個函式(Function)的時機。

函數包含四個重要的部分:

- 名字
- 參數
- 程式碼本體
- 回傳值

```{r eval=F}
名字<-function(參數1,參數2,...){
  程式碼本體
  最後一行的輸出自動設為回傳值
}
```


寫函數的四個步驟:

- 先寫出可以用的程式碼
- 將程式碼內可以重複使用的部分指派給臨時變數
- 其餘程式碼用臨時變數表示，讓程式碼變簡潔
- 把程式碼變成函數function

寫好的函數的方法:

- 正確
- 容易閱讀與理解

函數命名原則:

- 長的函數名稱要遵循一樣的命名樣式
- 不要用原本就存在R中的函數名稱
- 可以被理解的名稱，通常是**動詞**

參數命名原則:

- 可以被理解的名稱
- 通常是**名詞**
- 輸入資料參數通常放在第一個
- 其他設定值通常會設定預設值






<!--chapter:end:04-function.Rmd-->

# 資料讀取與匯出 {#io}

資料(Data)在[維基百科](http://en.wikipedia.org/wiki/Data){target="_blank"}的定義是`values of qualitative or quantitative variables, belonging to a set of items.`，一般來說，在資料分析前會經過多個步驟，包括**資料匯入**Chapter \@ref(io)、**資料清洗處理**Chapter \@ref(manipulation)並轉換為Tidy data、**資料分析**Chapter \@ref(eda)、**資料呈現與視覺化**Chapter \@ref(vis)。

資料有多種可能來源，包括:

- 硬碟
- 網路下載
- Open Data (API)
- 網頁裡 (爬蟲！)
- 任何地方

以下介紹由檔案、網路等來源匯入多種資料格式的匯入方式，以及建議的資料匯出方法。

##從檔案匯入基本資料格式 {#file}

###Import Dataset功能 (RStudio)
[RStudio](https://www.rstudio.com/){target="_blank"} 1.0版後即提供很好的資料匯入介面，使用者可以不用撰寫任何程式碼，就能完成`.csv`、`Excel`以及`SAS`等檔案匯入。首先選取RStudio四分割視窗右上角的Environment標籤，選擇**Import Dataset**，就會出現檔案格式的選項

```{r echo=FALSE}
knitr::include_graphics("figure/import.png")
```

以csv檔案為例，在選單中選取`From CSV`，選取後會跳出資料匯入輔助視窗，點選`Browse`按鈕開啟檔案選取器，並點選欲匯入之文字檔案

```{r echo=FALSE}
knitr::include_graphics("figure/csv.png")
```

檔案選取後，資料匯入輔助視窗有預覽功能，供使用者檢查資料匯入方法是否正確，若需調整各項參數，可利用下方`Import Options`的選項微調，最常用的調整功能是`Delimiter`分隔符號與`First Row as Names`首列是否為欄位名稱。

```{r echo=FALSE}
knitr::include_graphics("figure/csv2.png")
```

如果要匯入的檔案為**tab分隔文字檔**，一樣可以選擇`.csv`選項，再修改`Delimiter`參數為`Tab`即可。

資料匯入輔助視窗右下方`Code Preview:`子視窗中會自動產生資料匯入程式碼，如果未來想再使用視窗匯入，希望透過程式碼匯入，可以將此段程式碼複製貼上到R程式碼檔案(.R)，供後續分析使用。

###分隔文字檔 .txt
`readr` [@R-readr] package提供完整的文字檔讀取功能，各讀取函數的第一個參數通常為**檔案路徑與名稱**，`read_delim()`函數可用來讀取所有用分隔符號分隔的文字檔案，以tab分隔為例，只需將`delim`參數設定為`\t`，即可用tab將各欄位分開讀取。此外，`col_names`參數也常被使用，TRUE代表資料內有包含欄位名稱(通常在首列)，預設為TRUE，如果設定為FALSE，欄位名稱則會依順序被設定為 X1, X2, X3 ...。

參數整理如下 (可用?read_delim指令閱讀官方說明)：

- `file`, 檔名
- `delim`, 分隔符號
- `quote`, 把欄位包起來的符號
- `escape_backslash`, 預設FALSE，是否用/作為逃脫符號
- `escape_double`, 預設TRUE，是否用quote符號作為逃脫符號
- `col_names`, 是否有欄位名稱（表頭）（T/F）
- `col_types`, 每一個欄位的類別，用向量表示 
- `comment`, 備註標示符號，在備註標示符號之後的文字不會被讀入
- `skip`, 要跳過幾行？

```{r eval=F}
library(readr)
dataset <- read_delim("檔案路徑與名稱", delim="\t")
```

###CSV檔案 .csv {#csv}
`readr` [@R-readr] package也提供CSV (逗號分隔)檔案的讀取功能，`read_csv()`
```{r eval=F}
library(readr)
dataset <- read_csv("檔案路徑與名稱")
```

###Excel檔案 .xls
`readxl` [@R-readxl] package提供讀取Excel檔案 (xls, xlsx)的函數`read_excel()`，除了常用的`col_names`參數外，也可使用`sheet`參數設定要讀取的工作表(sheet)
```{r eval=F}
library(readxl)
dataset <- read_excel("檔案路徑與名稱")
```

###R物件 .rds
R物件有檔案小與讀取快速的優點，如果在R程式處理資料後必須儲存一份以供後續分析的話，使用R物件儲存是最佳的方式，讀取R物件有多種函數可供選擇，推薦使用`readRDS()`函數 (參考資料:[A better way of saving and loading objects in R](http://www.fromthebottomoftheheap.net/2012/04/01/saving-and-loading-r-objects/){target="_blank"})
```{r eval=F}
dataset <- readRDS("檔案路徑與名稱")
```

###R程式 .R
`source`, 讀R的Obejct or script, 執行, ASCII (`dump`的相反) 

### 純文字資料 (無分隔)
`readLines`, 逐行讀取文字資料

###其他格式
透過載入套件，R可讀入許多其他格式的檔案:

- MySQL `RMySQL`
- HDF5 `rhdf5`
- Weka `foreign`
- Stata `foreign`
- SPSS `Hmisc`
- SAS `Hmisc`
- GIS `rgdal`
- Images `jpeg`
- Music `tuneR`

### 其他讀檔注意事項
讀檔的時候R會自動

- 跳過#開頭的任何行（Row）
- 判斷要讀幾行
- 判斷每個列（Column）的類別
- 把欄位包起來的符號

如果讀取時已指定**Column類別**以及**把欄位包起來的符號**，讀取速度會快很多。

##從網路匯入資料
### Open Data
**開放資料** (Open data) 指的是一種經過挑選與許可的資料，這些資料不受著作權、專利權，以及其他管理機制所限制，可以開放給社會公眾，任何人都可以自由出版使用，不論是要拿來出版或是做其他的運用都不加以限制。Open data 運動希望達成的目標與開放原始碼、內容開放、開放獲取等其他「開放」運動類似。Open data 背後的核心思想由來已，但 Open data 這名詞直到近代才出現，拜網際網路崛起而為人所知，尤其是 Data.gov 等 Open data 政府組織的設立。([維基百科](https://zh.wikipedia.org/wiki/%E9%96%8B%E6%94%BE%E8%B3%87%E6%96%99){target="_blank"})

台灣政府從2011年開始大力推動開放政府與開放資料的概念，多個機關與縣市政府架設開放資料平台，供民眾擷取或再利用各項資料

- [政府資料開放平台](http://data.gov.tw/){target="_blank"}
- [Data Taipei](http://data.taipei/){target="_blank"}
- [開放資料 x 開放桃園](http://data.tycg.gov.tw/){target="_blank"}
- [內政資料開放平台](http://data.moi.gov.tw/){target="_blank"}

Open Data常見的儲存方式為: `CSV`Chapter \@ref(csv)、`JSON`Chapter \@ref(json)、`XML`Chapter \@ref(xml)，開放資料網站通常有提供民眾**直接下載**檔案的服務，針對可下載的CSV格式資料，可以下載完成後，透過上述**由檔案匯入資料** Chapter \@ref(file)方法匯入即可。

### API (Application programming interfaces) {#api}
應用程式介面 Application programming interfaces (API) 通常是特定軟體、程序或系統，廠商或開發人員，為了能夠讓第三方的開發者可以額外開發應用程式來強化他們的產品，所推出可以與他們系統溝通的介面。([維基百科](https://zh.wikipedia.org/zh-tw/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%8E%A5%E5%8F%A3){target="_blank"})

以下載Open Data為例，若檔案更新頻繁，使用手動下載相當耗時。如[臺北市開放認養動物](http://data.taipei/opendata/datalist/datasetMeta?oid=6a3e862a-e1cb-4e44-b989-d35609559463){target="_blank"}資料，更新頻率為每日，所以許多開放資料也提供透過**API**下載的服務，透過API下載的資料格式會是JSON格式Chapter \@ref(json)，如[臺北市開放認養動物API資訊](http://data.taipei/opendata/datalist/datasetMeta/outboundDesc?id=6a3e862a-e1cb-4e44-b989-d35609559463&rid=f4a75ba9-7721-4363-884d-c3820b0b917c){target="_blank"}所示，開放資料網站會提供**資料集ID**與**資料RID**

- **資料集ID**: 紀錄資料的基本參數，如包含欄位、更新頻率等
- **資料RID**: 資料集

並同時提供擷取範例，如果需要下載原始資料，可直接從範例複製貼上即可，如http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=f4a75ba9-7721-4363-884d-c3820b0b917c



###JSON格式檔案 {#json}
JSON (**J**ava**s**cript **O**bject **N**otation)是一種輕量級的資料交換語言 ([Wiki](http://en.wikipedia.org/wiki/JSON){target="_blank"})，特色如下:

- from **a**pplication **p**rogramming **i**nterfaces (APIs)
- JavaScript、Java、Node.js應用
- 一些NoSQL非關連型資料庫用JSON儲存資料：**MongoDB**
- 資料儲存格式
    - Numbers (double)
    - Strings (double quoted)
    - Boolean (_true_ or _false_)
    - Array (ordered, comma separated enclosed in square brackets _[]_)
    - Object (unorderd, comma separated collection of **key:value** pairs in curley brackets _{}_)

[JSON檔案範例](https://api.github.com/users/yijutseng/repos){target="_blank"}

許多Open Data也用JSON格式儲存，例如[臺北市開放認養動物](http://data.taipei/opendata/datalist/datasetMeta?oid=6a3e862a-e1cb-4e44-b989-d35609559463){target="_blank"}資料，根據資料的API資訊，可得資料擷取網址http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=f4a75ba9-7721-4363-884d-c3820b0b917c 。

將JSON檔案匯入R可以使用`jsonlite`[@R-jsonlite] package，套件使用前必須安裝，安裝套件方法請參考Chapter \@ref(intro)，載入後，可使用`fromJSON()`函數載入JSON資料。
如API網址為**httr**類別，需要載入`httr`[@httr] package，並使用`GET()`函數處理資料擷取網址。
```{r message=FALSE,warning=FALSE}
PetData<-jsonlite::fromJSON("http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=f4a75ba9-7721-4363-884d-c3820b0b917c")
str(PetData)
```
由資料結構可知，經過`fromJSON()`函數匯入的JSON檔案被轉存為`列表list`的型態，且在result元素中包含五個子元素(offset, limit, count, sort, results)，其中，results子元素的類別為資料框data.frame，內含開放認養動物清單，因此，可使用`$`符號截取元素與子元素
```{r readJSON}
head(PetData$result$results)
```
results資料框中包含20個欄位，可以像分析資料框一樣，針對此資料框做分析，舉例來說，可分析各項**開放認養理由**出現次數
```{r readJSON1}
table(PetData$result$results$Reason)
```
分析可知開放認養理由以動物管制與未填寫居多。

如果需要將資料框轉換成JSON檔案可以使用`jsonlite` package所提供的`toJSON()`函數。
```{r writeJSON}
myjson <- jsonlite::toJSON(iris, pretty=TRUE)
str(myjson)
```


### XML 可延伸標記式語言 {#xml}
- E**x**tensible **m**arkup **l**anguage
- 描述**結構化**資料的語言
- 處理XML檔案是網頁**Html**爬蟲的基礎
- Components
    - Markup 標記 - labels that give the text structure
    - Content 內文 - the actual text of the document
- [XML Wiki](https://zh.wikipedia.org/wiki/XML){target="_blank"}

Tags, elements and attributes

- Tags correspond to general labels
    - Start tags `<breakfast_menu>`, `<price>`
    - End tags `</breakfast_menu>`,`</price>`
    - Empty tags `<line-break />`
- Elements are specific examples of tags
    - `<name>Belgian Waffles</name>`
- Attributes are components of the label
    - `<book category="web">`
    
許多Open Data也用XML格式儲存，例如[臺北市水質監測資訊](http://data.taipei/opendata/datalist/datasetMeta/download?id=961ca397-4a59-45e8-b312-697f26b059dc&rid=190796c8-7c56-42e0-8068-39242b8ec927){target="_blank"}。如需將XML檔案匯入R中，需要安裝`XML` [@R-XML] package，使用`xmlParse()`函數將檔案匯入。若出現`Error: 1: Unknown IO error2: failed to load external entity`，是因為XML套件處理http轉https的功能的不好，載入httr套件後，先使用GET()功能取用網址，再放入xmlParse()就不會有問題。

```{r}
library(XML)
library(httr)
waterQ <- xmlParse(GET("https://data.taipei/opendata/datalist/datasetMeta/download?id=961ca397-4a59-45e8-b312-697f26b059dc&rid=190796c8-7c56-42e0-8068-39242b8ec927"))
```

完成資料讀取後，使用`xpathSApply()`函數搭配**XPath**語法取得指定標籤內的資料，依需求也可改用`xpathApply()`函數，差別在於`xpathSApply()`函數回傳的物件是Vector 向量
，而`xpathApply()`回傳的物件是List 列表。
```{r}
#取得所有"code_name"標籤內的資料
xpathSApply(waterQ,"//code_name",xmlValue)[1:10]
#取得各監測站的經度
xpathSApply(waterQ,"//longitude",xmlValue)[1:10]
```

在`xpathApply()`與`xpathSApply()`函數中，第二個參數為**XPath**，**XPath**是XML路徑語言（XML Path Language），基於XML的樹狀結構，提供在資料結構樹中找尋節點的能力，**XPath**語法的邏輯，可參考[W3C Schools](https://www.w3schools.com/xml/xpath_syntax.asp){target="_blank"}或是Google搜尋相關中文教學，如[lxml、XPath 常用語法](http://tech-marsw.logdown.com/blog/2016/01/11/parsing-lxml-xpath-sheet){target="_blank"}。在此列舉幾個常用的語法:

```
// : 子結點資料, 如所有連結標籤 //a
@ : 屬性資料, 如所有連結標籤內的連結網址 //a/@href
```

### 網頁爬蟲 Webscraping

由於不是每個網站都提供API，但網頁上卻有你想要分析的資料（像是ptt推文！？），除了人工複製貼上以外，也可以將網頁處理程式化，以程式化的方式擷取網頁資料就叫做**網頁爬蟲（Webscraping）**（[Webscraping Wiki](http://en.wikipedia.org/wiki/Web_scraping){target="_blank"}）。在R中可以直接把HTML檔案當作XML檔案處理分析，也可使用`rvest`[@R-rvest] package輔助爬蟲程式撰寫。

此外，網頁爬蟲可能耗費很多網頁流量和資源，所以在許多網站被視為非法行為，如果一次讀太多太快，很可能被鎖IP。

以[長庚資管系](http://im.cgu.edu.tw/bin/home.php){target="_blank"}網站為例，可直接逐行讀取 `readLines()`

```{r}
con <- url("http://im.cgu.edu.tw/bin/home.php")
htmlCode <-readLines(con)
close(con)
htmlCode[1:5]
```

或是使用XML工具分析擷取網頁 (`XML` package)，使用方法與XML檔案處理方法類似，搭配**XPath**語言，篩選所需資料

```{r xmlhtml, warning=F}
html <- htmlParse("http://im.cgu.edu.tw/bin/home.php")
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//span[@class='ptname ']", xmlValue)
```

除了把HTML檔案當作XML處理外，`rvest`[@R-rvest] package是R語言中最常被使用的爬蟲套件，使用前一樣需要安裝與載入
```{r eval=F}
install.packages("rvest") ##安裝
```
```{r rvest,  eval=F,warning=F, message=F}
library(rvest) ##載入
```
載入`rvest`套件後，經由以下步驟進行網站解析：

- 使用`read_html(“欲擷取的網站網址”)`函數讀取網頁
- 使用`html_nodes()`函數擷取所需內容 (條件為CSS或xpath標籤)
- 使用`html_text()`函數處理/清洗擷取內容，留下需要的資料
- 使用`html_attr()`函數擷取資料參數（如連結url）

```{r eval=F}
YahooNewsurl="https://tw.news.yahoo.com/"
news_title = read_html(YahooNewsurl) %>% html_nodes(".tpl-title a") %>% html_text()
news_url = read_html(YahooNewsurl) %>% html_nodes(".tpl-title a") %>% html_attr("href")
Yahoo_news = data.frame(title = news_title, url=news_url)
head(Yahoo_news)
```

```
                                    title                                                           url
1         曾1妻5妾好風光 男星慘賣豪宅還債 /從1妻5妾的風光到變賣豪宅還債-網友噓雷洪：活該-091741737.html
2          美報告：美棄「一中」台灣更危險               /美報告-美拋棄-中-台灣處境更危險-081036215.html
3           藍色凍蕃薯！1張圖看寒流有多冷       /霸王級寒流再襲台-張圖看懂這波寒流有多強-101500692.html
4           他被妻子戴綠帽 對象竟是親弟弟                 /他被妻子戴綠帽-對象竟是親弟弟-072010033.html
5               匆忙推出移民禁令 他後悔了           /匆忙推移民禁令-美國土安全部長表後悔-044517088.html
6 蔡政府對釣魚台態度 國民黨憂美日安保質變       /蔡政府對釣魚台態度-國民黨憂美日安保質變-160200179.html
```

在`html_nodes()`、`html_text()`和`html_attr()`函數中，擷取條件的撰寫會因網頁語法不同而有差異，必須要使用**Google Chrome開發工具**等工具輔助觀察需要擷取資料的條件。以上述Yahoo新聞為例，需要擷取的資料所在HTML片段如下：

```
<ul class="tpl-title yom-list list-style-none" id="yui_3_9_1_1_1486568229946_2408">
<li class="list-story first" id="yui_3_9_1_1_1486568229946_2407">
<div class="txt" id="yui_3_9_1_1_1486568229946_2406">
<a href="/從1妻5妾的風光到變賣豪宅還債-網友噓雷洪：活該-091741737.html" class="title " data-ylk="pkg:96a0ca11-47bc-3100-81ad-0a288707f150;ver:60cdb126-ee0c-11e6-bb9b-8a777738a932;lt:i;pos:1;" data-rapid_p="1">曾1妻5妾好風光 男星慘賣豪宅還債</a>
<cite id="yui_3_9_1_1_1486568229946_2405">
<span class="provider" id="yui_3_9_1_1_1486568229946_2404">Yahoo奇摩娛樂新聞</span>
</cite></div></li>
....
```
觀察上述程式碼可已發現新聞清單被包含在`ul`標籤下，且css class為`tpl-title yom-list list-style-none`，所以這邊可以使用第一個class`tpl-title`為篩選條件。CSS 標籤的意義可參考[W3C Schools](https://www.w3schools.com/cssref/css_selectors.asp)的教學{target="_blank"}。在此整理常用的語法：

- CSS Selector 常見語法 [參考資料](https://www.w3schools.com/cssref/css_selectors.asp)
    - **.**xxx：select elements with class="xxx"
    - **#**xxx：select elements with id="xxx"
    - **[**yyy**]**：select elements with attribute yyy
    - **[**yyy=zzz**]**：select elements with attribute yyy="zzz"
    
網頁爬蟲需要多做觀察與練習，才可熟知篩選技巧。

其他爬蟲相關參考資源:

- [網路爬蟲實作 - 用 r 語言打造自己的爬蟲程式](https://www.slideshare.net/secret/mdfHLPgvIW1kPR){target="_blank"} 
- [rvest GitHub](https://github.com/hadley/rvest){target="_blank"} 
- R Bloggers 有很多[爬蟲範例](http://www.r-bloggers.com/?s=Web+Scraping){target="_blank"}（英文）
- [Ptt爬蟲實作](http://bryannotes.blogspot.tw/2014/08/r-ptt-wantedsocial-network-analysis.html){target="_blank"} 
- [大數學堂 網頁爬蟲課程](http://www.largitdata.com/course_list/1){target="_blank"}
- [搭配結巴中文斷詞的使用範例](https://github.com/CGUIM-BigDataAnalysis/BigDataCGUIM/blob/master/105/JiebaR.md){target="_blank"}

## Facebook資料擷取
Facebook提供[Graph API](https://developers.facebook.com/docs/graph-api?locale=zh_TW){target="_blank"}，讓應用程式可透過API讀取與寫入 Facebook相關資料，**Graph API**會根據篩選條件，回傳JSON格式的資料。除此之外，Facebook還提供[Graph API Explorer](https://developers.facebook.com/tools/explorer/){target="_blank"}，讓程式開發人員可以測試資料撈取方法和結果。
在開始使用**Graph API**之前，必須要取得自己的**access token** (存取權杖)，[Graph API Explorer](https://developers.facebook.com/tools/explorer/){target="_blank"}工具提供**Get Token**按鈕(通常在視窗右上角)，可以讓開發者在不用新增應用程式(Application)的情況下取得暫時的**access token**。

有關Facebook access token的詳細介紹，可參考[官方文件](https://developers.facebook.com/docs/facebook-login/access-tokens/?locale=zh_TW){target="_blank"}

### Graph API in R
```{r eval=FALSE, warning=F}
library(httr)
token<-"your token" #將access token複製到此處 
FBData = GET(
    paste0("https://graph.facebook.com/v2.8/tsaiingwen?fields=posts%7Bmessage%7D&access_token=",
           token))
names(FBData)
```

```
## [1] "url"         "status_code" "headers"     "all_headers" "cookies"     "content"     "date"       
## [8] "times"       "request"     "handle"    
```

```{r eval=FALSE}
json1 = content(FBData)
names(json1)
```
```
## [1] "posts" "id"
```
```{r eval=FALSE}
names(json1$posts)
```
```
## [1] "data"   "paging"
```
```{r eval=FALSE}
head(json1$posts$data,3)
```
```
[[1]]
[[1]]$message
[1] "「國機國造」不是夢想，而是一個行動。今天啟動的高級教練機「自研自製」任務，是國防自主的重要里程碑。我們不只要讓戰機起飛，更要讓產業起飛。\n\n國防產業同樣是「5+2」關鍵產業之一，所以，除了要如期、如質完成新式高教機的「自研自製」外，也要重新厚植台灣的航太工業人才鏈，以及加強相關產業的連結、轉型和升級。\n\n國防自主沒有捷徑，只有努力再努力、堅持再堅持。今天，我們重新跨出歷史性的一步。"

[[1]]$id
[1] "46251501064_10154006497451065"


[[2]]
[[2]]$message
[1] "今天，智慧機械推動辦公室正式啟動。「落實產學合作」、「支持創新研發」、「強化行銷通路」是辦公室的三項重點任務。\n\n智慧機械是「5+2」關鍵產業的其中之一。政府有決心。我相信，所有的機械業者－無論做的是螺桿、刀庫、控制器或是工作母機，大家也都有很強的決心，要走向創新、走向智慧化、走向品牌。我們是一個團隊，我們一起加油！"

[[2]]$id
[1] "46251501064_10154006456601065"


[[3]]
[[3]]$message
[1] "今天來向台商拜個晚年。我也邀請台商朋友們，共同參與台灣經濟轉型升級的世紀工程。\n\n無論是擴大對國內的投資，或者配合新南向政策，前進海外深耕佈局，我期待跟台商朋友們一起努力，群策群力，克服困難和瓶頸，為台灣經濟發展打開全新的局面。"

[[3]]$id
[1] "46251501064_10154001652641065"

```


```{r eval=FALSE}
json1$posts$data[[1]]$message
```
```
##[1] "「國機國造」不是夢想，而是一個行動。今天啟動的高級教練機「自研自製」任務，是國防自主的重要里程碑。我們不只要讓戰機起飛，更要讓產業起飛。\n\n國防產業同樣是「5+2」關鍵產業之一，所以，除了要如期、如質完成新式高教機的「自研自製」外，也要重新厚植台灣的航太工業人才鏈，以及加強相關產業的連結、轉型和升級。\n\n國防自主沒有捷徑，只有努力再努力、堅持再堅持。今天，我們重新跨出歷史性的一步。"
```
### Rfacebook package
除了直接使用Graph API外，也可使用`Rfacebook`[@R-Rfacebook] package來讀取Facebook資料。
以下為使用Rfacebook取得 `tsaiingwen` 粉絲頁的資料範例：
```{r eval=FALSE}
library(Rfacebook)
token<-"your token" #將token複製到此處 
getPage("tsaiingwen", token,n = 5)
```
```
5 posts       from_id           from_name
1 46251501064 蔡英文 Tsai Ing-wen
2 46251501064 蔡英文 Tsai Ing-wen
3 46251501064 蔡英文 Tsai Ing-wen
4 46251501064 蔡英文 Tsai Ing-wen
5 46251501064 蔡英文 Tsai Ing-wen
                                                                                                                                                                                                                                                                                                                                                                                        message
1 「國機國造」不是夢想，而是一個行動。今天啟動的高級教練機「自研自製」任務，是國防自主的重要里程碑。我們不只要讓戰機起飛，更要讓產業起飛。\n\n國防產業同樣是「5+2」關鍵產業之一，所以，除了要如期、如質完成新式高教機的「自研自製」外，也要重新厚植台灣的航太工業人才鏈，以及加強相關產業的連結、轉型和升級。\n\n國防自主沒有捷徑，只有努力再努力、堅持再堅持。今天，我們重新跨出歷史性的一步。
2                                                                   今天，智慧機械推動辦公室正式啟動。「落實產學合作」、「支持創新研發」、「強化行銷通路」是辦公室的三項重點任務。\n\n智慧機械是「5+2」關鍵產業的其中之一。政府有決心。我相信，所有的機械業者－無論做的是螺桿、刀庫、控制器或是工作母機，大家也都有很強的決心，要走向創新、走向智慧化、走向品牌。我們是一個團隊，我們一起加油！
3                                                                                                                                                          今天來向台商拜個晚年。我也邀請台商朋友們，共同參與台灣經濟轉型升級的世紀工程。\n\n無論是擴大對國內的投資，或者配合新南向政策，前進海外深耕佈局，我期待跟台商朋友們一起努力，群策群力，克服困難和瓶頸，為台灣經濟發展打開全新的局面。
4                                                                                                                                                                                                                                                                                    「快了」！雞年通機捷，等待很值得。大年初四，我來看看機場捷運通車前的準備，也坐捷運到中壢，跟鄉親拜年問好。
5                                                                                                                                                                                                                                                                                                            雞年初三發福袋\n\n臺中豐原慈濟宮、彰化溪湖福安宮、雲林北港朝天宮、嘉義九華山地藏庵
              created_time  type
1 2017-02-07T08:02:45+0000 photo
2 2017-02-07T07:18:00+0000 photo
3 2017-02-05T07:12:52+0000 photo
4 2017-01-31T08:37:42+0000 photo
5 2017-01-30T11:41:07+0000 photo
                                                                                                    link
1 https://www.facebook.com/tsaiingwen/photos/a.390960786064.163647.46251501064/10154006497206065/?type=3
2 https://www.facebook.com/tsaiingwen/photos/a.390960786064.163647.46251501064/10154006455396065/?type=3
3 https://www.facebook.com/tsaiingwen/photos/a.390960786064.163647.46251501064/10154001652641065/?type=3
4 https://www.facebook.com/tsaiingwen/photos/a.390960786064.163647.46251501064/10153989357181065/?type=3
5 https://www.facebook.com/tsaiingwen/photos/a.390960786064.163647.46251501064/10153987089121065/?type=3
                             id likes_count comments_count shares_count
1 46251501064_10154006497451065        2013            125           43
2 46251501064_10154006456601065        2217            163           57
3 46251501064_10154001652641065        9416            920          163
4 46251501064_10153989358051065       34116           1574          373
5 46251501064_10153987095776065       20592            665          269
```

由於每次擷取資料的比數有上限（大概是30筆左右），如果需要取得更多更長期的資料，就要使用迴圈協助，分批取得資料，透過設定 **since** 和 **until**參數，可設定資料擷取區間。

首先先取得日期向量，供後續迴圈做使用
```{r eval=FALSE}
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2017-01-01"),lastDate,by="5 days")
DateVectorStr<-as.character(DateVector)
DateVectorStr
```
```
## "2017-01-01" "2017-01-06" "2017-01-11" "2017-01-16" "2017-01-21" "2017-01-26" "2017-01-31" "2017-02-05"
```

利用上述日期向量資料，搭配迴圈，依序設定**since** 和 **until**參數
```{r eval=FALSE}
totalPage<-NULL
token<-'your token'
numberOfPost<-30
for(i in 1:(length(DateVectorStr)-1)){
    tempPage<-getPage("tsaiingwen", token,
                      since = DateVectorStr[i],until = DateVectorStr[i+1])
    totalPage<-rbind(totalPage,tempPage)
}
nrow(totalPage)
```
```
## 4 posts 8 posts 10 posts 3 posts 2 posts 14 posts 1 posts
## [1] 42
```

Rfacebook Packages提供其他函數可供使用

- getUsers()
- getPost()
- searchFacebook()
- Check https://github.com/pablobarbera/Rfacebook
- ?Rfacebook


##資料匯出
在R中完成資料處理後，有多種匯出選擇，如果是要匯出供他人在其他環境(如Excel)使用，建議匯出成tab分隔的文字檔(.txt)或是逗號分隔的文字檔(.csv)；但若是要在R的環境繼續使用，建議匯出成R物件 (.rds)，除了可保留欄位型別設定外，讀取速度與檔案大小皆優於文字檔案。

###文字檔 .txt
使用`write.table()`函數寫入檔案，需要參數有

- `x` 要匯出的檔案，通常為matrix或是data.frame格式
- `file` 檔案名稱
- `append` T/F TRUE表示在檔案後端加入文字，F表示直接覆蓋原始檔案 (預設F)
- `quote` 是否需要用雙引號將字串包起 (預設T)
- `sep` 分隔符號 (預設空白)
- `eol` 換行符號
- `na` 表示空值的字串
- `dec` 小數點表示法
- `row.names` T/F 是否需要輸出row names
- `col.names` T/F 是否需要輸出column names
- `qmethod` 逃脫字串設定
- `fileEncoding` 編碼設定

```{r eval=FALSE}
write.table(iris,file="iris.txt",sep=",",row.names = F,col.names = T)
```

###CSV檔 .csv
與`write.table()`類似，使用`write.csv()`函數寫入檔案
```{r eval=FALSE}
write.csv(iris,file="iris.csv",row.names = F)
```

###R物件 .rds
若是要在R的環境繼續使用，建議匯出成R物件檔案(.rds)
```{r eval=FALSE}
saveRDS(iris,"iris.rds")
```



<!--chapter:end:05-io.Rmd-->

# 資料處理與清洗 {#manipulation}

## Tidy Data
Each column is a variable. Each row is an observation.

- 一個欄位（Column）內只有一個數值，最好要有凡人看得懂的Column Name
- 不同的觀察值應該要在不同行（Row）
- 一張表裡面，有所有分析需要的資料
- 如果一定要多張表，中間一定要有index可以把表串起來
- One file, one table

## 資料型別轉換處理
在資料型態章節Chapter \@ref(DataType)中，曾介紹**數值 (numeric)**、**字串 (character)**、**布林變數 (logic)**以及**日期 (Date)**等資料型態，在此章節中將介紹如何檢查變數型別與各型別的轉換。

###資料型別檢查
使用以下`is.`函數檢查資料型別，回傳布林變數，若為真，回傳TRUE

- 是否為**數字** `is.numeric(變數名稱)`
- 是否為**文字** `is.character(變數名稱)`
- 是否為**布林變數** `is.logical(變數名稱)`

```{r}
num<-100
cha<-'200'
boo<-T
is.numeric(num)
is.numeric(cha)
is.character(num)
is.character(cha)
is.logical(boo)
```

或使用`class(變數名稱)`函數，直接回傳資料型別
```{r}
class(num)
class(cha)
class(boo)
class(Sys.Date())
```

###資料型別轉換
使用以下`as.`函數轉換型別

- 轉換為**數字** `as.numeric(變數名稱)`
- 轉換為**文字** `as.character(變數名稱)`
- 轉換為**布林變數** `as.logical(變數名稱)`

```{r}
as.numeric(cha)
as.numeric(boo)
as.character(num)
as.character(boo)
```
若無法順利完成轉換，會回傳空值`NA`，並出現警告訊息`Warning: NAs introduced by coercion，Warning: 強制變更過程中產生了 NA`
```{r}
as.numeric("abc")
```

日期的轉換則建議使用`lubridate`[@R-lubridate] package，如果想要將`年/月/日`格式的文字轉換為日期物件，可使用`ymd()`函數（y表年year，m表月month，d表日day），如果想要將`月/日/年`格式的文字轉換為日期物件，則使用`mdy()`函數，以此類推。

```{r ,message=F}
library(lubridate)
ymd('2012/3/3')
mdy('3/3/2012')
```

## 文字字串處理

### 基本處理

- 切割 `strsplit()`
- 子集 `substr()`
- 大小寫轉換 `toupper()` `tolower()`
- 兩文字連接 `paste()` `paste0()`
- 文字取代 `gsub()`
- 前後空白去除 `str_trim()` 需安裝`stringr`[@R-stringr] package

```{r}
strsplit ("Hello World"," ")
toupper("Hello World")
tolower("Hello World")
paste("Hello", "World", sep='')
substr("Hello World", start=2,stop=4)
gsub("o","0","Hello World")
library(stringr)
str_trim(" Hello World ")
```

### 搜尋字串
搜尋字串函數通常使用在**比對文字向量**，文字比對**有分大小寫**，依照回傳值的型態不同，有兩種常用函數，`grep()`與`grepl()`:

- 回傳符合條件之向量位置(index) `grep(搜尋條件,要搜尋的向量)`
- 回傳每個向量是否符合條件(TRUE or FALSE) `grepl(搜尋條件,要搜尋的向量)`

```{r}
grep("A",c("Alex","Tom","Amy","Joy","Emma")) ##在姓名文字向量中尋找A，回傳包含"A"之元素位置
```

```{r}
grepl("A",c("Alex","Tom","Amy","Joy","Emma")) ##在姓名文字向量中尋找A，回傳各元素是否包含"A"
grepl("a",c("Alex","Tom","Amy","Joy","Emma")) ##在姓名文字向量中尋找a，回傳各元素是否包含"a"
```

### 正規表示式 (Regular Expression)

字串處理通常會搭配正規表示式 (Regular Expression)

Regular Expression (正規表示式)是指一組能用來表示字串共同格式 (common structure)的樣式 (Pattern)，像是`@`符號會固定出現在email中，或是手機號碼固定是10碼，等等樣式。
在所有的程式語言中，只要用到**字串比對**與**字串取代**等字串相關功能，都會用到正規表示式。雖然正規表示式在不同程式語言中會有些許差異，但核心概念是相同的。

以下是常見的範例:

|語法          |正則表達式    |範例          |
|--------------|--------------|--------------|
|整數|[0-9]+|5815|
|浮點數|[0-9]+\.[0-9]+|58.15|
|純英文字串|[A-Za-z]+|CGUIM|
|Email|[a-zA-Z0-9_]+@[a-zA-Z0-9._]+|`im@mail.cgu.edu.tw`|
|URL|`http://[a-zA-Z0-9./_]+`|`http://www.is.cgu.edu.tw/`|


可以用正規表示式的R函數如下：

- grep()
- grepl()
- gsub()
- str_split()
- stringr package中的諸多函數

正規表示式的常用語法分類如下：

- 逃脫字元
- 表示數量 
- 表示位置
- 運算子
- 特殊符號

#### 逃脫字元

**\**

#### 表示數量的語法

- `*`: 出現0~無限多次
- `+`: 出現1~無限多次
- `?`: 出現0~1次
- `{n}`: 出現n次
- `{n,}`: 出現n~無限多次
- `{n,m}`: 出現n~m次

```{r}
stringVector<-c("a","abc","ac","abbc","abbbc","abbbbc")
grep("ab*",stringVector,value=T)
grep("ab+",stringVector,value=T)
grep("ab?c",stringVector,value=T)
grep("ab{2}c",stringVector,value=T)
grep("ab{2,}c",stringVector,value=T)
grep("ab{2,3}c",stringVector,value=T)
```

#### 表示位置的語法

- `^`: 出現在字串開始的位置
- `$`: 出現在字串結束ˇ的位置
- `\b`: 出現空字串(空白)開始或結束的位置
- `\B`: 出現非字串開始或結束的位置

```{r}
stringVector<-c("abc","bcd","cde","def","abc def","bcdefg abc")
grep("^bc",stringVector,value=T)
grep("bc$",stringVector,value=T)
grep("\\bde",stringVector,value=T)
grep("\\Bde",stringVector,value=T)
```

#### 運算子

- `.`: 出現所有的字元一次，包括空字串
- `[...]`: 出現字元清單(...)中的字元一次，可用`-`表示範圍，如`[A-Z]`，`[a-z]`，`[0-9]`
- `[^...]`: 不出現字元清單(...)中的字元
- `\`: 要搜尋字串中的特殊字元時，前方須加上`\`
- `|`: 或

```{r}
stringVector<-c("03-2118800","02-23123456","0988123456",
                "07-118","0-888","csim@mail.cgu.edu.tw","csim@.","csim@",
                "http://www.is.cgu.edu.tw/")
grep("[0-9]{2}-[0-9]{7,8}",stringVector,value=T)
grep("[0-9]{10}",stringVector,value=T)
grep("02|03",stringVector,value=T)
grep("[a-zA-Z0-9_]+@[a-zA-Z0-9._]+",stringVector,value=T)
```

#### 特殊符號

- `\d`: 數字，等於 [0-9]
- `\D`: 非數字，等於 [^0-9]
- `[:lower:]`: 小寫字，等於 [a-z]
- `[:upper:]`: 大寫字，等於 [A-Z]
- `[:alpha:]`: 所有英文字，等於 [[:lower:][:upper:]] or [A-z]
- `[:alnum:]`: 所有英文字和數字，等於 [[:alpha:][:digit:]] or [A-z0-9]
- `\w`: 文字數字與底線，等於 [[:alnum:]_] or [A-z0-9_]
- `\W`: 非文字數字與底線，等於 [^A-z0-9_]
- `[:blank:]`: 空白字元，包括空白和tab
- `\s`: 空白字元, ` `
- `\S`: 非空白字元
- `[:punct:]`: 標點符號 ! " # $ % & ’ ( ) * + , - . / : ; < = > ? @ [  ] ^ _ ` { | } ~.

```{r}
stringVector<-c("03-2118800","02-23123456","0988123456",
                "07-118","0-888","csim@mail.cgu.edu.tw","http://www.is.cgu.edu.tw/")
grep("\\d{2}-\\d{7,8}",stringVector,value=T)
grep("\\d{10}",stringVector,value=T)
grep("\\w+@[a-zA-Z0-9._]+",stringVector,value=T)
```

#### 參考資料

- [Regular Expression 詳論](https://dotblogs.com.tw/johnny/archive/2010/01/25/13301.aspx)
- [RegExLib.com](http://regexlib.com/)
- [Regular Expression in R](http://stat545.com/block022_regular-expression.html)

##子集Subset {#subset}

###一維資料 (向量)
在向量章節`{#vector}`有介紹使用`[]`取出單一或多個元素的方法
```{r}
letters ##R語言內建資料之一
letters[1] ##取出letters向量的第一個元素
letters[1:10] ##取出letters向量的前十個元素
letters[c(1,3,5)] ##取出letters向量的第1,3,5個元素
letters[c(-1,-3,-5)] ##取出letters向量除了第1,3,5個元素之外的所有元素
```

若想要快速取得一向量的開頭與結尾元素，可使用`head()`和`tail()`函數
```{r}
head(letters,5) ##取出letters向量的前五個元素
tail(letters,3) ##取出letters向量的後三個元素
```

###二維資料
最常見的二維資料為data.frame資料框，二維資料可針對列(Row)和行(Column)做子集，子集選擇方式一樣是使用`[]`，但因應二維資料的需求，以`,`分隔列與行的篩選條件，資料篩選原則為**前Row,後Column**，**前列,後行**，若不想篩選列，則在`,`前方保持**空白**即可。

篩選方式可輸入位置(index)、欄位名稱或輸入布林變數(TRUE/FALSE)

- 輸入位置: `dataFrame[row index,column index]`
- 輸入布林變數: `dataFrame[c(T,F,T),c(T,F,T)]`
- 輸入欄位名稱: `dataFrame[row name,column name]`

```{r Species}
data(iris)
iris[1,2] ##第一列Row，第二行Column
iris[1:3,] ##第1~3列Row，所有的行Column
iris[,"Species"] ##所有的列Row，名稱為Species的行Column
iris[1:10,c(T,F,T,F,T)] ##第1~10列Row，第1,3,5行Column (TRUE)
```

也可使用`$`符號做**Column的篩選**
```{r}
iris$Species ##所有的列Row，名稱為Species的行Column
```

**Row的篩選**可使用`subset()`函數，使用方法為`subset(資料表,篩選邏輯)`

```{r}
subset(iris,Species=="virginica") ##Species等於"virginica"的列Row，所有的行Column
```

**Row的篩選**也可搭配字串搜尋函數`grepl()`

```{r}
knitr::kable(iris[grepl("color",iris$Species),]) ##Species包含"color"的列，所有的行
```

若想要快速取得資料框的前幾列(Row)或後幾列，也可使用`head()`和`tail()`函數
```{r}
head(iris,5) ##取出iris資料框的前五列
tail(iris,3) ##取出iris資料框的後三列
```

##排序

###sort 向量排序
`sort()`函數可直接對向量做**由小到大**的排序
```{r}
head(islands) ##排序前的前六筆資料
head(sort(islands)) ##由小到大排序後的前六筆資料
```
如需**由大到小**排序，可將`decreasing`參數設為TRUE
```{r}
head(sort(islands,decreasing = T)) ##由大到小排序後的前六筆資料
```

###order
如需對資料框做排序，可使用`order()`函數，`order()`函數可回傳**由小到大**之**元素位置**，以`iris$Sepal.Length`為例，回傳的第一個位置為`14`，表示`iris$Sepal.Length`中，數值最小的元素為第14個元素。
```{r}
order(iris$Sepal.Length)
iris$Sepal.Length[14]
```
若將`decreasing`參數設定為TRUE，則會回傳**由大到小**的元素位置，以`iris$Sepal.Length`為例，回傳的第一個位置為`132`，表示`iris$Sepal.Length`中，數值最大的元素為第132個元素。
```{r}
order(iris$Sepal.Length,decreasing = T)
iris$Sepal.Length[132]
```
依照order回傳的元素位置，重新排序iris資料框

```{r}
head(iris) ##排序前的前六筆資料
head(iris[order(iris$Sepal.Length),]) ##依照Sepal.Length欄位數值大小排序後的前六筆資料
head(iris[order(iris$Sepal.Length,decreasing = T),]) ##改為由大到小排序的前六筆資料
```

##資料組合
有時需要在資料框新增一列，或新增一行，可以利用資料組合函數完成

- Row 列的組合 `rbind()`
- Column 行的組合 `cbind()`

`rbind()`和`cbind()`的參數可以是向量，也可以是資料框，使用向量做資料整合範例:
```{r}
rbind(c(1,2,3), #第一列
      c(4,5,6)  #第二列
      ) 
```

使用資料框與向量做資料整合範例:
```{r warning=F}
irisAdd<-rbind(iris, #資料框
      c(1,1,1,1,"versicolor")  #新增一列
      ) 
tail(irisAdd)
```
使用向量做資料整合範例:
```{r}
cbind(c(1,2,3), #第一行
      c(4,5,6)  #第二行
      ) 
```
使用資料框與向量做資料整合範例:
```{r warning=F}
irisAdd<-cbind(iris, #資料框
      rep("Add",nrow(iris))  #新增一行
      ) 
tail(irisAdd)
```


##資料結合 (Join)

除了按照行列順序的組合外，更常有的情形是依照某個欄位的值作為結合依據，如：

- 用學號把以下兩個資料框結合成一個資料框
    - 學號與姓名資料框
    - 學號與宿舍床位資料框
- 用縣市名稱與年度將人口資料與醫療資源資料結合

原生的R環境可以用`merge()`函數將資料框結合，使用方法為`merge(資料框1,資料框2,by="結合依據欄位")`

```{r}
nameDF<-data.frame(ID=c(1,2,3,4,5),
                  Name=c("Amy","Bob","Chris","David","Emma"))
scoreDF<-data.frame(ID=c(1,2,4),
                  Score=c(60,90,50))
```

```{r, eval=F}
nameDF
```
```{r, echo=F}
knitr::kable(nameDF)
```

```{r, eval=F}
scoreDF
```
```{r, echo=F}
knitr::kable(scoreDF)
```

```{r,eval=F}
merge(nameDF,scoreDF,by="ID")
```
```{r,echo=F}
knitr::kable(merge(nameDF,scoreDF,by="ID"))
```

按照上述輸出結果可知，merge函數預設只保留兩資料框都有對應到的資料，如果不想要merge函數將沒對應到的資料刪除，可以設定參數`all`，`all.x`或是`all.y`，來保留沒對應到的資料列。

`merge(資料框1,資料框2,by="結合依據欄位",all=T)`

`merge(資料框1,資料框2,by="結合依據欄位",all.x=T)`

`merge(資料框1,資料框2,by="結合依據欄位",all.y=T)`

```{r,eval=F}
merge(nameDF,scoreDF,by="ID",all=T)
```
```{r,echo=F}
knitr::kable(merge(nameDF,scoreDF,by="ID",all=T))
```

`dplyr`套件提供更有效率的資料結合方法，包括:

- inner_join()：保留有對應到的資料
- left_join()：保留左邊資料框的所有資料
- right_join()：保留右邊資料框的所有資料
- full_join()：保留所有資料
- semi_join()
- anti_join()


inner_join()：只保留兩張表都有的列，使用方法為 `inner_join(x, y, by = )`

```{r}
library(dplyr) #使用前須先載入套件
inner_join(nameDF,scoreDF,by="ID")
```

left_join()：保留左邊的表所有的列，使用方法文為 `left_join(x, y, by = )`

```{r}
left_join(nameDF,scoreDF,by="ID")
```

right_join()：保留右邊的表所有的列。使用方法為 `right_join(x, y, by = )`

```{r}
right_join(nameDF,scoreDF,by="ID")
```


full_join()：保留所有的列。使用方法為 `full_join(x, y, by = )`

```{r}
full_join(nameDF,scoreDF,by="ID")
```


semi_join()：留下左邊的ID也有出現在右邊的表的列，右表資料不會輸出。使用方法為 `semi_join(x, y, by = )`

```{r}
semi_join(nameDF,scoreDF,by="ID")
```


##長表與寬表{#reshape}
在資料處理的過程中，常因各種需求，需要執行長寬表互換的動作，在R中有很好用的套件reshape2[@R-reshape2] package，提供完整的轉換功能，最常使用的是

- 寬表轉長表 `melt(資料框/寬表,id.vars=需要保留的欄位)`
- 長表轉寬表 `dcast(資料框/長表,寬表分列依據~分欄位依據)`

原來的`airquality`資料框中，有Ozone, Solar.R, Wind, Temp, Month, Day等六個欄位 (Column)，屬於寬表，以下範例將保留Month和Day兩個欄位，並將其他欄位的名稱整合至variable欄位，數值整合至value欄位，寬表轉長表範例如下:
```{r}
library(reshape2)
head(airquality)
airqualityM<-melt(airquality,id.vars = c("Month","Day")) ##欄位需要保留"Month","Day"
head(airqualityM)
```

轉換過的長表`airqualityM`資料框中，剩下Month, Day, variable, value等四個欄位 (Column)，屬於長表，以下範例variable欄位的值轉換為新欄位，並將value欄位填回新增的欄位，長表轉寬表範例如下:
```{r}
library(reshape2)
##欄位保留"Month","Day"外，其他欄位數目由variable定義
airqualityCast<-dcast(airqualityM, Month +Day~variable) 
head(airqualityCast)
```

##遺漏值處理
遺漏值(Missing Value)常常出現在真實資料內，在數值運算時常會有問題，最簡單的方法是將有缺值的資料移除，如資料為向量，可使用`is.na()`來判斷資料是否為空值`NA`，若為真`TRUE`，則將資料移除。
```{r}
naVec<-c("a","b",NA,"d","e")
is.na(naVec)
naVec[!is.na(naVec)] ##保留所有在is.na()檢查回傳FALSE的元素
```

若資料型態為資料框，可使用`complete.cases`來選出完整的資料列，如果資料列是完整的，則會回傳真TRUE
```{r}
head(airquality)
complete.cases(airquality) 
head(airquality[complete.cases(airquality),]) ##保留所有在complete.cases()檢查回傳TRUE的元素
```

利用演算法補值也是一種解決辦法，可參考_skydome20_的[R筆記–(10)遺漏值處理(Impute Missing Value)](http://www.rpubs.com/skydome20/R-Note10-Missing_Value){target="_blank"}教學。


##綜合練習範例Case study {#manCase}
在本範例中，介紹使用`SportsAnalytics` [@R-SportsAnalytics] package 撈取NBA各球員的數據，並加以觀察分析。

### 載入資料
首先用`library()`函數將`SportsAnalytics`套件載入 (若尚未安裝此套件者，必須先安裝套件，可參考Chapter \@ref(intro))，並利用套件內提供的`fetch_NBAPlayerStatistics()`函數，將對應年份之資料取出。
```{r}
library(SportsAnalytics)
NBA1516<-fetch_NBAPlayerStatistics("15-16")
```
###資料總覽
資料取出後，可用`str()`函數總覽`NBA1516`這個資料框的欄位與欄位類別
```{r}
str(NBA1516)
```
可以發現此`NBA1516`資料框內有476筆球員資料(觀察值, obs)，每筆資料有25個欄位 (variables)。
###資料預覽
如果想看資料框內容，可用`head()`和`tail()`快速瀏覽部分資料
```{r}
head(NBA1516)
```

###資料排序後篩選
觀察資料框的組成後，我們想要找出**出場數**最**高**的前五名選手的所有資料，此時可以利用`order()`函數先**由大到小**排序(`decreasing = T`)後，再用`[,]`取子集。
```{r}
NBA1516Order<-NBA1516[order(NBA1516$GamesPlayed,decreasing = T),]
NBA1516Order[1:5,] ##逗號前方放1~5，表示取1~5列；逗號後方空白，表示要取所有欄位
```
如果我們想要出**出場分鐘數**最**高**的前十名選手的**名字**，一樣可以用`order()`函數先**由大到小**排序(`decreasing = T`)後，再用`[,]`取子集。
```{r}
NBA1516OrderM<-NBA1516[order(NBA1516$TotalMinutesPlayed,decreasing = T),]
NBA1516OrderM[1:10,"Name"] ##逗號前方取1~10列；逗號後方放"Name"，表示取名稱為Name之欄位
```

###欄位值篩選
除了排序取值外，也可用欄位條件搜尋，舉例來說，可以取出所有波士頓賽爾迪克隊的選手資料，使用`subset()`函數
```{r}
subset(NBA1516,Team=="BOS")
```

###字串條件搜尋後篩選
當然也可以結合**字串搜尋**函數`grepl()`，將所有名字裡有"James"的選手資料取出
```{r}
NBA1516[grepl("James",NBA1516$Name),]
```

<!--chapter:end:06-manipulation.Rmd-->

# 探索式資料分析 {#eda}
## 什麼是探索式資料分析
探索式資料分析 (**E**xploratory **D**ata **A**nalysis) 的主要精神是運用視覺化、基本的統計等工具，反覆的探索資料特性，獲取資料所包含的資訊、結構和特點，因為在進行複雜或嚴謹的分析之前，必須要對資料有更多認識，才能訂定對的資料分析方向。

探索式資料分析包括分析各變數間的關聯性，看是否有預料之外的有趣發現，或是觀察資料內容是否符合預期，若否，檢查資料是否有誤，最後檢查資料是否符合分析前的假設，由上述可知，探索式資料分析通常不需要嚴謹的假設和細節呈現，主要功能還是『觀察』資料的特性。在資料量大/雜的時候，探索式資料分析就非常重要，因為透過探索式資料分析，分析人員可以在複雜的統計計算與耗時的模型建立前，就先發現可能的錯誤，更重要的是，可以透過探索性分析來調整分析的方向，減少因分析方向錯誤所造成的時間浪費。

探索式資料分析分為:

- 圖形化Graphical 或 量化Quantitative
- 單變量Univariate 或 雙變量Bivariate 或 多變量Multivariate

圖形化的分析方式包括做圖與列表，量化的分析方式則是資料初步統計，本章節著重於量化的分析方式，圖形化的分析方式請參考Ch \@ref(vis)。

以單變量分析來說，量化的分析方式可包含

- 計算集中趨勢 ([維基百科](https://zh.wikipedia.org/wiki/%E9%9B%86%E4%B8%AD%E8%B6%8B%E5%8A%BF){target="_blank"})
    - 平均值 Mean `mean()`
    - 中位數 Median `median()`
    - 眾數 Mode，R無內建函數，可直接用`table()`找出現次數最多的資料

- 計算資料分散程度
    - 最小值 Min `min()`
    - 最大值 Max `max()`
    - 範圍 Range `range()`
    - 四分位差 Quartiles `quantile()`
    - 變異數 Variance `var()`
    - 標準差 Standard deviation `sd()`

以雙變量分析來說，分析方式可包括:

- 列聯表 Crosstabs `table()`, `ftable()`, `prop.table()`
- 共變數 Covariance `cov()`
- 相關性 Correlation `cor()`

量化分析方式的測量值大多可用R的內建函數完成計算，但是在探索式分析時，常常需要遇到資料分組的分析情形（如觀察男性和女性的血壓差異、A隊與B隊的三分球命中率差異、中鋒和後衛的助攻次數...等），若只用基本的內建函數計算，需要先完成資料分組或子集後，再作進一步的運算，相當耗時，為了使這類資料分組與分析的工作更容易被完成，本書在介紹探索式資料分析時會搭配介紹`data.table`[@R-data.table]和`dplyr`[@R-dplyr] packages，這兩個packages各有優點，可依自己喜好選用。

## data.table {#datatable}
data.table是data.frame資料框型別的延伸，如要使用必須安裝並載入data.table[@R-data.table] package
```{r eval=F}
install.packages("data.table") ##安裝
```
```{r message=F}
library(data.table) ##載入
```

使用`data.table`讀取大型資料的速度比使用資料框快上數倍，效能比較可參考[Benchmarks : Grouping](https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping)，讀取資料的函數為`fread()`，使用方法與一般檔案讀取方法(Ch \@ref(file))類似
```{r eval=F}
fread("檔案名稱")
```

如果已經使用其他資料來源將檔案讀成資料框data.frame格式，可以使用`data.table()`函數將data.frame轉為data.table格式，以先前介紹過的NBA資料為例（Ch \@ref(manCase)，需安裝與載入`SportsAnalytics`套件）

```{r}
library(SportsAnalytics)
library(data.table)
NBA1516<-fetch_NBAPlayerStatistics("15-16")
NBA1516DT<-data.table(NBA1516)
class(NBA1516DT)
```
可以發現轉換後的`NBA1516DT`資料型態為`data.table`以及`data.frame`，這是因為data.table是data.frame資料框型別的延伸，所以是data.table型態的資料，就一定會是data.frame型態。


`data.table`資料型態的特殊結構和語法設計，便於後續資料分析處理，基本語法結構如下：

**DT[**`i`**,**`j`**,**`by`**=]**

- `i` 觀察值 (Row) 篩選邏輯
- `j` 所需欄位 (Column)
- `by` 分組依據

各參數間需要以逗號`,`區隔，但若只需使用前方參數，後方的`,`可省略，如只需使用i和j兩個參數，可以寫成DT[i,j]。
各參數的使用方法分述如下：

### i 觀察值篩選邏輯
第一個參數`i`是用來篩選**觀察值**，也就是針對列(Row)做子集。篩選方式與Ch \@ref(subset)雷同，可透過**布林值**的向量或是**元素索引(index)**向量指定篩選條件，透過觀察值的篩選，可保留需要的資料，進行後續分析。

以前述NBA球員資料為例，如需擷取球員姓名包含James字串的資料，可使用下列指令：
```{r eval=F}
NBA1516DT[grepl('James',Name)]
```
```{r echo=F}
knitr::kable(NBA1516DT[grepl('James',Name)]) 
```

如需篩選所有中鋒，且姓名包含"A"字串的球員資料，可使用下列指令：
```{r  eval=F}
NBA1516DT[grepl('A',Name)&Position=="C"]
```
```{r echo=F}
knitr::kable(NBA1516DT[grepl('A',Name)&Position=="C"]) 
```

如需篩選各隊出場數超過80場的球員資料，可使用下列指令：
```{r eval=F}
NBA1516DT[GamesPlayed>80]
```
```{r echo=F}
knitr::kable(NBA1516DT[GamesPlayed>80]) 
```

### j 欄位選擇運算
第二個參數`j`是用來決定輸出欄位，輸出的欄位可以是原始欄位，也可以是計算後的欄位，以計算所有球員的平均出場數為例：
```{r}
NBA1516DT[,mean(GamesPlayed)] ##因沒有篩選需求，,前方留空
```
也可以一次計算多個數值，如同時計算平均出場數、平均犯規次數以及平均抄截次數，此時第二個欄位`j`需要使用`.()`包起來
```{r}
NBA1516DT[,.(mean(GamesPlayed),mean(PersonalFouls),mean(Steals))] ##因沒有篩選需求，,前方留空
```
由上述輸出可以發現輸出的數字自動被加上欄位名稱V1, V2, V3，可能會造成數據判別錯誤，所以在計算新欄位時，可以在新欄位定義的前方加上`欄位名稱=`，同時替欄位取名字
```{r}
NBA1516DT[,.(GamesPlayedMean=mean(GamesPlayed),
             PersonalFoulsMean=mean(PersonalFouls),
             StealsMean=mean(Steals))]
```
除了計算平均值以外，當然可以帶入其他函式做各式各樣的運算
```{r}
NBA1516DT[,.(GamesPlayedMax=max(GamesPlayed), #最大值
             ThreesMadeMin=min(ThreesMade), #最小值
             FieldGoalsMadeSD=sd(FieldGoalsMade))] #標準差
```

若配合第一個參數一起使用，可以計算出所有**出場數大於70**的球員，**平均投進幾顆三分球與兩分球**
```{r}
NBA1516DT[GamesPlayed>70,
          .(ThreesMadeMean=mean(ThreesMade), FieldGoalsMadeMean=mean(FieldGoalsMade))]
```

### by 分組依據
第三個參數`by`為分組計算的依據，舉例來說，我們可以計算NBA各隊的**球員數**與**平均助攻數**，球員個數的計算在`data.table`內可使用`.N`指令，平均使用`mean()`函數，此時只要在`by=`後方加上分組依據(各隊Team)，即可完成運算
```{r}
NBA1516DT[,.(.N,AssistsMean=mean(Assists)),
          by=Team]
```
`.N`在`data.table`內是保留字，用來計算個數

三個參數結合使用，可以輕鬆計算出**NBA各隊的中鋒球員數和他們的平均三分球出手次數**，指令如下：
```{r}
NBA1516DT[Position=="C",
          .(.N,ThreesAttemptedMean=mean(ThreesAttempted)),
          by=Team]
```

### 參考文件與資源
`data.table`還有很多好用的功能，有興趣的話可以參考下列資料

- [官網](https://github.com/Rdatatable/data.table/wiki){target="_blank"}
- 指令全集[The data.table R package cheat sheet](https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf){target="_blank"}
- [A data.table R tutorial by DataCamp](https://www.datacamp.com/community/tutorials/data-table-r-tutorial#gs.vzMYa_k){target="_blank"}
- DataCamp[互動式教學課程](https://www.datacamp.com/courses/data-table-data-manipulation-r-tutorial){target="_blank"}

## dplyr
`dplyr`[@R-dplyr] package是[Hadley Wickham](http://hadley.nz/){target="_blank"}開發的資料處理分析套件，如要使用必須安裝並載入`dplyr` package
```{r echo=F}
select <- dplyr::select 
```
```{r eval=F}
install.packages("dplyr") ##安裝
```
```{r message=F}
library(dplyr) ##載入
```

`dplyr`使用以下函數分析整理資料：

- `select()`: 選要分析的欄位，欄位子集 (Column)
- `filter()`: 選要分析的觀察值，觀察值子集 (Row)
- `mutate()`: 增加新欄位
- `summarise()`: 計算統計值
- `group_by()`: 分組依據
- `arrange()`: 觀察值排序
- `rename()`: 欄位重新命名
- `%>%`: the “pipe” operator 連結上數函式，將所有函式計算串在一起執行

以上述NBA資料為例，各函數功能分述如下：
首先先讀入資料

```{r}
library(SportsAnalytics)
NBA1516<-fetch_NBAPlayerStatistics("15-16")
```

### select() 
使用`select()`函式可選要分析的欄位，也就是針對欄位 (Column)做子集，函式使用方式為`select(資料名稱,欄位條件1,欄位條件2,...)`，其中條件1與條件2是使用**或**的連結概念。另外`dplyr`提供幾個方便篩選名稱的函式：

- `starts_with()`
- `ends_with()`
- `contains()`
- `matches()`
- `num_range()`
- `one_of()`
- `everything()`

詳細說明可在R執行視窗中輸入`?select_helpers`查看。

舉例來說，我們想要篩選欄位名稱為`Name`、`ThreesMade`、`ThreesAttempted`、`FieldGoalsMade`與`FieldGoalsAttempted`的五個欄位，指令範例如下
```{r select1}
##等同於
##NBA1516[,c("Name","ThreesMade","ThreesAttempted","FieldGoalsMade","FieldGoalsAttempted")]
select1<-select(NBA1516,Name,starts_with("Threes"),starts_with("FieldGoals"))
head(select1)
```

若想篩選欄位`Name`到欄位`FreeThrowsAttempted`間的所有欄位，可用`:`串連欄位名稱
```{r selec2}
##等同於NBA1516[,2:12]
select2<-select(NBA1516,Name:FreeThrowsAttempted)
head(select2)
##等同於NBA1516[,c(2:4,6:12)]
select3<-select(NBA1516,Name:FreeThrowsAttempted,-GamesPlayed)
head(select3)
```

### filter() {#filter}
使用`filter()`函式可選要分析的觀察值，也就是針對列 (Row)做子集，使用方法為`filter(資料名稱,篩選條件)`，舉例來說，如果想要看出場分鐘數超過2850分鐘的球員資料，可用輸入下列指令
```{r filter1}
##等同於 NBA1516[NBA1516$TotalMinutesPlayed>2850,]
filter1<-filter(NBA1516,TotalMinutesPlayed>2850)
filter1
```

也可選擇隊伍名稱為"BOS"或"SAN"的球員資料
```{r filter2}
##等同於 NBA1516[NBA1516$Team %in% c("BOS","SAN"),]
filter2<-filter(NBA1516,Team %in% c("BOS","SAN"))
head(filter2)
```

在`filter()`函式中可**直接做變數計算**後再篩選
```{r filter3}
##等同於
filter3<-filter(NBA1516,FieldGoalsMade/FieldGoalsAttempted>0.7)
filter3
```

也可使用 `&` 和 `|`等符號串連邏輯
```{r filter4}
##等同於
filter4<-filter(NBA1516,FieldGoalsMade/FieldGoalsAttempted>0.7 & GamesPlayed>30)
filter4
```

### mutate()
使用`mutate()`增加新欄位，如需新增新欄位`FieldGoalsRate`，欄位值為`FieldGoalsMade/FieldGoalsAttempted`，指令如下
```{r mutate1}
mutate1<-mutate(NBA1516,FieldGoalsRate=FieldGoalsMade/FieldGoalsAttempted)
mutate1$FieldGoalsRate[1:10]
```

### summarise() {#summarise}
`summarise()`函式用來計算統計值，像是**球員個數**、**不重複的隊伍數**以及**不重複的守備位置數**等
```{r summarise1}
sum1<-summarise(NBA1516,
                nPlayer=n(),
                nTeam=n_distinct(Team),
                nPosition=n_distinct(Position))
sum1
```

計算統計值的功能通常會與其他功能合併使用，像是與前述`filter()`功能 Ch \@ref(filter)合併使用，可計算**出場分鐘數大於2500分鐘**的球員個數、平均投進的兩分球數以及平均投出的兩分球數
```{r summarise2}
filter1<-filter(NBA1516,TotalMinutesPlayed>2500)
sum2<-summarise(filter1,
                nPlayer=n(),
                meanFieldGoalsMade=mean(FieldGoalsMade),
                meanFieldGoalsAttempted=mean(FieldGoalsAttempted))
sum2
```

上述分析序列（先篩選再總和），可直接用**pipe**符號`%>%`將指令串連，減少暫存物件（filter1）的生成，主要概念是先篩選後計算
```{r summarise3}
sum3<-filter(NBA1516,TotalMinutesPlayed>2500) %>%
  summarise(nPlayer=n(),meanFieldGoalsMade=mean(FieldGoalsMade),
                meanFieldGoalsAttempted=mean(FieldGoalsAttempted))
sum3
```


### group_by()
`group_by()`函數的功能為設定分組依據，通常會與`summarise()`函式Ch \@ref(summarise)合併使用，例如計算各**隊**（以Team作為分組依據）的球員數、平均投進的兩分球數以及平均投出的兩分球數
```{r group1}
group1<-group_by(NBA1516,Team)%>%
  summarise(nPlayer=n(),meanFieldGoalsMade=mean(FieldGoalsMade),
                meanFieldGoalsAttempted=mean(FieldGoalsAttempted))
head(group1)
```

當然也可以設定**多個**分組依據，像是計算各**隊**各**守備位置**（以Team和Position作為分組依據）的球員數、平均投進的兩分球數以及平均投出的兩分球數
```{r group2}
group2<-group_by(NBA1516,Team,Position)%>%
  summarise(nPlayer=n(),meanFieldGoalsMade=mean(FieldGoalsMade),
                meanFieldGoalsAttempted=mean(FieldGoalsAttempted))
head(group2)
```
### arrange()
排序功能，預設為**遞增排序**
```{r arrange1}
arrange1<-arrange(NBA1516,TotalMinutesPlayed)
head(arrange1)
```
使用`desc()`將要**遞減排序**的變數包起來，就可以遞減排序
```{r arrange2}
arrange2<-arrange(NBA1516,desc(TotalMinutesPlayed),desc(GamesPlayed))
head(arrange2)
```

結合`group_by()`、`summarise()`、`arrange()`，可完成一連串的資料分析，例如計算各**隊**各**守備**位置（以Team和Position作為分組依據）的球員數、平均投進的兩分球數以及平均投出的兩分球數，並依平均投進的兩分球數**由大到小排序**
```{r arrange3}
arrange3<-group_by(NBA1516,Team,Position)%>%
  summarise(nPlayer=n(),meanFieldGoalsMade=mean(FieldGoalsMade),
                meanFieldGoalsAttempted=mean(FieldGoalsAttempted)) %>%
  arrange(desc(meanFieldGoalsMade))
head(arrange3)
```

### rename()
`新名稱=舊名稱`
```{r rename1}
rename1<-rename(NBA1516,Po=Position)
rename1[1:5,1:5]
```

### 參考文件與資源

- [Introduction to dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html){target="_blank"}
- DataCamp互動式教學課程 [Data Manipulation in R with dplyr](https://www.datacamp.com/courses/dplyr-data-manipulation-r-tutorial){target="_blank"}



<!--chapter:end:07-eda.Rmd-->

# 資料視覺化 {#vis}

## 資料視覺化的目的

延續Ch \@ref(eda)，探索式資料分析可分為圖形化Graphical 或 量化Quantitative分析，總括來說**作圖**的目的有:

- 了解資料的特性
- 尋找資料的模式(patterns)
- 建議資料分析與建模的策略
- 結果呈現與溝通

其中前三項屬於探索圖 (Exploratory graphs)，結果呈現與溝通屬於結果圖 (Final graphs)，探索圖屬探索式資料分析，目的是在『看』與『觀察』資料的樣子，所以探索圖有以下特性:

- 很快就可以做一張圖
- 探索過程中，可能可以做圖
- 主要目的是了解資料的樣子
- 不用做圖形格式調整美化

而在製作結果圖 (Final graphs)時，則須考慮以下事項:

- 比較，呈現差異
    - 比較什麼？誰跟誰比較？
- 呈現因果關係（causality）,機制（mechanism）,結果解釋（explanation）,系統化的結構（systematic structure）
    - 因果模型？為什麼你想要做這樣的比較
- 呈現多變數（Multivariate）資料
    - 多變數（Multivariate）：超過兩個變數就叫多變數
    - 所有真實事件都是多變數的
- 將證據整合呈現
    - 在同一個畫面呈現文字、數字、影像、圖表
    - 盡量用圖形呈現資料
- 將圖表做適當的標記與說明，包括xy軸名稱、單位、資料來源等
    - 資料圖表必須可以呈現你想說的故事
- 內容才是最重要的
    - 資料不好，分析不好，圖表再美也沒有用
    
在R中，有三個常用的畫圖套件，包括基本功能(Base)、`lattice`以及`ggplot2`，由於各套件繪圖邏輯不同，本書只介紹最推薦的`ggplot2`套件的使用方式。

## ggplot2簡介
`ggplot2` [@R-ggplot2]的開發靈感來自於Dr. Leland Wilkinson的[Grammar of Graphics](http://www.springer.com/us/book/9780387245447){target="_blank"}

“In brief, the grammar tells us that a statistical graphic is a `mapping` from data to `aesthetic` attributes (colour, shape, size) of `geometric` objects (points, lines, bars). The plot may also contain statistical transformations of the data and is drawn on a specific coordinate system”

-from `ggplot2` book

`ggplot2` Package是由[Hadley Wickham](http://hadley.nz/){target="_blank"}開發，是第三個R的畫圖Package。自發表以來一直是最熱門的R packages之一，目前還在持續發展更新中，對原始碼有興趣的人可以到[GitHub](https://github.com/tidyverse/ggplot2){target="_blank"}看一下最新動態。

簡單來說，做圖的文法包括兩個最主要元素：

- **Aesthetic attributes**：包括顏色、形狀、點的大小與線的粗細等
- **Geometric objects**：包括點、線、盒狀圖、直條圖等

其他元素包括：

- **Facets**：提供在同一張圖內做多個子圖的方法，只要使用Faceting功能設定子圖分類的依據參數即可
- **Stats**：將資料做統計轉換
- **Scales**：修改點線的顏色、形狀、xy軸的範圍等

在開始學ggplot2的核心功能之前，`qplot()`是ggplot2 Package提供最基本的畫圖方法，跟基本的plot() function很接近，提供一個簡單入門的方法。

### qplot()
`qplot()`為ggplot2 “Hello, world!”，簡單使用`qplot(x軸名稱,y軸名稱,data=使用資料)`就可畫散佈圖

```{r qplot1, fig.height=4, warning=F,message=F}
library(SportsAnalytics)
NBA1516<-fetch_NBAPlayerStatistics("15-16") ## 讀入資料
library(ggplot2) #記得將ggplot2 package讀入，如果沒安奘記得先安裝
qplot(FieldGoalsAttempted, TotalPoints, data = NBA1516)
```

針對做圖的文法的第一個主要元素**Aesthetics**（包括顏色、形狀、點的大小與線的粗細等），可透過增加指令做修改，如加上`color=Position`，表示用守備位置Position著色

```{r qplot2, fig.height=4}
qplot(FieldGoalsAttempted, TotalPoints, data = NBA1516,color=Position)
```
針對做圖的文法的第二個主要元素**Geometric**（包括點、線、盒狀圖、直條圖等），也可透過增加指令修改，如使用`geom = c("point", "smooth")` 在圖上加點與漸進線

```{r qplot3, fig.height=4}
qplot(FieldGoalsAttempted, TotalPoints, data = NBA1516,
      geom = c("point", "smooth"))
```

如果輸入的變量並非**雙**變量，而是**單**變量時，預設圖形會從**散佈圖**變為**Histograms直方圖**

```{r, fig.height=3.5, warning=F,message=F}
#畫TotalPoints的直方圖/ fill = Position 並用守備位置Position著色
qplot(TotalPoints, data = NBA1516, fill = Position)
```

作圖的**Facets**元素可提供在同一張圖內做多個子圖的方法，只要使用`facets = `來設定子圖分類的依據參數即可，以下圖為例，輸入的變量是**雙**變量，所以預設圖形為散佈圖，而設定子圖的語法為`直向分類~橫向分類`，直向分類意指以增加列（Row）的方式畫子圖，橫向分類意指以增加行（Column）的方式畫子圖，通常只會設定單一方向，如果選擇的是`直向`，`橫向分類`部分可用`.`表示，範例如下：

```{r, fig.height=3.5}
#facets = . ~ Position 用守備位置Position分群畫圖(橫向)
qplot(FieldGoalsAttempted, TotalPoints, 
      data = NBA1516,
      facets = . ~ Position)
```


```{r, fig.height=4}
#facets = . ~ Position 用守備位置Position分群畫圖(直向)
qplot(FieldGoalsAttempted, TotalPoints, 
      data = NBA1516,
      facets = Position ~ .)
```

`ggplot2`套件會自動幫使用者選擇顏色與圖形各項參數，但使用者也可依需求微調，如直方圖的分組間隔，可透過`binwidth`參數設定
```{r, fig.height=3.5}
#facets = . ~ Position 用守備位置Position分群畫圖(直向)
##binwidth = 2 每2分一組
qplot(TotalPoints, data = NBA1516, 
      facets = Position ~ ., binwidth = 2)
```

```{r, fig.height=3.5}
#facets = . ~ Position 用守備位置Position分群畫圖(直向)
##binwidth = 100 每100分一組
qplot(TotalPoints, data = NBA1516,
      facets = Position ~ ., binwidth = 100)
```

總括來說`qplot()`提供快速方便的畫圖功能，並且保留部分參數設定的彈性，但若需要調整更多參數，仍須使用完整的`ggplot()`函式。

### ggplot()

使用ggplot2作圖有以下步驟：

- 準備好資料。當然要有資料才能畫圖
- 設定**Aesthetic attributes**。使用`aes(x, y, ...)`指定
- 指定**Geometric objects**。常用的包括`geom_point()`、`geom_line()`、`geom_point()`、`geom_polygon()`、`geom_errorbar()`

```{r warning=F, message=F}
library(ggplot2) ##須先安裝 install.packages("ggplot2")
```

首先先產生教學用畫圖資料
```{r}
df <- data.frame(gp = factor(rep(letters[1:3], each = 10)),y = rnorm(30))
```
設定兩個畫圖的重要元素**Aesthetic attributes**和**Geometric objects**
```{r}
ggplot(df, aes(x = gp, y = y)) +geom_point()
```
用`geom_boxpolt()`改畫盒狀圖
```{r}
ggplot(df, aes(x = gp, y = y)) +geom_boxplot()
```
使用Faceting功能
```{r}
df$z<-df$y+rnorm(30)
ggplot(df, aes(x = z, y = y)) +geom_point()+facet_grid(gp~.)
```
轉向
```{r}
ggplot(df, aes(x = z, y = y)) +geom_point()+facet_grid(.~gp)
```
用`geom_smooth()`替xy散佈圖加上趨勢線
```{r}
ggplot(df, aes(x = z, y = y)) +geom_point()+facet_grid(gp~.)+geom_smooth()
```
用`geom_smooth()`替xy散佈圖加上趨勢線，使用linear regresion
```{r}
ggplot(df, aes(x = z, y = y)) +geom_point()+facet_grid(gp~.)+geom_smooth(method='lm')
```
改用`geom_line()`畫線
```{r}
ggplot(df, aes(x = z, y = y)) +geom_line()+facet_grid(gp~.)
```
改用顏色分組，使用`aes(color='group name')`
```{r}
ggplot(df, aes(x = z, y = y, color=gp)) +geom_line()
```

畫圖前需要注意的幾個小地方：

提供資料時，把資料修改為想要在圖片顯示的文字。從上面的範例可以發現，ggplot2會直接將資料分組（a/b/c）直接標在圖上，與其之後再來改圖，不如在資料處理時就將a/b/c改為有意義且可以直接使用的文字。
如果是離散性的資料，但卻又是數值時（像是1,2,3）可以用factor()轉換，ggplot會將factor視為離散資料。

除了基本的製圖外，`ggplot2`套件也提供完整的資料標示設定與其他參數設定功能，包括：

- 標籤 `xlab()`, `ylab()`, `labs(x=,y=)`, `ggtitle()`
- 每一個`geom_*()`都有參數可設定
- 圖形樣式設定 `theme()`，可使用內建樣式
  - `theme_gray()`: 灰背景，預設樣式
  - `theme_bw()`: 黑白樣式
- 使用其他樣式套件
  - `ggthemes` packages [Website](https://cran.r-project.org/web/packages/ggthemes/vignettes/ggthemes.html)
  - `xkcd` packages [Website](http://xkcd.r-forge.r-project.org/)


在比較多組的平均值高低時，因為各組樣本數與資料分佈不同，平均數的誤差值也會不同，所以在資料視覺化時，建議加上誤差線(Error bar)，誤差線通常使用在bar chart和line chart，而誤差值的計算有下列三種選擇：

  - Standard deviation (SD) 標準差：呈現資料本質時使用
  - Standard error (SE) 標準誤差：呈現預估平均值的可能誤差時使用
  - Confidence interval (CI) 信賴區間：呈現預估平均值的信心時使用
    
以空氣污染料為例，若想比較各月臭氧濃度差異，可以使用bar chart來呈現，在ggplot2中，如果要畫bar chart，需要將**Geometric objects**設定為`geom_bar`
```{r,fig.height=3.5}
library(datasets) 
library(data.table)
airquality$Month<-as.factor(airquality$Month) #將Month轉為因子變項
airquality.mean<-data.table(airquality)[,.(OzoneMean=mean(Ozone,na.rm = T)),by=Month] #計算每月Ozone平均
ggplot()+geom_bar(data=airquality.mean,aes(x=Month,y=OzoneMean),
                  stat = "identity") #stat = "identity" 直接畫數字
```

在ggplot2套件中，只要加上`geom_errorbar()`函式，設定資料高低值，就能在原圖中加上誤差線
```{r,fig.height=3}
library(datasets) 
library(data.table)
airquality$Month<-as.factor(airquality$Month) #將Month轉為因子變項
airquality.stat<-data.table(airquality)[,.(OzoneMean=mean(Ozone,na.rm = T),OzoneSD=sd(Ozone,na.rm = T)),by=Month] #計算每月Ozone平均與標準差
ggplot(data=airquality.stat)+ #資料airquality.eb
    geom_bar(aes(x=Month,y=OzoneMean),stat = "identity")+
    geom_errorbar( #ymin低點, ymax高點
        aes(x=Month,ymin=OzoneMean-OzoneSD,ymax=OzoneMean+OzoneSD), width=.1)
```



## ggplot2+地圖

### Choropleth map面量圖
Choropleth map[面量圖](https://en.wikipedia.org/wiki/Choropleth_map){target="_blank"}是指**把統計資料用顏色畫在對應的地圖上**的一種資料視覺化方式，在R中可以使用`choroplethr`[@R-choroplethr] package來畫面量圖，
`choroplethr` package是一個基於`ggplot2` package的`面量圖`做圖工具，使用前需要先安裝，建議同時安裝`choroplethrMaps` package
```{r,eval=F,warning=F,message=F}
install.packages(c("choroplethr","choroplethrMaps")) ##第一次使用前先安裝
```
```{r, warning=F,message=F}
library(choroplethr)
```

`choroplethr`[@R-choroplethr] package內建美國各州地圖與人口學資料，所以可以輕鬆使用`state_choropleth()`函式畫出美國各州人口分布
```{r}
data(df_pop_state) #記載各州人口數的資料
state_choropleth(df_pop_state) #把各州人口畫在地圖上
```

若將`reference_map`設定為` = TRUE`，可在面量圖的背景加上google地圖，因google地圖需要使用API key，因此須先使用ggmap套件的`register_google(key = "your key")`，帶入google金鑰設定授權金鑰。以下金鑰為示範金鑰，目前已失效，請自行至[Google Cloud Platform](https://console.cloud.google.com/){target="_blank"}，點選API及服務申請Maps Static API後，複製API key。

```{r, warning=F,message=F, fig.height=3.5}
data(continental_us_states)
library(ggmap)
register_google(key = "AIzaSyC7JRppSZtZuzpy9SdsVbpK5Nhf_oh2xl0")
state_choropleth(df_pop_state,reference_map = TRUE,
                 zoom= continental_us_states) #把各州人口畫在地圖上
```

除了美國地圖外，使用`choroplethr` package搭配`WDI`: [World Development Indicators](http://beta.data.worldbank.org/){target="_blank"} 的世界人口分布資料，可以針對世界人口分佈做**面量圖**。
世界人口資料的代碼為`SP.POP.TOTL`，代碼查詢可見[World Development Indicators](http://beta.data.worldbank.org/){target="_blank"}

由於需要使用`WDI`的資料，所以需要安裝與載入`WDI`[@R-WDI] package

```{r,eval=F,warning=F,message=F}
install.packages("WDI") ##第一次使用前先安裝
```
```{r choroplethr_wdi_1 , warning=F,message=F, fig.height=3,eval=F}
library(WDI)
choroplethr_wdi(code="SP.POP.TOTL", year=2016, 
                title="2016 Population", num_colors=1)
```

除了人口資料外，WDI也有世界平均壽命資料，平均壽命的代碼為`SP.DYN.LE00.IN`，代碼查詢可見[World Development Indicators](http://beta.data.worldbank.org/){target="_blank"}
```{r choroplethr_wdi_2,warning=F,message=F, fig.height=4,eval=F}
choroplethr_wdi(code="SP.DYN.LE00.IN", year=2016, 
                title="2016 Life Expectancy")
```

如果只需亞洲太平洋人口分布，可使用`zoom`參數設定想畫的國家，國家的名稱設定必須要和`country.regions`資料完全吻合
```{r choroplethr_wdi_3,eval=F, warning=F,message=F, fig.height=2.5,eval=F}
choroplethr_wdi(code="SP.POP.TOTL", year=2015, 
                title="2015 Life Expectancy",
                zoom=c('taiwan','japan','south korea','philippines'))
```



### ggmap()
`ggmap`[@R-ggmap] package是一個可以把google map載入並作圖的套件，一樣是基於`ggplot2`套件開發的。
依照往例，第一次使用前需要安裝
```{r,eval=F,warning=F,message=F}
install.packages("ggmap", type = "source") ##第一次使用前先安裝
```
載入`ggmap`[@R-ggmap] package後，可以使用`get_googlemap()`函式取得google map圖層，並用`ggmap()`函式將取得的圖層畫出來，使用google map的資源時，必須先使用register_google(key = "your key")帶入google金鑰。
投影片金鑰已失效，請自行至Google Cloud Platform，點選API及服務申請Maps Static API後，複製API key。

`get_googlemap()`函式需要設定的參數如下：

- center 中心點經緯度座標
- zoom 放大倍率
- language 地圖語言

```{r, warning=F,message=F, fig.height=4}
library(ggmap)
register_google(key = "AIzaSyC7JRppSZtZuzpy9SdsVbpK5Nhf_oh2xl0")
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58), 
                  zoom = 7,
                  language = "zh-TW")
ggmap(twmap)
```

只要資料有經緯度等資訊，就可以使用`ggmap` package與各式資料結合呈現，以台北市水質地圖開放資料為例，首先先將資料載入處理（參考Ch \@ref(JSON)）。台北市水質資料的Open data API網址是http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=190796c8-7c56-42e0-8068-39242b8ec927
```{r eval=F, message=F, warning=F}
##資料載入
library(jsonlite)
library(RCurl)
WaterData<-fromJSON(getURL("http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=190796c8-7c56-42e0-8068-39242b8ec927"))
WaterDataFrame<-WaterData$result$results
WaterDataFrame$longitude<-as.numeric(WaterDataFrame$longitude)
WaterDataFrame$latitude<-as.numeric(WaterDataFrame$latitude)
WaterDataFrame$qua_cntu<-as.numeric(WaterDataFrame$qua_cntu)
##結合ggmap
library(ggmap)
TaipeiMap <- get_googlemap(
    center  = c(lon=121.50,lat=25.06), 
    zoom = 11, maptype = 'roadmap')
TaipeiMapO <- ggmap(TaipeiMap)+ 
    geom_point(data=WaterDataClean, 
               aes(x=longitude, y=latitude,
                   color=qua_cntu),size=3.5)+ 
    scale_color_continuous(
        low = "yellow",high = "red")+ 
    guides(size=FALSE)
TaipeiMapO
```

```{r echo=FALSE}
knitr::include_graphics("figure/waterQ.png")
```

`ggmap`套件提供多種地圖型態，使用者可透過設定`maptype`自行選擇適合的地圖樣式，樣式有：

- terrain
- terrain-background
- satellite
- roadmap
- hybrid (google maps)
- watercolor
- toner (stamen maps)

透過設定`extent`參數可將地圖輸出樣式改為滿版
```{r eval=F,warning=F,message=F, fig.height=3}
library(ggmap)
ggmap(TaipeiMap,extent = 'device') #extent = 'device' 滿版
```


###Density Map
除了面量圖外，密度圖Density Map也是常用來表示因地理位置不同的數值差異，以下是美國人口密度圖範例
```{r, echo=F, warning=F,message=F}
StateCenter<-data.frame( #取得美國各州中心座標資料
    region=tolower(state.name),lon=state.center$x,lat=state.center$y)
StatePop<-merge(df_pop_state,StateCenter,by="region") #美國各州人口資料
PopPoint<-NULL #將人口數值，轉為點！重要！
for(i in 1:nrow(StatePop)){
    for(j in 1:(StatePop[i,"value"]/1000000)){
        PopPoint<-rbind(PopPoint,StatePop[i,])   
    }
}
USMap <- get_googlemap(center = c(lon=-99.582,lat=40.091), zoom = 4)
densityMap<-ggmap(USMap, extent = "device") + 
    geom_density2d(data = PopPoint, aes(x = lon, y = lat), size = 0.3) + 
    stat_density2d(data = PopPoint, 
            aes(x = lon, y = lat, fill = ..level.., alpha = ..level..), 
                size = 0.01, bins = 16, geom = "polygon") + 
    scale_fill_gradient(low = "green", high = "red", guide = FALSE) + 
    scale_alpha(range = c(0, 0.3), guide = FALSE)
densityMap
```

上述範例使用 `ggplot2` + `ggmap` 套件來畫人口密度圖，做圖的第一步是資料載入，包括取得美國各州中心座標資料以及美國各州人口資料
```{r warning=F,message=F}
#取得美國各州中心座標資料
StateCenter<-data.frame( 
    region=tolower(state.name),lon=state.center$x,lat=state.center$y)
head(StateCenter,1)
#美國各州人口資料
StatePop<-merge(df_pop_state,StateCenter,by="region") 
head(StatePop,1)
```

第二個步驟是將人口數字轉換為**資料列數**，需要這樣轉換的原因是密度圖是用資料列數來決定畫圖的密度，而不是透過單一數值，所以需要在此步驟做轉換
```{r warning=F,message=F}
#將人口數值，轉為點！重要！
PopPoint<-NULL 
for(i in 1:nrow(StatePop)){
    #每100萬人轉為1點
    for(j in 1:(StatePop[i,"value"]/1000000)){
        PopPoint<-rbind(PopPoint,StatePop[i,])   
    }
}
head(PopPoint,3)
```

第三個步驟是作圖
```{r warning=F,message=F}
USMap <- get_googlemap(center = c(lon=-99.582,lat=40.091), zoom = 4)
densityMap<-ggmap(USMap, extent = "device") + 
    geom_density2d(data = PopPoint, aes(x = lon, y = lat), size = 0.3) + 
    stat_density2d(data = PopPoint, 
            aes(x = lon, y = lat, fill = ..level.., alpha = ..level..), 
                size = 0.01, bins = 16, geom = "polygon") + 
    scale_fill_gradient(low = "green", high = "red", guide = FALSE) + 
    scale_alpha(range = c(0, 0.3), guide = FALSE)
densityMap
```

###參考資料
- [ggmap package source code](https://github.com/dkahle/ggmap)
- [ggmap cheat sheet](https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/ggmap/ggmapCheatsheet.pdf)
- [ggmap doc](https://dl.dropboxusercontent.com/u/24648660/ggmap%20useR%202012.pdf)


## Taiwan的面量圖
因為畫台灣的面量圖尚無好的套件輔助，但因Open Data的關係，我們可以很容易地取得台灣鄉鎮市邊界的經緯度檔案，通常地圖/邊界經緯度檔案是用空間資料開放格式`shapefile` `.shp`儲存，透過[政府資料開放平台](http://data.gov.tw/){target="_blank"}可以下載台灣的地圖資料，資料集名稱為[鄉鎮市區界線](http://data.gov.tw/node/7441){target="_blank"}。使用`shapefile`與`ggplot2`畫圖的步驟如下：

- 取得空間資料檔案
- 使用`rgdal`, `rgeos`,`maptools` package處理地圖檔shapefile
- 使用`ggplot2` & `RColorBrewer` 畫圖

上述套件在第一次使用前需要安裝與載入

```{r, eval=F,echo=F, warning=F,message=F, fig.height=4}
install.packages(c("rgdal","rgeos","maptools","ggplot2","RColorBrewer"))
library(rgdal)#for fortify()
library(rgeos) #for fortify()
library(maptools) #for readShapeSpatial()

tw_new <- readShapeSpatial("Taiwan/Town_MOI_1041215.shp") #空間資料檔名 請自行下載

library(ggplot2) #for fortify(), ggplot(), ggmap()
tw_new.df <- fortify(tw_new, region = "T_UID") #from ggplot2 package
mydata<-data.frame(NAME_2=tw_new$T_Name, id=tw_new$T_UID,
                   prevalence=rnorm(length(tw_new$T_UID)))#prevalence 畫圖假資料
final.plot<-merge(tw_new.df,mydata,by="id",all.x=T)

library(RColorBrewer) #配色用brewer.pal( 9 , "Reds" )
twcmap<-ggplot() +
    geom_polygon(data = final.plot, 
                 aes(x = long, y = lat, group = group, 
                     fill = prevalence), 
                 color = "black", size = 0.25) + 
    coord_map()+#維持地圖比例
    scale_fill_gradientn(colours = brewer.pal(9,"Reds"))+
    theme_void()+
    labs(title="Prevalence of X in Taiwan")
twcmap
```
```{r echo=FALSE}
knitr::include_graphics("figure/Taiwan.png")
```

以上各步驟詳述如下：
1. 處理shapefile-1

- 需要`rgdal`, `rgeos`,`maptools`
- fortify: 將`shapefile`物件轉為`data.frame`

```{r, eval=F,warning=F,message=F, fig.height=3}
library(ggplot2) #for fortify(), ggplot(), ggmap()
head(tw_new$Town_ID)
tw_new.df <- fortify(tw_new, region = "T_UID") #from ggplot2 package
head(tw_new.df,10)
```
```
       long      lat order  hole piece id group
1  119.9170 26.17518     1 FALSE     1  1   1.1
2  119.9171 26.17517     2 FALSE     1  1   1.1
3  119.9171 26.17518     3 FALSE     1  1   1.1
4  119.9171 26.17518     4 FALSE     1  1   1.1
5  119.9171 26.17518     5 FALSE     1  1   1.1
6  119.9172 26.17518     6 FALSE     1  1   1.1
7  119.9172 26.17518     7 FALSE     1  1   1.1
8  119.9172 26.17518     8 FALSE     1  1   1.1
9  119.9173 26.17515     9 FALSE     1  1   1.1
10 119.9173 26.17515    10 FALSE     1  1   1.1
```

2. 做一個假資料來畫：著色基準檔
```{r, eval=F,warning=F,message=F, fig.height=3}
#做一個假資料來畫
#prevalence設為亂數rnorm(需要的亂數個數)
mydata<-data.frame(NAME_2=tw_new$T_Name, id=tw_new$T_UID,
                   prevalence=rnorm(length(tw_new$T_UID)))
head(mydata)
```
```
                  NAME_2  id prevalence
1 \xa6\xa8\xa5\\\xc2\xed 178  1.0551637
2            \xa8ΥV\xb6m 164 -0.6307466
3     \xb3\xc1\xbcd\xb6m 118 -1.2255327
4     \xba\xf1\xaeq\xb6m 376  0.1314583
5  \xc4\xf5\xc0\xac\xb6m 369  1.3665832
6      \xa5Ф\xa4\xc2\xed  78 -0.3132549
```

3. 處理中文編碼
利用iconv將不知所以然的代碼（\xa6\xa8\xa5\\\xc2\xed）轉為看得懂的中文
```{r, eval=F,warning=F,message=F, fig.height=3}
#from big5 to utf-8
mydata$NAME_2<-iconv(as.character(mydata$NAME_2), #NAME_2原本是factor
                     from="big5", to = "UTF-8")
head(mydata,10)
```
```
   NAME_2  id prevalence
1  成功鎮 178  1.0551637
2  佳冬鄉 164 -0.6307466
3  麥寮鄉 118 -1.2255327
4  綠島鄉 376  0.1314583
5  蘭嶼鄉 369  1.3665832
6  田中鎮  78 -0.3132549
7  社頭鄉  83  1.2072224
8  竹田鄉 157  0.7312959
9  萬丹鄉 148  1.4849184
10 三灣鄉  64  0.6094254
```

4. 合併的圖檔與著色基準檔
最後將有prevalence的假數據mydata和經緯度資料tw_new.df合併, 用merge()
```{r, eval=F,warning=F,message=F, fig.height=3}
final.plot<-merge(tw_new.df,mydata,by="id",all.x=T)
head(final.plot,10)
```
```
   id     long      lat order  hole piece group NAME_2 prevalence
1   1 119.9170 26.17518     1 FALSE     1   1.1 南竿鄉  0.9584632
2   1 119.9171 26.17517     2 FALSE     1   1.1 南竿鄉  0.9584632
3   1 119.9171 26.17518     3 FALSE     1   1.1 南竿鄉  0.9584632
4   1 119.9171 26.17518     4 FALSE     1   1.1 南竿鄉  0.9584632
5   1 119.9171 26.17518     5 FALSE     1   1.1 南竿鄉  0.9584632
6   1 119.9172 26.17518     6 FALSE     1   1.1 南竿鄉  0.9584632
7   1 119.9172 26.17518     7 FALSE     1   1.1 南竿鄉  0.9584632
8   1 119.9172 26.17518     8 FALSE     1   1.1 南竿鄉  0.9584632
9   1 119.9173 26.17515     9 FALSE     1   1.1 南竿鄉  0.9584632
10  1 119.9173 26.17515    10 FALSE     1   1.1 南竿鄉  0.9584632
```

5. 畫台灣面量圖
```{r, eval=F,warning=F,message=F, fig.height=3}
library(RColorBrewer) #配色用brewer.pal( 9 , "Reds" )
twcmap<-ggplot() +
    geom_polygon(data = final.plot, 
                 aes(x = long, y = lat, group = group, 
                     fill = prevalence), 
                 color = "black", size = 0.25) + 
    coord_map()+#維持地圖比例
    scale_fill_gradientn(colours = brewer.pal(9,"Reds"))+
    theme_void()+
    labs(title="Prevalence of X in Taiwan")
twcmap
```
```{r echo=FALSE}
knitr::include_graphics("figure/Taiwan.png")
```

### ggmap+面量圖
```{r, eval=F,warning=F,message=F, fig.height=6}
library(ggmap)
twmap <- get_map(location = 'Taiwan', zoom = 7,language = "zh-TW")
ggmap(twmap)+ #ggmap
    geom_polygon(data = final.plot,  #面量圖
        aes(x = long, y = lat, group = group, fill = prevalence), 
        color = "grey80", size = 0.1,alpha = 0.5) + 
scale_fill_gradientn(colours = brewer.pal(9,"Reds"))
```
```{r echo=FALSE}
knitr::include_graphics("figure/ggmapTaiwan.png")
```

##Heatmap
`Heatmap`熱度圖使用顏色的深淺來表示數值的大小，通常會搭配XY兩軸的變量，所以使用一張圖就能表示三個維度的資訊，在ggplot2套件中，可以使用`geom_tile()`來畫Heatmap，以下以NBA球員的資料作為範例，希望能透過Heatmap來呈現球員表現的差異。
首先先將檔案讀入
```{r message=FALSE,warning=F}
#讀.csv檔案
nba <- read.csv("http://datasets.flowingdata.com/ppg2008.csv")
head(nba)
```

為了做圖，將寬表轉長表，寬表與長表的概念可參見\@ref(reshape)
```{r message=FALSE,warning=F}
library(reshape2) #for melt()
nba.m <- melt(nba,id.vars = "Name") #寬表轉長表,以名字作依據
head(nba.m,10)
```

將Geometric objects指定為`geom_tile()`，完成Heatmap
```{r message=FALSE,warning=F,fig.height=4}
library(ggplot2) #for ggplot()
ggplot(nba.m, aes(variable, Name)) + #aes(x,y)
    geom_tile(aes(fill = value),colour = "white")+ #geom_tile: 區塊著色
    scale_fill_gradient(low = "white",high = "steelblue") #數值低：白色
```

看上圖可以發現，因為G欄資料明顯大於其他欄位，導致顏色差異不明顯，為了解決此問題，將個欄位的資料標準化處理，這邊使用到apply函式

apply()有類似for迴圈的功能

- apply(Data, MARGIN, FUN,…)
    - Data：矩陣（Matrix），Data Frame
    - MARGIN：1=row, 2=column
    - FUN：函數
    - …：函數要用的參數
    
```{r message=FALSE,warning=F,fig.height=4}
nba[,2:21]<-apply(nba[,2:21], 2, scale) #scale處理，將數值轉為平均=0
head(nba,2)
nba.m <- melt(nba) ##寬轉長
ggplot(nba.m, aes(variable, Name)) + 
    geom_tile(aes(fill = value),colour = "white")+ #geom_tile: 區塊著色
    scale_fill_gradient(low = "white",high = "steelblue") #數值低：白色
```

以上範例之參考資料為[How to Make a Heatmap – a Quick and Easy Solution](http://flowingdata.com/2010/01/21/how-to-make-a-heatmap-a-quick-and-easy-solution/){target="_blank"}

## Treemap
Treemap(矩形式樹狀結構繪圖法)是以二維平面的方式展示包含階層結構（hierarchical）形式的統計資訊，在R中可以使用`treemapify`[@R-treemapify] packages
```{r eval=F, message=FALSE,warning=F,fig.height=4}
install.packages("devtools")
library(devtools)
install_github("wilkox/ggfittext")
install_github("wilkox/treemapify") 
```
```{r message=FALSE,warning=F,fig.height=4}
library(treemapify)
```

以G20 Dataset為例，二十國集團（英語：Group of Twenty，縮寫：G20）是一個國際經濟合作論壇，於1999年12月16日在德國柏林成立，屬於布雷頓森林體系框架內非正式對話的一種機制，由七國集團（美國、英國、法國、德國、義大利、日本、加拿大），金磚五國（中國、印度、巴西、俄羅斯、南非），七個重要經濟體（澳大利亞、墨西哥、韓國、土耳其、印尼、沙烏地阿拉伯、阿根廷），以及歐盟組成。按照慣例，國際貨幣基金組織與世界銀行列席該組織的會議。二十國集團的GDP總量約佔全球GDP的85％，貿易佔全球貿易總額的80%以上，人口約佔全球人口的2/3。（[維基百科](https://en.wikipedia.org/wiki/G-20_major_economies){target="_blank"}）

G20 Dataset包含20個國家的資訊，資料欄位有：

- Region 國家所在區域
- Country 國家名稱
- Trade.mil.USD 總貿易額，以百萬為單位
- Nom.GDP.mil.USD 名義國內生產總值，以百萬為單位
- HDI 人類發展指數（[維基百科](https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E7%B1%BB%E5%8F%91%E5%B1%95%E6%8C%87%E6%95%B0){target="_blank"}）
- Population  人口數
- Economic.classification 經濟狀況分類

首先將資料讀入，並用`str()`函式觀察資料型態
```{r G20data, message=FALSE,warning=F,fig.height=4}
data(G20)#範例資料
str(G20)
```

用搭配`ggplot()`函數，使用`geom_treemap()`做圖
```{r ggplotify1, message=FALSE,warning=F,fig.height=4}
ggplot(G20, aes(area = gdp_mil_usd, fill = hdi)) +
  geom_treemap()
```


看函式名稱不難了解`ggplotify()`也是基於`ggplot2`套件開發，所以可以使用ggplot2的圖形設定參數改變圖形樣式，由於數字越大顏色越深比較符合視覺化的常理，所以這邊使用`ggplot2`的`scale_fill_gradient()`函式指定數值高低所需的顏色
```{r ggplotify2,message=FALSE,warning=F,fig.height=4}
ggplot(G20, aes(area = gdp_mil_usd, fill = hdi, label = country)) +
  geom_treemap() + 
    scale_fill_gradient(low = "white",high = "steelblue") #指定高低顏色
```

也可使用`geom_treemap_text()`加上文字標籤。

```{r ggplotify3,message=FALSE,warning=F,fig.height=4}
ggplot(G20, aes(area = gdp_mil_usd, fill = hdi, label = country)) +
  geom_treemap() + 
  scale_fill_gradient(low = "white",high = "steelblue") #指定高低顏色+
  geom_treemap_text(fontface = "italic", colour = "white", place = "centre",
                    grow = TRUE)
```

完整做圖程式碼如下：
```{r eval=F, message=FALSE,warning=F,fig.height=4}
## install.packages("devtools") 第一次使用前需要安裝
## library(devtools)
## install_github("wilkox/treemapify") 
library(treemapify)
data(G20)#載入範例資料
ggplot(G20, aes(area = gdp_mil_usd, fill = hdi, label = country)) +
  geom_treemap() + 
  scale_fill_gradient(low = "white",high = "steelblue") #指定高低顏色+
  geom_treemap_text(fontface = "italic", colour = "white", place = "centre",
                    grow = TRUE)
```

`treemap`[@R-treemap] package也提供相同的功能
```{r treemap1,message=FALSE,warning=F,fig.height=4}
library(treemap)
data(GNI2014)
treemap(GNI2014,
       index=c("continent", "iso3"), #分組依據
       vSize="population", #區塊大小
       vColor="GNI", #顏色深淺
       type="value")
```

[參考資料](https://github.com/wilkox/treemapify){target="_blank"}

## 參考文件與資源

- 官方網站[文件](http://docs.ggplot2.org/current/){target="_blank"}
- RStudio製作的[ggplot cheat sheet](https://www.rstudio.com/wp-content/uploads/2016/11/ggplot2-cheatsheet-2.1.pdf){target="_blank"}
- DataCamp互動式課程1 [Data Visualization with ggplot2 (Part 1)](https://www.datacamp.com/courses/data-visualization-with-ggplot2-1){target="_blank"}
- DataCamp互動式課程2 [Data Visualization with ggplot2 (Part 2)](https://www.datacamp.com/courses/data-visualization-with-ggplot2-2){target="_blank"}
- DataCamp互動式課程3 [Data Visualization with ggplot2 (Part 3)](https://www.datacamp.com/courses/data-visualization-with-ggplot2-3){target="_blank"}

<!--chapter:end:08-graphics.Rmd-->

# 互動式資料呈現 {#InteractiveGraphics}
在R中有多種互動式資料呈現方式，除了傳統的`GGobi`、`iPlots`、`identify`等套件外，結合網頁呈現的互動畫呈現方式有更多的彈性，以下介紹幾種好用的互動式套件：

- ggvis
- googleVis
- Plot.ly

使用者可依需求選擇使用。

最後再介紹Shiny，一個RStudio推出供R語言使用的網頁應用框架，使用者可以將做好的互動式圖表用Shiny部署網頁，並將分析結果以網頁的方式分享給別人。

## ggvis

ggvis[@R-ggvis] 是RStudio開發的互動式繪圖套件，繪圖語法與ggplot2[@R-ggplot2]套件類似，基本概念是使用R做資料處理與分析，然後利用網頁的方式做視覺化呈現。如果使用RStudio IDE，透過ggvis套件畫的圖會呈現在右下角的**Viewer**視窗中。

使用ggvis套件時，必須先安裝與載入
```{r ggvisInstall, eval=F, message=F}
install.packages("ggvis")
```
```{r ggvisLoad, message=F}
library(ggvis)
```
```{r ggvis1, message=F}
p <- ggvis(mtcars, x = ~wt, y = ~mpg)
layer_points(p)
```

增加`input_slider`函數，讓使用者可以調整圖形畫圖方式（因書本輸出格式，不支援動態畫圖，請將程式碼複製貼上到RStudio中就能看到互動式畫圖的樣子）
```{r ggvis2, message=F}
p<-ggvis(mtcars,~wt)
layer_histograms(p,width =  input_slider(0, 2, step = 0.10, label = "width"),
                   center = input_slider(0, 2, step = 0.05, label = "center"))
```

除了`input_slider()`外，ggvis還提供以下互動式輸入介面：

- input_checkbox()
- input_checkboxgroup()
- input_numeric()
- input_radiobuttons()
- input_select()
- input_text()

其他詳細使用說明請參考[官網](http://ggvis.rstudio.com/){target="_blank"}

##googleVis
googleVis[@R-googleVis] package是基於[Google Chart API](https://developers.google.com/chart/interactive/docs/){target="_blank"}開發的R套件，使用前需要先安裝與載入。

```{r googlevisInstall, eval=F, message=F}
install.packages("googleVis")
```

```{r googlevisLoad, message=F}
library(googleVis)
```

如果想要一次看完所有作圖範例，可用以下指令（執行完畢需要一點時間）
```{r googlevisDemo, eval=F, message=F}
demo(googleVis)
```

googleVis套件提供多種繪圖方式，包括：

- 一維資料做圖
    - gvisHistogram
  
- 類別-數值資料做圖
    - gvisPieChart
    - gvisGauge
    - gvisBarChart
    - gvisColumnChart
    - gvisCandlestickChart
  
- 數值-數值資料做圖
    - gvisLineChart
    - gvisAreaChart
    - gvisSteppedAreaChart
    - gvisScatterChart
    - gvisAnnotationChart
  
- 數值-數值-數值資料做圖
    - gvisBubbleChart

- 地圖相關
    - gvisIntensityMap
    - gvisGeoChart
    - gvisMap
  
- 其他圖形
    - gvisOrgChart
    - gvisTreeMap
    - gvisSankey
    - gvisComboChart
    - gvisCalendar
    - gvisTimeline

詳細使用說明請參考[googleVis套件說明](https://cran.r-project.org/web/packages/googleVis/vignettes/googleVis_examples.html){target="_blank"}

```{r googlevis1, message=F}
df=data.frame(country=c("US", "GB", "BR"), 
              val1=c(10,13,14), 
              val2=c(23,12,32))
Line <- gvisLineChart(df)
plot(Line)
```

```{r googlevis2, message=F}
require(datasets)
states <- data.frame(state.name, state.x77)
GeoStates <- gvisGeoChart(states, "state.name", "Illiteracy",
                          options=list(region="US", 
                                       displayMode="regions", 
                                       resolution="provinces",
                                       width=600, height=400))
plot(GeoStates)
```

```{r googlevis3, message=F}
AndrewMap <- gvisMap(Andrew, "LatLong" , "Tip", 
                     options=list(showTip=TRUE, 
                                  showLine=TRUE, 
                                  enableScrollWheel=TRUE,
                                  mapType='terrain', 
                                  useMapTypeControl=TRUE))
plot(AndrewMap)
```

其他Google Chart可以做的圖形種類，可以參考[Chart Gallery](https://developers.google.com/chart/interactive/docs/gallery){target="_blank"}

## Plot.ly
[Plotly](https://plot.ly/){target="_blank"}是一個線上分析與視覺化的工具，如需線上作圖，可至https://plot.ly/create/ 建立帳號並開始作圖。Plotly也**提供套件R使用**，使用者可以透過安裝plotly[@R-plotly] package在R中畫基於**Plotly.js** (**d3.js ** + **stack.gl**)的圖表和地圖。除了R的套件外，還有Python, MATLAB, Perl, Julia, Arduino等套件可供使用。

使用plotly套件時，必須先安裝與載入
```{r plotlyInstall, eval=F, message=F}
install.packages("plotly")
```
```{r plotlyLoad, message=F}
library(plotly)
```

```{r plotly1, message=F}
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = ~carat, y = ~price, color = ~carat,
        size = ~carat, text = ~paste("Clarity: ", clarity))
```

```{r plotly2, message=F,warning=F}
p <- ggplot(data = d, aes(x = carat, y = price)) +
  geom_point(aes(text = paste("Clarity:", clarity))) +
  geom_smooth(aes(colour = cut, fill = cut)) + facet_wrap(~ cut)
ggplotly(p)
```

Plotly提供免費的圖形分享空間，方便使用者將做好的圖上傳到網路上，若想使用Plotly提供圖形分享空間，必須要先申請Plotly帳號，透過[此網頁](https://plot.ly/settings/api)取得API keys，並使用下列程式碼設定帳號與API keys
```{r setPlotly, eval=F, message=F}
Sys.setenv("plotly_username"="your_plotly_username")
Sys.setenv("plotly_api_key"="your_api_key")
```

設定完基本資料後，使用`plotly_POST`函式將plotly物件`p`上傳到指定路徑(`filename`)的網路空間中。
```{r postPlotly, eval=F, message=F}
plotly_POST(p, filename = "file-name")
```

參考資料

- [Plotly官網](https://plot.ly/){target="_blank"}
- [Plotly API for R](https://plot.ly/r/){target="_blank"}
- [Plotly cheat sheet](https://images.plot.ly/plotly-documentation/images/r_cheat_sheet.pdf){target="_blank"}


## Shiny簡介
Shiny是RStudio推出供R語言使用的網頁應用框架（Web application framework），透過Shiny，使用者可以輕鬆地將資料分析結果轉換成互動式的網頁應用，不用另外學習其他網頁程式語言（如HTML, CSS, JavaScript等），若要使用Shiny，RStudio IDE提供完整測試預覽功能，建議一起使用。使用前必須先安裝並載入`shiny` [@R-shiny] package

```{r shinyInstall, eval=F, message=F}
install.packages("shiny")
```
```{r shinyLoad, message=F}
library(shiny)
```

shiny package內提供11個網頁部署範例，使用者可以直接用下列程式碼觀看相關範例的呈現效果與原始碼
```{r shinyEx, eval=F, message=F}
runExample("01_hello") # a histogram
runExample("02_text") # tables and data frames
runExample("03_reactivity") # a reactive expression
runExample("04_mpg") # global variables
runExample("05_sliders") # slider bars
runExample("06_tabsets") # tabbed panels
runExample("07_widgets") # help text and submit buttons
runExample("08_html") # Shiny app built from HTML
runExample("09_upload") # file upload wizard
runExample("10_download") # file download wizard
runExample("11_timer") # an automated timer
```

在RStudio內，可直接透過新增專案 **New Project**新增Shiny應用程式

```{r echo=FALSE}
knitr::include_graphics("figure/shiny1.png")
```

```{r echo=FALSE}
knitr::include_graphics("figure/shiny2.png")
```

```{r echo=FALSE}
knitr::include_graphics("figure/shiny3.png")
```

```{r echo=FALSE}
knitr::include_graphics("figure/shiny4.png")
```


Shiny應用程式包括兩個元件：

  - **ui.R** : 使用者介面（前端）程式碼 user-interface script
  - **server.R** : 伺服器端（後端）程式碼 server script

使用者介面程式碼**ui.R**控制Shiny應用程式的外觀，伺服器端程式碼**server.R**控制Shiny應用程式的功能。

**ui.R範例**
```{r ui, eval=F, message=F}
library(shiny)

shinyUI(fluidPage(

  # 網頁標題
  titlePanel("Hello Shiny!"),

  # Sidebar + slider
  sidebarLayout(
    sidebarPanel(
      sliderInput("bins",
                  "Number of bins:",
                  min = 1,
                  max = 50,
                  value = 30)
    ),

    # 圖形呈現
    mainPanel(
      plotOutput("distPlot")
    )
  )
))
```

**server.R範例**
```{r server, eval=F, message=F}
library(shiny)

shinyServer(function(input, output) {

 
  # 將直方圖Histogram存入distPlot變數，在UI端用plotOutput呈現
  output$distPlot <- renderPlot({
    x  <- faithful[, 2]  # Old Faithful Geyser data
    # input$bins是用UI端的Sidebar + slider調整
    bins <- seq(min(x), max(x), length.out = input$bins + 1)
    hist(x, breaks = bins, col = 'darkgray', border = 'white')
  })
})
```

若想使用介紹過的Plotly與Shiny結合，可參考[此教學網頁](https://plot.ly/r/shiny-tutorial/){target="_blank"}

參考資料

- [Shiny官網](http://shiny.rstudio.com/){target="_blank"}
- [Shiny cheat sheet](https://www.rstudio.com/wp-content/uploads/2016/01/shiny-cheatsheet.pdf){target="_blank"}





<!--chapter:end:09-InteractiveGraphics.Rmd-->

# 資料探勘 {#datamining}
**撰寫中**

## 什麼是資料探勘
**資料探勘（Data mining）**是用人工智慧、機器學習、統計學的交叉方法，在相對較大型的資料集中發現模式的計算過程。使用資料探勘技術可以建立從**輸入資料**學習新資訊，變成智慧的**演算法**或**資料模式**，用來**預測事件**或**協助決策**。所以，當資料太`少`或`太髒`的時候，資料探勘的效力會被影響。

資料探勘要派上用場，必須有以下條件：

- 有一些模式/模型可`學`
- 很難定義這些模式/模型
- 有資料可`學`這些模式/模型

資料探勘的應用範例如下：

- 天氣預測
- 搜尋建議、購物建議
- 股市預測
- 臉部辨識、指紋辨識
- 垃圾郵件標記
- 尿布啤酒

資料探勘可分為**監督式**學習與**非監督式**學習，監督式學習的特點是訓練資料中有**正確答案**，由輸入物件和預期輸出所組成，而演算法可以由訓練資料中學到或建立一個模式，並依此模式推測新的實例；非監督式學習則不用提供**正確答案**，也就是不需要人力來輸入標籤，單純利用訓練資料的特性，將資料分群分組。

此兩種學習可解決不同的問題，條列如下：

- Supervised learning 監督式學習
    - Regression 迴歸：真實的'值'（股票、氣溫）
    - Classification 分類：分兩類（P/N, Yes/No, M/F, Sick/Not sick）/分多類 (A/B/C/D)

- Unsupervised learning 非監督式學習
    - Clustering 分群
    - Association Rules 關聯式規則

在**監督式**學習中常見的資料探勘演算法如下： 

  - Linear Regression 線性迴歸
  - Logistic Regression 羅吉斯迴歸、邏輯迴歸
  - Support Vector Machines 支持向量機
  - Decision Trees 決策樹
  - K-Nearest Neighbor
  - Neural Networks 神經網路
  - Deep Learning 深度學習


在**非監督式**學習中常見的資料探勘演算法如下： 

  - Hierarchical clustering 階層式分群
  - K-means clustering
  - Neural Networks 神經網路
  - Deep Learning 深度學習

以下介紹在R中使用各類演算法的方法

## Regression 迴歸
Regression Analysis 迴歸分析主要用在了解兩個或多個變數間`是否相關`、`相關方向與強度`，並建立`數學模型`以便觀察特定變數來預測研究者感興趣的變數，常見的迴歸分析演算法包括：

- Linear Regression 線性迴歸
- Logistic Regression 羅吉斯迴歸、邏輯迴歸

### Linear Regression 線性迴歸

首先，嘗試將Linear Regression 線性迴歸用在NBA的資料看看，做NBA`得分`與`上場分鐘數`的線性迴歸觀察
```{r linear1,message=FALSE,warning=FALSE}
#讀入SportsAnalytics package
library(SportsAnalytics)
#擷取2015-2016年球季球員資料
NBA1516<-fetch_NBAPlayerStatistics("15-16")
```

```{r linear2,warning=F,message=F,fig.height=4}
library(ggplot2)
ggplot(NBA1516,aes(x=TotalMinutesPlayed,y=TotalPoints))+
    geom_point()+geom_smooth(method = "glm")
```

在R中，最基本的簡單線性迴歸分析為`lm()`，使用方法為`lm(formula,data=資料名稱)`，搭配formula使用，formula的撰寫方法為：依變項~自變項1＋自變項2＋....
```{r linear3,warning=F,message=F,fig.height=4.5}
lm(TotalPoints~TotalMinutesPlayed,data =NBA1516)
```
由此可知總得分數TotalPoints等於`0.4931` * 總出場分鐘數 `-85.9071`

TotalPoints = `0.4931` * TotalMinutesPlayed `-85.9071`

更被廣泛使用的是廣義線性迴歸模型generalized linear models (glm)，函數為`glm()`，使用方法與`lm()`類似，包括了線性迴歸模型和邏輯迴歸模型。
如果需要修改預設模型，可設定family參數：

    - `family="gaussian"` 線性模型模型
    - `family="binomial"` 邏輯迴歸模型
    - `family="poisson"` 卜瓦松迴歸模型

Gaussian distribution高斯函數是`常態分布`的密度函數

Binomial distribution二項分布是`n個獨立的是/非試驗中成功的次數`的離散機率分布

Poisson distribution`次數`分佈：

- 某一服務設施在一定時間內受到的服務請求的次數
- 公車站的候客人數
- 機器故障數
- 自然災害發生的次數
- DNA序列的變異數.....

以下為使用多變量線性迴歸來分析`得分`與`上場分鐘數`和`兩分球出手數`的關係範例

```{r linear4,warning=F,message=F,fig.height=4.5}
# e+01: 10^1 / e-04: 10^(-4)
glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted,
    data =NBA1516)
```
由此可知總得分數等於`-0.0002347` * 總出場分鐘數 + `1.255794` * 兩分球出手數  `-17.99`
TotalPoints = `-0.0002347` * TotalMinutesPlayed + `1.255794` * FieldGoalsAttempted  `-17.99`


如需使用多變量線性迴歸來分析`得分`與`上場分鐘數`和`兩分球出手數`和`守備位置`的關係，可修改formula

```{r linear5,warning=F,message=F,fig.height=4.5}
glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+Position,
    data =NBA1516)
# e+01: 10^1 / e-04: 10^(-4)
```
由此可知總得分數TotalPoints和`上場分鐘數`和`兩分球出手數`和`守備位置`的關係為：
TotalPoints = `-0.0065` * TotalMinutesPlayed + `1.28` *FieldGoalsAttempted  `+22.85` + `22.85` * PositionPF + `-65.03` * PositionPG + `-38.52` * PositionSF + `-52.18` * PositionSG

由上述結果可發現，`守備位置`的變項被轉為**虛擬變項 Dummy Variable**：PositionPF、PositionPG、PositionSF、PositionSG，如果是控球後衛（PG），會得到：

  - PositionPF=0
  - PositionPG=1
  - PositionSF=0
  - PositionSG=0

可能有人會問，那中鋒去哪了？其實中鋒被當作基準項，也就是當守備位置是中鋒(C)時，會得到：

  - PositionPF=0
  - PositionPG=0
  - PositionSF=0
  - PositionSG=0

總結以上，多變量線性迴歸分析有下列特色：

- 假設：各變數相互獨立！
- 若自變項X是類別變項，需要建立`虛擬變項`
- 在R裡，`類別變項`請記得轉成factor，R會自動建立`虛擬變項`
- 用在`依變數為連續變數`，`自變數為連續變數或虛擬變數`的場合


### Logistic Regression 羅吉斯迴歸


Logistic Regression 羅吉斯迴歸常用在`依變數為二元變數（非0即1）`的場合，如：
  - 生病/沒生病
  - 錄取/不錄取
  - `family="binomial"` 邏輯迴歸模型

以分數資料為例，分析為什麼錄取/不錄取？
```{r logistic1,warning=F,message=F,fig.height=4.5}
mydata <- read.csv("https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/binary.csv")
```
```{r warning=F,message=F,eval=F}
# GRE:某考試成績, GPA:在校平均成績, rank:學校聲望
head(mydata)
```
```{r warning=F,message=F,echo=F}
knitr::kable(head(mydata)) 
```

```{r logistic2,warning=F,message=F,fig.height=4.5}
mydata$rank <- factor(mydata$rank)
mylogit <- glm(admit ~ gre + gpa + rank,
               data = mydata, family = "binomial")
sum<-summary(mylogit)
sum$coefficients
```

### 最佳模型篩選
到底該用哪個模型來預測，會得到最準確的結果？在迴歸模型中，常用的判斷準則包括：

  - Akaike’s Information Criterion (AIC)
  - Bayesian Information Criterion (BIC)
    
AIC和BIC都是數值越小越好，以下建立三個模型，並比較其AIC，
```{r linear7,warning=F,message=F,fig.height=4.5}
OneVar<-glm(TotalPoints~TotalMinutesPlayed,data =NBA1516)
TwoVar<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted,
            data =NBA1516)
ThreeVar<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+Position,
              data =NBA1516)
c(OneVar$aic,TwoVar$aic,ThreeVar$aic)
```

在建立迴歸模型時，常會遇到到底該放多少參數？所有參數都有用嗎？這類的問題，我們可以藉由觀察coefficients來判斷參數在模型中的"實用程度"
```{r linear8,warning=F,message=F,fig.height=4.5}
sum2<-summary(TwoVar)
sum2$coefficients
```

```{r linear9,warning=F,message=F,fig.height=4.5}
sum3<-summary(ThreeVar)
sum3$coefficients
```

## Decision Trees 決策樹

決策樹是在`樹狀目錄`中建立一系列分割，以建立模型。這些分割會表示成`「節點」(Node)`。每次發現輸入資料行與可預測資料行有明顯地相互關聯時，此演算法就會在模型中加入一個`節點`。演算法決定分岔的方式不同，視它預測連續資料行或分隔資料行而定。

```{r echo=F}
library(rpart)
library(rpart.plot)
DT<-rpart(Position~Blocks+ThreesMade+Assists+Steals,data=NBA1516)
prp(DT)	
```

以下介紹常見的Classification And Regression Tree (CART)，使用前須先安裝`rpart` packages [@R-rpart]

```{r rpart1,eval=F,warning=F,message=F,fig.height=4.5}
install.packages("rpart")
```
以前述NBA資料為例，嘗試用用籃板/三分/助攻/抄截數據來判斷守備位置，建立決策樹的函數為`rpart()`，使用方式為`rpart(formula, data)`
```{r rpart2,warning=F,message=F,fig.height=4.5}
library(rpart)
DT<-rpart(Position~Blocks+ThreesMade+Assists+Steals,data=NBA1516)
DT
#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）
```

```{r rpart3,warning=F,message=F,fig.height=4.5}
par(mfrow=c(1,1), mar = rep(1,4)) #下,左,上,右
plot(DT)
text(DT, use.n=F, all=F, cex=1)
#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）
```

可以看出預設的`plot()`畫出來的圖很難看懂，可以改用`rpart.plot` package [@R-rpart.plot]裡面的`prp()`
```{r rpart41,eval=F,warning=F,message=F,fig.height=4.5}
install.packages("rpart.plot") #第一次使用前須先安裝
```
```{r rpart4,warning=F,message=F,fig.height=4.5}
library(rpart.plot)
prp(DT)	
```

決策樹演算法決定`節點`的方式如下：

- Gini impurity
- Information gain
- Variance reduction

細節可參考[維基百科](https://en.wikipedia.org/wiki/Decision_tree_learning)


## Clustering 分群
Clustering 分群的目的是將相近的觀察值作做分群，分群過程中，可能會遇到以下問題：

- 如何定義相近？
- 如何分群？
- 如何視覺化？
- 如何解釋分群？

### Hierarchical clustering 階層式分群

- An agglomerative approach
    - Find closest two things
    - Put them together
    - Find next closest

- Requires
    - A defined distance
    - A merging approach

- Produces
    - A tree showing how close things are to each other

如何定義相近？用距離`distance`的概念來定義相近。

- Distance or similarity
    - Continuous - euclidean distance
    - Continuous - correlation similarity
    - Binary - manhattan distance

- Pick a distance/similarity that makes sense for your problem


 Example distances - Euclidean

$$\sqrt{(A_1-A_2)^2 + (B_1-B_2)^2 + \ldots + (Z_1-Z_2)^2}$$

 Example distances - Manhattan

$$|A_1-A_2| + |B_1-B_2| + \ldots + |Z_1-Z_2|$$

 Merging apporach
 
- Agglomerative 聚合

    - Single-linkage：取最小值
    - Complete-linkage：取最大值
    - Average-linkage：取平均值
    

 Hierarchical clustering - hp vs. mpg
```{r, echo=F, fig.height=5.5,fig.width=8}
par(mfrow=c(1,1),mar=rep(2,4))
plot(mtcars$hp, mtcars$mpg, col = "blue", pch = 19, cex = 2)
text(mtcars$hp + 25, mtcars$mpg,
     labels = as.character(rownames(mtcars)))
```

Hierarchical clustering - #1

```{r echo=F,message=F,warning=F, fig.height=5,fig.width=8}
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
labelCar<-rownames(mtcars)[-1]
#install.packages("fields")
library(fields)
dataFrame <- data.frame(x=x,y=y)
rdistxy <- rdist(dataFrame) #Euclidean distance
diag(rdistxy) <- diag(rdistxy) + 1e5

# Find the index of the points with minimum distance
ind <- which(rdistxy == min(rdistxy),arr.ind=TRUE)
par(mfrow=c(1,2),mar=rep(1,4))
plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)

# Make a cluster and cut it at the right height
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[1]+0.00001) )
plot(cutDendro$lower[[23]],yaxt="n")
```

 Hierarchical clustering - #2
```{r echo=F, fig.height=6,fig.width=8}
# Find the index of the points with minimum distance
ind3 <- which(rdistxy == rdistxy[order(rdistxy)][3],arr.ind=TRUE)
par(mfrow=c(1,1),mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)
points(x[ind3[1,]],y[ind3[1,]],col="red",pch=19,cex=1)
```

 Hierarchical clustering - #3

```{r echo=F,fig.height=5,fig.width=8}
# Find the index of the points with minimum distance
ind3 <- which(rdistxy == rdistxy[order(rdistxy)][3],arr.ind=TRUE)
par(mfrow=c(1,3),mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)
points(x[ind3[1,]],y[ind3[1,]],col="red",pch=19,cex=1)

# Make dendogram plots
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[2]) )
plot(cutDendro$lower[[19]],yaxt="n")
plot(cutDendro$lower[[22]],yaxt="n")

```

可用`dist()`函數計算距離，使用method=""設定計算距離的依據
```{r,fig.height=4,fig.width=6,warning=F,message=F}
mtcars.mxs<-as.matrix(mtcars)
d<-dist(mtcars.mxs) #預設為euclidean
head(d)
```

`dist()`函數可用方法包括：
 "euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski"
```{r,fig.height=4,fig.width=6,warning=F,message=F}
d<-dist(mtcars.mxs, method="manhattan") #計算manhattan距離
head(d)
```


用`hclust`函數畫圖，必要參數是各觀察值的距離（可用`dist()`函數計算）
```{r,fig.height=4,fig.width=6}
par(mar=rep(2,4),mfrow=c(1,1))
hc<-hclust(dist(mtcars.mxs)) #可用method參數設定聚合方法，預設為complete
plot(hc)
```

```{r,fig.height=4,fig.width=6}
par(mar=rep(2,4),mfrow=c(1,1))
hc<-hclust(dist(mtcars.mxs),method="average") #聚合方法為計算平均距離
plot(hc)
```

```{r,fig.height=4,fig.width=6}
clusterCut <- cutree(hc, k=5) #分5群
sort(clusterCut)
```

```{r,fig.height=4,fig.width=6}
ggplot()+geom_point(data=mtcars,
                    aes(x=hp,y=mpg,color=as.factor(clusterCut)))
```


```{r,fig.height=4,fig.width=6}
clusterCut <- cutree(hc,h =4) #切在高度=4的地方（距離=4）
sort(clusterCut)
```


```{r,fig.height=4.5,fig.width=6}
par(mar=rep(0.2,4),mfrow=c(1,1))
heatmap(mtcars.mxs)
```

```{r, fig.height=4,fig.width=4}
distxy <- dist(mtcars.mxs)
hClustering <- hclust(distxy)
plot(hClustering)
```


 Hierarchical clustering: summary
- 可快速瀏覽觀察值與各欄位的關係

- 分群結果可能被以下參數影響：
    - 計算距離的方法
    - 分群依據
    - 更改數值的大小

- 可能會遇到的問題：
    - 有時會不太清楚要如何切割分群結果


### K-means clustering

- 執行步驟
    - 指定要分幾群
    - 計算每一群的中心點
    - 將各個物件/觀察值指定給最近的中心點
    - 依照新的分群計算新的中心點

- 輸入
    - 計算距離的資料（數值）
    - 要分成幾群 # of clusters
    - 預設個群的中間點位置


- 產出
    - 計算出每’群‘的中心點
    - 指定每個觀察值所在的’群‘


```{r, fig.height=4,fig.width=6}
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=labelCar)
```


```{r,echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=labelCar)
cx <- c(-1,0.5,2.5)
cy <- c(2,0,-1)
points(cx,cy,col=c("red","orange","purple"),pch=3,cex=2,lwd=2)
```


```{r,echo=FALSE,fig.height=4.5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)
cx <- c(-1,0.5,2.5)
cy <- c(2,0,-1)
points(cx,cy,col=cols1,pch=3,cex=2,lwd=2)
## Find the closest centroid
distTmp <- matrix(NA,nrow=3,ncol=length(x))
distTmp[1,] <- (x-cx[1])^2 + (y-cy[1])^2
distTmp[2,] <- (x-cx[2])^2 + (y-cy[2])^2
distTmp[3,] <- (x-cx[3])^2 + (y-cy[3])^2
newClust <- apply(distTmp,2,which.min)
points(x,y,pch=19,cex=2,col=cols1[newClust])
```



```{r,echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)

## Find the closest centroid
points(x,y,pch=19,cex=2,col=cols1[newClust])
newCx <- tapply(x,newClust,mean)
newCy <- tapply(y,newClust,mean)
points(newCx,newCy,col=cols1,pch=3,cex=2,lwd=2)
```



```{r,echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)

points(newCx,newCy,col=cols1,pch=3,cex=2,lwd=2)

## Iteration 2
distTmp <- matrix(NA,nrow=3,ncol=length(x))
distTmp[1,] <- (x-newCx[1])^2 + (y-newCy[1])^2
distTmp[2,] <- (x-newCx[2])^2 + (y-newCy[2])^2
distTmp[3,] <- (x-newCx[3])^2 + (y-newCy[3])^2
newClust2 <- apply(distTmp,2,which.min)
points(x,y,pch=19,cex=2,col=cols1[newClust2])

```



```{r,echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)

## Final centroids
finalCx <- tapply(x,newClust2,mean)
finalCy <- tapply(y,newClust2,mean)
points(finalCx,finalCy,col=cols1,pch=3,cex=2,lwd=2)
points(x,y,pch=19,cex=2,col=cols1[newClust2])

```




 `kmeans()`

- Important parameters: `x`, `centers`, `iter.max`, `nstart`

```{r kmeans}
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=3)
names(kmeansObj)
kmeansObj$cluster
```



```{r,fig.height=4,fig.width=4}
par(mar=rep(0.2,4))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
```



 Heatmaps

```{r,fig.height=3,fig.width=8}
set.seed(1234)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
kmeansObj <- kmeans(dataMatrix,centers=3)
par(mfrow=c(1,2), mar = c(2, 4, 0.1, 0.1))
image(t(dataMatrix)[,nrow(dataMatrix):1],yaxt="n")
image(t(dataMatrix)[,order(kmeansObj$cluster)],yaxt="n")
```


 K-means注意事項

- 需要決定# of clusters
    - 用眼睛/人工/特殊要求選
    - 用 cross validation/information theory選
    - [Determining the number of clusters](http://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)


- K-means 沒有一定的結果
    - 不同的 # of clusters
    - 不同的 # of iterations



`kmeans()`, k=2

```{r,echo=F,fig.height=5,fig.width=4}
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=2)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:2,pch=3,cex=3,lwd=3)
```

 `kmeans()`, k=3

```{r,echo=F,fig.height=5,fig.width=4}
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=3)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
```

`kmeans()`, k=4

```{r,echo=F,fig.height=5,fig.width=4}
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=4)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:4,pch=3,cex=3,lwd=3)
```

## Association Rules 關聯式規則

**關聯式規則**用於從大量數據中挖掘出有價值的數據項之間的相關關係，原則為不考慮項目的次序，而僅考慮其組合。著名的`購物籃分析 (Market Basket Analysis)`即為關聯式規則分析的應用。而**Apriori演算法**是挖掘`布林關聯規則` (Boolean association rules) 頻繁項集的算法，在R中，可以使用`arules`[@R-arules] 套件來執行關聯式規則分析。

以下以超市資料為例，使用關聯式規則分析執行購物籃分析。

首先先讀入超市消費資料

```{r warning=F,message=F,fig.height=4.5}
# Load the libraries
if (!require('arules')){
  install.packages("arules");
  library(arules) #for Apriori演算法
}
if (!require('datasets')){
  install.packages("datasets");
  library(datasets) #for Groceries data
}
data(Groceries) # Load the data set
Groceries@data@Dim #169 種商品，9835筆交易資料
```

超市資料的原始樣貌為：
```{r echo=FALSE}
knitr::include_graphics("figure/groceries.png")
```

可使用arules套件中的apriori函數來實作apriori演算法
```{r warning=F,message=F,fig.height=4.5}
# Get the rules
rules <- apriori(Groceries, # data= Groceries
                 parameter = list(supp = 0.001, conf = 0.8), #參數最低限度
                 control = list(verbose=F)) #不要顯示output
options(digits=2) # Only 2 digits
inspect(rules[1:5]) # Show the top 5 rules
```


根據計算結果，解讀模型的方法如下：

啤酒=>尿布

- `Support`: 一次交易中，包括規則內的物品的機率。買啤酒同時買尿布的機率。交集
- `Confidence`: 包含左邊物品A的交易也會包含右邊物品B的條件機率。在買了啤酒的顧客中，有買尿布的比例。
- `Lift`: 規則的信心比期望值高多少。（買了啤酒以後，有買尿布的機率）/（在所有顧客群中買尿布的機率）
    - `lift`=1: items on the left and right are independent.

可用排序功能排序後，列出最有關連（confidence最高）的幾條規則
```{r warning=F,message=F,fig.height=4.5}
rules<-sort(rules, by="confidence", decreasing=TRUE) #按照confidence排序
inspect(rules[1:5]) # Show the top 5 rules
```

特別針對某項商品（右側變數），像是：買了什麼東西的人，會買`牛奶`呢？
```{r warning=F,message=F,fig.height=4.5}
rulesR<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.08),
        appearance = list(default="lhs",rhs="whole milk"), #設定右邊一定要是牛奶
        control = list(verbose=F)) #不要顯示output
rulesR<-sort(rulesR, decreasing=TRUE,by="confidence") #按照confidence排序
inspect(rulesR[1:5]) # Show the top 5 rules
```

特別針對某項商品（左側變數），像是：買了`牛奶`的人，會買什麼呢？
```{r warning=F,message=F,fig.height=4.5}
rulesL<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2),
        appearance = list(default="rhs",lhs="whole milk"), #設定左邊一定要是牛奶
        control = list(verbose=F)) #不要顯示output
rulesL<-sort(rulesL, decreasing=TRUE,by="confidence") #按照confidence排序
inspect(rulesL[1:5]) # Show the top 5 rules
```


 規則視覺化
```{r eval=F,warning=F,message=F,fig.height=4.5}
if (!require('arulesViz')){
  install.packages("arulesViz"); 
  library(arulesViz)
}
#Mac->http://planspace.org/2013/01/17/fix-r-tcltk-dependency-problem-on-mac/
plot(rules,method="graph",interactive=TRUE,shading=NA) #會跑一陣子
```

```{r echo=FALSE}
knitr::include_graphics("figure/arulesViz.png")
```
```{r echo=FALSE}
knitr::include_graphics("figure/arulesVizBig.png")
```

## Open Source Packages
### Prophet

Prophet 是 Facebook在2017年開放出來的時序性預測演算法，用來預測各類資料的時序變化，像是顧客造訪數、溫度、疾病發生率等等，以下是Prophet for R的安裝使用範例

- C/C++ Tool
  - [R Tools](https://cran.r-project.org/bin/windows/Rtools/) on Windows
  - [Command Line Tools](http://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/) on OS X

```{r eval=F}
install.packages('prophet')
```

[R API](https://facebookincubator.github.io/prophet/docs/quick_start.html#r-api)

```{r eval=F}
library(prophet)
library(dplyr)
df <- read.csv('https://raw.githubusercontent.com/facebookincubator/prophet/master/examples/example_wp_peyton_manning.csv') %>%
    mutate(y = log(y))
m <- prophet(df)
future <- make_future_dataframe(m, periods = 365)
tail(future)
forecast <- predict(m, future)
tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])
plot(m, forecast)
prophet_plot_components(m, forecast)

```


[Prophet官網](https://facebookincubator.github.io/prophet/)

### TensorFlow
- Python 3.5.3 **64 bit** [網站](https://www.python.org/downloads/release/python-353/)
  - Windows x86-64 executable installer
- TensorFlow 1.0.1 [網站](https://www.tensorflow.org/install/)
  - pip3 install --upgrade tensorflow
  - pip3 install --upgrade tensorflow-gpu
- C/C++ Tool
  - [R Tools](https://cran.r-project.org/bin/windows/Rtools/) on Windows
  - [Command Line Tools](http://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/) on OS X
- tensorflow package for R [網站](https://rstudio.github.io/tensorflow/index.html)

```{r eval=F}
devtools::install_github("rstudio/tensorflow")
```

TensorFlow for R

- Locating TensorFlow (optional)
- Hello World

```{r eval=F}
library(tensorflow)
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
```


### MXNet

Amazon
[Install MXNet for R](http://mxnet.io/get_started/windows_setup.html#install-mxnet-for-r)
MXNet for R [Tutorials](http://mxnet.io/tutorials/index.html#r)

MXNet for R
```{r eval=F}
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
```

## 模型驗證
在完成模型訓練後，為了驗證模型訓練的好不好，需要用一組**獨立**的測試資料，來做模型的驗證。所以，在訓練模型前，必須特別留意是否有保留一份**獨立的資料**，並確保在訓練模型時都不用到此獨立資料集。因此，資料集可分為以下兩種：

- **訓練組** Training set, Development set: 讓演算法`學`到`知識`
- **測試組** Test set, Validation set: 驗證`學`的怎麼樣

Training set和Test set通常會比例分配，如2/3的資料設為`Training set`，剩下的1/3做驗證`Test set`。以下圖的監督式學習流程圖為例，可以注意到綠色箭頭的資料集在訓練過程中從未被使用。


```{r echo=FALSE}
knitr::include_graphics("figure/SupervisedLearning.png")
```

### Regression 迴歸驗證

以NBA資料為例，首先先將資料讀入
```{r message=FALSE,warning=FALSE}
#讀入SportsAnalytics package
if (!require('SportsAnalytics')){
    install.packages("SportsAnalytics")
    library(SportsAnalytics)
}
#擷取2015-2016年球季球員資料
NBA1516<-fetch_NBAPlayerStatistics("15-16")
NBA1516<-NBA1516[complete.cases(NBA1516),]
```

- 以Training set來`選看起來最好的模型`
- 用Test set來`驗證模型是不是真的很好`
- 想像.....訓練出來題庫答得好的學生，寫到新題目不一定會寫！？
- 訓練模型時，只能看Training set，用Training set來選一個最好的模型
- 訓練模型時，不能偷看Test set，才是真正的驗證

為分出訓練組與測試組，需使用隨機抽樣的方式
```{r message=FALSE,warning=FALSE}
sample(1:10,3) # 從1到10，隨機取三個數字
sample(1:nrow(NBA1516),nrow(NBA1516)/3) #從第一行到最後一行，隨機取1/3行數
```

使用上述方法，選出1/3的元素位置，把NBA的資料分成Training 和 Test set
```{r message=FALSE,warning=FALSE}
NBA1516$Test<-F #新增一個參數紀錄分組
#隨機取1/3當Test set
NBA1516[sample(1:nrow(NBA1516),nrow(NBA1516)/3),]$Test<-T
# Training set : Test set球員數
c(sum(NBA1516$Test==F),sum(NBA1516$Test==T))
```


並用訓練組的資料（NBA1516$Test==F），訓練一個多變數線性迴歸模型
```{r warning=F,message=F,fig.height=4.5}
fit<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+
             Position+ThreesAttempted+FreeThrowsAttempted,
              data =NBA1516[NBA1516$Test==F,])
summary(fit)$coefficients
```

逐步選擇模型 stepwise 後退學習：一開始先將所有參數加到模型裡，再一個一個拿掉
```{r warning=F,message=F,fig.height=4.5}
library(MASS)
##根據AIC，做逐步選擇, 預設倒退學習 direction = "backward"
##trace=FALSE: 不要顯示步驟
finalModel_B<-stepAIC(fit,direction = "backward",trace=FALSE)
summary(finalModel_B)$coefficients
```

逐步選擇模型 stepwise 往前學習：一開始先做一個沒有參數的模型，再把參數一個一個加進去
```{r warning=F,message=F,fig.height=4.5}
##根據AIC，做逐步選擇, 往前學習 direction = "forward"
finalModel_F<-stepAIC(fit,direction = "forward",trace=FALSE)
summary(finalModel_F)$coefficients
```

逐步選擇模型 stepwise 雙向學習：參數加加減減
```{r warning=F,message=F,fig.height=4.5}
##根據AIC，做逐步選擇, 雙向學習 direction = "both"
finalModel_Both<-stepAIC(fit,direction = "both",trace=FALSE)
summary(finalModel_Both)$coefficients
```


用Test set來評估模型好不好，使用predict函數，將測試組資料放入預測模型中，預測測試組的結果
```{r warning=F,message=F,fig.height=3}
predictPoint<-predict(finalModel_Both, #Test==T, test data
                      newdata = NBA1516[NBA1516$Test==T,])
cor(x=predictPoint,y=NBA1516[NBA1516$Test==T,]$TotalPoints) #相關係數
plot(x=predictPoint,y=NBA1516[NBA1516$Test==T,]$TotalPoints)
```

### Logistic Regression 邏輯迴歸驗證

首先，先把入學資料分成Training 和 Test set。這邊要特別留意，當答案有正反兩面時，`Level 1 要放正面答案`-->有病/錄取...
```{r warning=F,message=F,fig.height=4.5}
mydata <- read.csv("https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/binary.csv")
mydata$admit <- factor(mydata$admit) # 類別變項要轉為factor
mydata$rank <- factor(mydata$rank) # 類別變項要轉為factor
mydata$Test<-F #新增一個參數紀錄分組
mydata[sample(1:nrow(mydata),nrow(mydata)/3),"Test"]<-T #隨機取1/3當Test set
c(sum(mydata$Test==F),sum(mydata$Test==T)) # Training set : Test set學生數
#修改一下factor的level: 改成Level 1為錄取，2為不錄取-->Level 1 要放正面答案
mydata$admit<-factor(mydata$admit,levels=c(1,0))
```

逐步選擇最好的模型
```{r warning=F,message=F,fig.height=4.5}
# GRE:某考試成績, GPA:在校平均成績, rank:學校聲望
mylogit <- glm(admit ~ gre + gpa + rank,
               data = mydata[mydata$Test==F,], family = "binomial")
finalFit<-stepAIC(mylogit,direction = "both",trace=FALSE) # 雙向逐步選擇模型
summary(finalFit)
```

用預測組預測新學生可不可以錄取，並驗證答案
```{r warning=F,message=F,fig.height=4.5}
AdmitProb<-predict(finalFit, # 用Training set做的模型
                   newdata = mydata[mydata$Test==T,], #Test==T, test data
                   type="response") #結果為每個人被錄取的機率
head(AdmitProb)
table(AdmitProb<0.5,mydata[mydata$Test==T,]$admit) # row,column
```

當答案是二元時：效能指標

- Sensitivity 敏感性
- Specificity 特異性
- Positive Predictive Value (PPV) 陽性預測值
- Negative Predictive Value (NPV) 陰性預測值

名詞解釋

```{r echo=FALSE}
knitr::include_graphics("figure/Cond.png")
```

- TP: 有病且預測也有病
- TN: 沒病且預測也沒病
- FP: 沒病但是預測有病
- FN: 有病但預測沒病


```{r echo=FALSE}
knitr::include_graphics("figure/para.png")
```

當答案是二元時：效能指標公式
 
- Sensitivity 敏感性：所有`真的有病`的人，被`預測有病`的比例
- Specificity 特異性：所有`真的沒病`的人，被`預測沒病`的比例
- Positive Predictive Value (PPV) 陽性預測值：所有被`預測有病`的人，`真的有病`的比例
- Negative Predictive Value (NPV) 陰性預測值：所有被`預測沒病`的人，`真的沒病`的比例

 回想一下剛剛的驗證結果
```{r warning=F,message=F,fig.height=4.5}
table(AdmitProb<0.5,mydata[mydata$Test==T,]$admit) # row,column
```
```{r echo=FALSE}
knitr::include_graphics("figure/para.png")
```


 計算預測效能參數
```{r warning=F,message=F,fig.height=4.5}
AdmitProb<-predict(finalFit,
                   newdata = mydata[mydata$Test==T,], #Test==T, test data
                   type="response") #結果為每個人『不』被錄取的機率
AdmitAns<-factor(ifelse(AdmitProb<0.5,1,0),levels=c(1,0))
str(AdmitAns)
```

 計算預測效能參數
```{r warning=F,message=F,fig.height=4.5}
library(caret) # install.packages("caret") #計算參數的packages
sensitivity(AdmitAns,mydata[mydata$Test==T,]$admit)
specificity(AdmitAns,mydata[mydata$Test==T,]$admit)
posPredValue(AdmitAns,mydata[mydata$Test==T,]$admit)
negPredValue(AdmitAns,mydata[mydata$Test==T,]$admit)
```


### Decision Trees 決策樹驗證

 阻攻/籃板/三分/助攻/抄截判斷位置-訓練
```{r warning=F,message=F,fig.height=4.5}
if (!require('rpart')){
    install.packages("rpart"); library(rpart)
}
DT<-rpart(Position~Blocks+TotalRebounds+ThreesMade+Assists+Steals,
          data=NBA1516[NBA1516$Test==F,]) #訓練組 Training set
#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）
DT
```

阻攻/籃板/三分/助攻/抄截判斷位置-訓練

預設的`plot()`真的太難用，改用`rpart.plot` package的`prp()`
```{r warning=F,message=F,fig.height=4.5}
if (!require('rpart.plot')){
  install.packages("rpart.plot"); 
  library(rpart.plot)
}
prp(DT)	# 把決策樹畫出來
```

 阻攻/籃板/三分/助攻/抄截判斷位置-訓練
```{r warning=F,message=F,fig.height=5}
prp(DT)
```

 有批球員沒寫守備位置？--預測
```{r warning=F,message=F,fig.height=5}
posPred<-predict(DT,newdata= NBA1516[NBA1516$Test==T,]) #Test==T, test data
# 預設為class probabilities, type = "prob"
head(posPred)
```


 有個人沒寫守備位置--對答案
```{r warning=F,message=F,fig.height=5}
result<-cbind(round(posPred,digits = 2),
              NBA1516[NBA1516$Test==T,]$Name,
      as.character(NBA1516[NBA1516$Test==T,]$Position))
head(result)
```


 有個人沒寫守備位置--預測-2
```{r warning=F,message=F,fig.height=5}
posPredC<-predict(DT,newdata= NBA1516[NBA1516$Test==T,],type = "class")
# type = "class" 直接預測類別
head(posPredC)
```

 有個人沒寫守備位置--對答案-2
```{r warning=F,message=F,fig.height=5}
resultC<-cbind(as.character(posPredC),NBA1516[NBA1516$Test==T,]$Name,
      as.character(NBA1516[NBA1516$Test==T,]$Position))
head(resultC)
```

## Case Study

完整的模型建立步驟範例：

- 標題：以聲波撞擊礦石的回聲預測礦石是否為礦物
- 以Sonar, Mines vs. Rocks為例

**步驟1.1:讀資料**

```{r message=F,warning=F}
#install.packages("mlbench") # 此package內有很多dataset可練習
library(mlbench)
data(Sonar)
str(Sonar) #看一下資料型別，有沒有缺值，類別變項是不是factor
```

在建立模型之前...別忘了基本的資料分析，使用`探索性分析 Exploratory data analysis`，看看資料長怎麼樣，要是有一個參數可以完美的把礦物跟石頭分開，那就不用麻煩建模了...

探索性分析 Exploratory data analysis
```{r warning=F,message=F,fig.height=4}
library(ggplot2);library(reshape2) #install.packages(c("ggplot2","reshape2"))
Sonar.m<-melt(Sonar,id.vars = c("Class"))
ggplot(Sonar.m)+geom_boxplot(aes(x=Class,y=value))+
    facet_wrap(~variable, nrow=5,scales = "free_y") #圖片太小了
```

**步驟1.2: 資料前處理**
 
- 缺值？
    - 沒有缺值，不需要處理
- 答案種類？
    - 類別變項叫`Class`，M: mine礦-->+, R: rock-->-，不需要處理
- 類別變項的型別是不是factor？
    - 是，不需要處理
- 有沒有無關的參數？
    - 沒有無關的參數，不需要處理

**步驟2:分成訓練組與測試組**

該怎麼分可以自己決定，1/3，1/5...都可以
```{r}
Sonar$Test<-F #新增一個參數紀錄分組
#隨機取1/3當Test set
Sonar[sample(1:nrow(Sonar),nrow(Sonar)/3),]$Test<-T
# 看一下 Training set : Test set 案例數
c(sum(Sonar$Test==F),sum(Sonar$Test==T))
```

**步驟3:訓練模型**

- 注意只能用`訓練組`的資料，`Test`參數==F，忘記可以看前面範例
- 數值自變項X很多，先用迴歸好了～
- 要解釋一下模型
```{r warning=F,message=F}
fit<-glm(Class~., Sonar[Sonar$Test==F,],family="binomial")
finalFit<-stepAIC(fit,direction = "both",trace = F)
summary(finalFit)$coefficients
```

**步驟4.1:用測試組驗證模型-預測**

```{r warning=F,message=F,fig.height=4.5}
MinePred<-predict(finalFit,newdata = Sonar[Sonar$Test==T,])
MineAns<-ifelse(MinePred<0.5,"M","R") #<0.5: Level 1
MineAns<-factor(MineAns,levels = c("M","R"))
MineAns
```

**步驟4.2:用測試組驗證模型-效能**

```{r warning=F,message=F,fig.height=4.5}
library(caret) # install.packages("caret") #計算參數的packages
sensitivity(MineAns,Sonar[Sonar$Test==T,]$Class)
specificity(MineAns,Sonar[Sonar$Test==T,]$Class)
posPredValue(MineAns,Sonar[Sonar$Test==T,]$Class)
negPredValue(MineAns,Sonar[Sonar$Test==T,]$Class)
```

**解釋範例 - 資料說明**

此資料來源為UCI Machine Learning Repository。

記載礦物與石頭接受各個不同角度的聲波撞擊後，接收到的回聲數值，一共有60個參數，代表使用一特別角度的聲波撞擊礦石所得回聲。另外，分類結果為二元分類，包括礦物 (M) 與石頭 (R) 。


**解釋範例 - 模型說明**

使用聲波在不同角度撞擊`礦石`所得到的回聲資料，以邏輯迴歸建立模型預測礦石是否為礦物，經最佳化後，模型使用參數為V1 + V2 + V3 + V4 + V7 + V11 + V12 + V13 + V17 + V18 + V22 + V24 + V25 + V26 + V30 + V31 + V32 + V38 + V39 + V48 + V50 + V52 + V53 + V58 + V59，共25個參數，各參數代表從一特別角度所得的礦石回聲

**解釋範例 - 預測效能說明**
 
使用聲波在不同角度撞擊`礦石`所得到的回聲資料，以邏輯迴歸模型預測礦石是否為礦物，可得敏感度97%，特異性89%，陽性預測率89%，陰性預測率97%。

## 參考資料
- 台大資工林軒田教授：
    - [Machine Learning Foundations](www.coursera.org/course/ntumlone)
    - [Machine Learning Techniques](www.coursera.org/course/ntumltwo)

- [Market Basket Analysis with R](http://www.salemmarafi.com/code/market-basket-analysis-with-r/)

- [Deep Learning in R](https://www.r-bloggers.com/deep-learning-in-r-2/)


<!--chapter:end:10-DataMining.Rmd-->

# 從小數據到大數據分析 {#big}

## R + Hadoop

## RHadoop安裝測試流程 (Cloudera)
安裝與測試日期2016/05/12

### 系統/軟體版本資訊
- Cloudera Hadoop Platform: CDH-5.4.5 [下載](http://www.cloudera.com/downloads/cdh/5-4-5.html){target="_blank"}
- R for Linux 3.3.0 [安裝說明](https://cran.rstudio.com/bin/linux/redhat/README){target="_blank"}
- RStudio Server [下載](https://www.rstudio.com/products/rstudio/download-server/){target="_blank"}
- RHadoop (latest version on May 12, 2016) [下載](https://github.com/RevolutionAnalytics/RHadoop/wiki/Downloads){target="_blank"}
    - ravro-1.0.3
    - plyrmr-0.6.0
    - rmr-3.3.1
    - rhdfs-1.0.8
    - rhbase-1.2.1


### 參考資料
- [RHadoop安裝說明文件](https://github.com/RevolutionAnalytics/RHadoop/wiki/Installing-RHadoop-on-RHEL){target="_blank"}
- [RHadoop安裝步驟](https://bigdatastudy.hackpad.com/ep/pad/static/IADMBeqF0vV){target="_blank"}
- [Setting persistent environment variable in CentOS 7 issue](http://unix.stackexchange.com/questions/271514/setting-persistent-environment-variable-in-centos-7-issue){target="_blank"}
- [How to resolve "Permission denied" errors in CDH](https://community.cloudera.com/t5/CDH-Manual-Installation/How-to-resolve-quot-Permission-denied-quot-errors-in-CDH/ta-p/36141){target="_blank"}

### 安裝步驟
1. 下載Cloudera CDH QuickStart VM [Cloudera VM](http://www.cloudera.com/developers/get-started-with-hadoop-tutorial.html){target="_blank"}
2. 安裝R [安裝說明](https://cran.rstudio.com/bin/linux/redhat/README){target="_blank"}
3. 安裝RHadoop [RHadoop安裝步驟](https://bigdatastudy.hackpad.com/ep/pad/static/IADMBeqF0vV){target="_blank"}
4. 安裝RStudio Server [說明](https://www.rstudio.com/products/rstudio/download-server/){target="_blank"}

#### Cloudera CDH QuickStart VM
Cloudera CDH QuickStart VM是由Cloudera提供的虛擬機器，內涵Linux系統與預載多項Hadoop相關服務，適合想了解Hadoop運作的初學者。

下載VM後，用Virtural Box 開啟即可。

- [Cloudera CDH QuickStart VM下載處](http://www.cloudera.com/developers/get-started-with-hadoop-tutorial.html){target="_blank"}
- [Virtural Box下載處](https://www.virtualbox.org/){target="_blank"}

以下安裝步驟都在Cloudera CDH QuickStart VM內進行

#### 安裝R
- Cloudera CDH用的Linux作業系統是CentOS
- 依照安裝說明，需要先安裝Extra
Packages for Enterprise Linux (EPEL)，但系統內有預載，所以可以不用按照說明重新下載安裝，直接執行`sudo yum install epel-release`指令即可
- 步驟：安裝最新EPRL，更新yum，安裝R。打開Terminal輸入以下指令。

```
sudo yum install epel-release
sudo yum update
sudo yum install R
```

#### 安裝RHadoop-1 先進行環境設定
設定`HADOOP_CMD`與`HADOOP_STREAMING`兩項環境參數，路徑可能會不同（尤其是`HADOOP_STREAMING`）

1. 尋找`HADOOP_STREAMING`路徑方法
```
find / -name hadoop-streaming-*.jar
```

2. 設定`HADOOP_CMD`與`HADOOP_STREAMING`兩項環境參數，路徑記得換成自己的
```
echo export HADOOP_CMD="/usr/bin/hadoop">/etc/profile.d/hadoopenv.sh
echo export HADOOP_STREAMING=
    "/opt/cloudera/parcels/CDH-5.4.5-1.cdh5.4.5.p0.7/lib/hadoop-mapreduce/
        hadoop-streaming-2.6.0-cdh5.4.5.jar" > /etc/profile.d/hadoopenv.sh
chmod 0755 /etc/profile.d/hadoopenv.sh
```

#### 安裝RHadoop-2 rmr2
- 每個Node都要裝
- 安裝前先至[說明檔](https://github.com/RevolutionAnalytics/rmr2/blob/master/pkg/DESCRIPTION){target="_blank"}看需要先安裝哪些其他的packages，Depends 和 Imports 所列的packages都要裝
- 以下為安裝packages的程式碼，在R內執行（在Terminal輸入`R`，就能進入R軟體）
```{r, eval=F}
install.packages(c("methods","Rcpp", "RJSONIO", "digest", "functional", 
                   "reshape2","stringr", "plyr", "caTools","quickcheck","testthat"), 
                 dependencies=TRUE, repos='http://cran.rstudio.com/')
```

- 使用`q()`指令，跳出R軟體
- [下載rmr2](https://github.com/RevolutionAnalytics/RHadoop/wiki/Downloads){target="_blank"}
- 安裝（請將`rmr2_2.3.0.tar.gz`替換成剛剛下載的安裝檔路徑）

```
sudo R CMD INSTALL rmr2_2.3.0.tar.gz
```

#### 安裝RHadoop-3 rhdfs
- 只要裝在會跑R的那個Node
- 在裝之前，先Check是否有安裝JDK （測試JDK 1.8.0_91沒問題）
- Check環境變數JAVA_HOME是否有設好

```
echo $JAVA_HOME
```

若什麼都沒有回傳，先設定環境變數（將`/usr/java/jdk1.8.0_91`換成自己的路徑）

```
echo export JAVA_HOME="/usr/java/jdk1.8.0_91">/etc/profile.d/jdkenv.sh
```

為了讓R可以跑JAVA，在Terminal輸入

```
R CMD javareconf
```

然後進到R程式（在Terminal輸入`R`，就能進入R軟體），安裝`rJava` package
```{r, eval=F}
install.packages("rJava",dependencies=TRUE, repos='http://cran.rstudio.com/'){target="_blank"}
```

最後跳出R程式，[下載rhdfs](https://github.com/RevolutionAnalytics/RHadoop/wiki/Downloads){target="_blank"}，安裝rhdfs

- 將`/usr/bin/hadoop`換成自己的`HADOOP_CMD`路徑
- `rhdfs_1.0.8.tar.gz`換成下載的安裝檔路徑）

```
sudo HADOOP_CMD=/usr/bin/hadoop R CMD INSTALL rhdfs_1.0.8.tar.gz
```

### 測試前，先解決權限問題
- 預設hdfs的存取權限不足，所以要打開
- 將`user01`改為自己的使用者名稱

```
sudo -u hdfs hadoop fs -mkdir /user/user01
sudo -u hdfs hadoop fs -chown user01 /user/user01
```

### 測試
進入R測試以下程式碼是否能執行
```{r, eval=F}
Sys.setenv(HADOOP_CMD="/usr/bin/hadoop")
Sys.setenv(HADOOP_STREAMING="/opt/cloudera/parcels/CDH-5.4.5-1.cdh5.4.5.p0.7/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.4.5.jar")
library(rmr2)
#test mapreduce
small.ints = to.dfs(1:100)
out<-mapreduce(
    input = small.ints, 
    map = function(., v) cbind(v, v^2))
head(from.dfs(out))
```

### 安裝RStudio Server
[官方下載與安裝說明](https://www.rstudio.com/products/rstudio/download-server/){target="_blank"}

在Terminal執行以下程式碼

- 檔案連結`https://download2.rstudio.org/rstudio-server-rhel-0.99.896-x86_64.rpm`可能有最新版，請Check[官網](https://www.rstudio.com/products/rstudio/download-server/){target="_blank"}

```
wget https://download2.rstudio.org/rstudio-server-rhel-0.99.896-x86_64.rpm
sudo yum install --nogpgcheck rstudio-server-rhel-0.99.896-x86_64.rpm

```

打開瀏覽器，輸入`http://localhost:8787/`，就能進入RStudio Server了！

測完收工～

## RHadoop MapReduce: easy word count
```{r eval=F}
Debate<-readLines("https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/104/RepDebateMiami.txt")
DebateSplit<-unlist(strsplit(tolower(Debate),split = ' |\\.|\\,|\\?'))
#table(DebateSplit)
```

```{r eval=F}
DebateSplitDFS = to.dfs(DebateSplit)
result = mapreduce(
    input = DebateSplitDFS,
    map = function(.,v) keyval(v, 1),
    reduce = function(k,vv) keyval(k, sum(vv)))
head(result)
```

## R + Spark
sparklyr
SparkR 


Supports dplyr, Spark ML and H2O
Distributed on CRAN
Easy to install
Extensible

測試環境

- R version 3.3.2 (2016-10-31)
- Platform: x86_64-w64-mingw32/x64 (64-bit)
- Running under: Windows >= 8 x64 (build 9200)
- sparklyr_0.5.3-9002


```{r spark1,eval=F}
install.packages("sparklyr")
#devtools::install_github("rstudio/sparklyr")
```

```{r spark2,eval=F}
library(sparklyr)
spark_install(version = "2.1.0")
```

```{r spark3,eval=F}
#Sys.setenv(SPARK_HOME="C:/Users/yjtseng/AppData/Local/rstudio/spark/Cache/spark-2.0.1-bin-hadoop2.7")
#Sys.setenv(HADOOP_HOME="C:\\Program Files\\RStudio\\bin\\winutils\\x64\\")
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local", version = "2.1.0")
```

```{r spark4,eval=F}
install.packages(c("nycflights13", "Lahman"))
```

```{r spark5,eval=F}
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
src_tbls(sc)
flights_tbl %>% filter(dep_delay == 2)
```

```
Source:   query [6,233 x 19]
Database: spark connection master=local[8] app=sparklyr local=TRUE

    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay
   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>     <dbl>
1   2013     1     1      517            515         2      830            819        11
2   2013     1     1      542            540         2      923            850        33
3   2013     1     1      702            700         2     1058           1014        44
4   2013     1     1      715            713         2      911            850        21
5   2013     1     1      752            750         2     1025           1029        -4
6   2013     1     1      917            915         2     1206           1211        -5
7   2013     1     1      932            930         2     1219           1225        -6
8   2013     1     1     1028           1026         2     1350           1339        11
9   2013     1     1     1042           1040         2     1325           1326        -1
10  2013     1     1     1231           1229         2     1523           1529        -6
# ... with 6,223 more rows, and 10 more variables: carrier <chr>, flight <int>,
#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,
#   minute <dbl>, time_hour <dbl>
```

```{r spark6,eval=F}
spark_disconnect(sc)
```

在RStudio中有整合Spark連線功能，右上角的Spark頁籤可供使用者開啟特定版本的Spark connections，除此之外，也可使用Spark頁籤瀏覽在Spark中的表格結構與資料的前1000列。


參考資料

- http://spark.rstudio.com/
- https://shiring.github.io/machine_learning/2017/02/19/food_spark

<!--chapter:end:11-bigData.Rmd-->

# 軟體安裝介紹 {#install}
本章節將介紹R與RStudio的安裝與基本使用方式

## R安裝
[R語言](http://www.r-project.org/){target="_blank"}是一種自由軟體程式語言，主要用於資料分析與統計運算，2000年時終於發表R 1.0.0，有關R語言的發展歷史可參考[維基百科](https://zh.wikipedia.org/wiki/R%E8%AF%AD%E8%A8%80){target="_blank"}。

安裝步驟如下: 

**Step 1. 從R的官網下載安裝檔**

- 進入R官網 https://www.r-project.org/ 
- 選擇**Download**下方的**CRAN**連結
- 進入CRAN子網頁後，請選擇離所在地最近的載點，以臺灣桃園為例，可選擇元智大學 (	Department of Computer Science and Engineering, Yuan Ze University) 的載點。

進入下載網頁後，可看到多個選項:

- Download R for Linux
- Download R for (Mac) OS X
- Download R for Windows

依作業系統選擇適當連結後，點選**base** (Binaries for base distribution)，下載最新版本的R安裝檔。

**Step 2. 依安裝檔指示完成安裝**

## RStudio安裝
[RStudio](https://www.rstudio.com/){target="_blank"}是R語言的IDE，屬於免費自由軟體，提供一般桌面板與伺服器版，以下介紹桌面板安裝方式，伺服器版安裝可參考Chapter \@ref(big)。

**Step 1. 從RStudio的官網下載安裝檔**

- 進入RStudio官網 https://www.rstudio.com/ 
- 選擇網頁上方**Products**連結內的**RStudio**
- 選擇**Desktop**版本
- 點選**Open Source Edition**下方的**DOWNLOAD RSTUDIO DESKTOP**
- 點選RStudio Desktop Open Source License下方的**DOWNLOAD**

選單中會出現多種作業系統版本，以RStudio 1.0.136為例，各作業系統版本如下

- RStudio 1.0.136 - Windows Vista/7/8/10	
- RStudio 1.0.136 - Mac OS X 10.6+ (64-bit)	
- RStudio 1.0.136 - Ubuntu 12.04+/Debian 8+ (32-bit)
- RStudio 1.0.136 - Ubuntu 12.04+/Debian 8+ (64-bit)
- RStudio 1.0.136 - Fedora 19+/RedHat 7+/openSUSE 13.1+ (32-bit)
- RStudio 1.0.136 - Fedora 19+/RedHat 7+/openSUSE 13.1+ (64-bit)	

依作業系統選擇適當連結

**Step 2. 依安裝檔指示完成安裝**

## RStudio使用簡介


### 專案
RStudio引進專案(Project)的概念，幫助使用者管理同一專案之R程式碼檔案，同時完成工作路徑的設定 (設定為專案所在資料夾)。除快速測試外，建議一開始就以專案形式新增R程式碼。

以本課程為例，開啟RStudio視窗後，可在左上**File**選項中選擇**New Project**後，依需求選擇**New Directory**或**Existing Directory**

```{r echo=FALSE}
knitr::include_graphics("figure/NewProject.png")
```

若選擇的是**New Directory**，則會出現下列三個選項

- Empty Project
- R Package
- Shiny Web Application

若是新增一般分析專案，選擇**Empty Project**後，輸入**專案路徑**與**專案名稱**，完成專案新增。

```{r echo=FALSE}
knitr::include_graphics("figure/NewProject1.png")
```

完成專案新增後，在專案內新增R程式碼檔案(File -> New file -> R Script)後，**程式碼編輯區 Source editor**就會出現在左上角。


### RStudio介面
RStudio的介面共有四個區塊，分別為

- 程式碼編輯區 Source editor
- 執行視窗 Console
- 環境/物件
- 檔案/圖表/說明文件

剛開啟一個新的RStudio視窗時不會有**程式碼編輯區 Source editor**，必須要新增專案後才會出現。

```{r echo=FALSE}
knitr::include_graphics("figure/RStudio.png")
```

建議使用方式如下:

- 在左上方**程式碼編輯區 Source editor**撰寫程式碼
- 完成程式碼撰寫後，將需要執行的程式碼反白，點選**Run** (見下圖)，執行程式碼
- 除了反白外，將游標移至需要執行的程式碼，，點選**Run** (見下圖)也可執行該行程式碼
- 程式碼會在左下方Console視窗執行，顯示結果
- 如果有畫圖，會出現在右下方視窗
- 可在右上方視窗檢查所有變數

```{r echo=FALSE}
knitr::include_graphics("figure/ed.png")
```

RStudio的其他使用細節，可參考[RStudio IDE Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf){target="_blank"}

<!--chapter:end:12-install.Rmd-->

# 作者資訊{- #author}
曾意儒 Yi-Ju Tseng

[長庚大學 資訊管理學系](http://im.cgu.edu.tw/bin/home.php){target="_blank"} 助理教授

[個人網站](http://yijutseng.github.io){target="_blank"}

Lab: [數位健康實驗室](https://dhlab-cgu.github.io/){target="_blank"}

歡迎提供[建議與回饋](https://goo.gl/forms/5Htobvwy2vsB7yiF3){target="_blank"}





<!--chapter:end:13-author.Rmd-->

`r if (knitr:::is_html_output()) '# References {-}'`


<!--chapter:end:14-references.Rmd-->

